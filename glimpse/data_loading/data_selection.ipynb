{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11451</th>\n",
       "      <td>https://openreview.net/forum?id=QjINdYOfq0b</td>\n",
       "      <td>Summary: The paper presents a technique called...</td>\n",
       "      <td>The paper proposes to integrate multiple bit c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11452</th>\n",
       "      <td>https://openreview.net/forum?id=POWv6hDd9XH</td>\n",
       "      <td>I couldn't follow the method described in the ...</td>\n",
       "      <td>This paper proposes a new method for post-trai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11453</th>\n",
       "      <td>https://openreview.net/forum?id=POWv6hDd9XH</td>\n",
       "      <td>Post-training quantization is an important pro...</td>\n",
       "      <td>This paper proposes a new method for post-trai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11454</th>\n",
       "      <td>https://openreview.net/forum?id=POWv6hDd9XH</td>\n",
       "      <td>This paper proposes BRECQ which is a new Post ...</td>\n",
       "      <td>This paper proposes a new method for post-trai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11455</th>\n",
       "      <td>https://openreview.net/forum?id=POWv6hDd9XH</td>\n",
       "      <td>This paper explores the post-training inferenc...</td>\n",
       "      <td>This paper proposes a new method for post-trai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                id  \\\n",
       "11451  https://openreview.net/forum?id=QjINdYOfq0b   \n",
       "11452  https://openreview.net/forum?id=POWv6hDd9XH   \n",
       "11453  https://openreview.net/forum?id=POWv6hDd9XH   \n",
       "11454  https://openreview.net/forum?id=POWv6hDd9XH   \n",
       "11455  https://openreview.net/forum?id=POWv6hDd9XH   \n",
       "\n",
       "                                                    text  \\\n",
       "11451  Summary: The paper presents a technique called...   \n",
       "11452  I couldn't follow the method described in the ...   \n",
       "11453  Post-training quantization is an important pro...   \n",
       "11454  This paper proposes BRECQ which is a new Post ...   \n",
       "11455  This paper explores the post-training inferenc...   \n",
       "\n",
       "                                                    gold  \n",
       "11451  The paper proposes to integrate multiple bit c...  \n",
       "11452  This paper proposes a new method for post-trai...  \n",
       "11453  This paper proposes a new method for post-trai...  \n",
       "11454  This paper proposes a new method for post-trai...  \n",
       "11455  This paper proposes a new method for post-trai...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_glimpse = \"../../data/processed/\"\n",
    "\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "\n",
    "for year in range (2017, 2022):\n",
    "    sub_dataset = pd.read_csv(f\"{data_glimpse}all_reviews_{year}.csv\")\n",
    "    dataset = pd.concat([dataset, sub_dataset])\n",
    "\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(subset=['gold'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> list:\n",
    "    # Replace any set of successive dashes (e.g., --, ----, -----) with a newline\n",
    "    text = re.sub(r'-{2,}', '\\n', text)\n",
    "\n",
    "    # Remove patterns like \".2-\" or isolated numerics with hyphens\n",
    "    text = re.sub(r'\\.\\d+-', '', text)\n",
    "\n",
    "    # Replace multiple newlines or spaces with a single newline or space\n",
    "    # Replace multiple newlines with one\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    # Replace multiple spaces with one\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Remove any remaining unwanted characters (e.g., control characters)\n",
    "    # Remove non-ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "\n",
    "    # To be discussed\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    # remove empty sentences\n",
    "    sentences = [sentence for sentence in sentences if sentence != \"\"]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Natalia\n",
      "[nltk_data]     Lebedeva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Natalia\n",
      "[nltk_data]     Lebedeva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('punkt_tab')\n",
    "\n",
    "dataset['text_processed'] = dataset['text'].apply(preprocess_text)\n",
    "dataset['gold_processed'] = dataset['gold'].apply(preprocess_text)\n",
    "\n",
    "dataset['len_text'] = dataset['text'].apply(lambda x: len(x))\n",
    "dataset['len_gold'] = dataset['gold'].apply(lambda x: len(x))\n",
    "\n",
    "dataset['len_text_sent'] = dataset['text_processed'].apply(lambda x: len(x))\n",
    "dataset['len_gold_sent'] = dataset['gold_processed'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>gold</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>gold_processed</th>\n",
       "      <th>len_text</th>\n",
       "      <th>len_gold</th>\n",
       "      <th>len_text_sent</th>\n",
       "      <th>len_gold_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>https://openreview.net/forum?id=SyeKGgStDB</td>\n",
       "      <td>This paper proposes an RL agent for generating...</td>\n",
       "      <td>Paper is withdrawn by authors.</td>\n",
       "      <td>[This paper proposes an RL agent for generatin...</td>\n",
       "      <td>[Paper is withdrawn by authors.]</td>\n",
       "      <td>1961</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>https://openreview.net/forum?id=SyeKGgStDB</td>\n",
       "      <td>This paper presents a reinforcement learning a...</td>\n",
       "      <td>Paper is withdrawn by authors.</td>\n",
       "      <td>[This paper presents a reinforcement learning ...</td>\n",
       "      <td>[Paper is withdrawn by authors.]</td>\n",
       "      <td>3665</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>https://openreview.net/forum?id=SyeKGgStDB</td>\n",
       "      <td>The authors present the results of training a ...</td>\n",
       "      <td>Paper is withdrawn by authors.</td>\n",
       "      <td>[The authors present the results of training a...</td>\n",
       "      <td>[Paper is withdrawn by authors.]</td>\n",
       "      <td>2972</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id  \\\n",
       "5908  https://openreview.net/forum?id=SyeKGgStDB   \n",
       "5909  https://openreview.net/forum?id=SyeKGgStDB   \n",
       "5910  https://openreview.net/forum?id=SyeKGgStDB   \n",
       "\n",
       "                                                   text  \\\n",
       "5908  This paper proposes an RL agent for generating...   \n",
       "5909  This paper presents a reinforcement learning a...   \n",
       "5910  The authors present the results of training a ...   \n",
       "\n",
       "                                gold  \\\n",
       "5908  Paper is withdrawn by authors.   \n",
       "5909  Paper is withdrawn by authors.   \n",
       "5910  Paper is withdrawn by authors.   \n",
       "\n",
       "                                         text_processed  \\\n",
       "5908  [This paper proposes an RL agent for generatin...   \n",
       "5909  [This paper presents a reinforcement learning ...   \n",
       "5910  [The authors present the results of training a...   \n",
       "\n",
       "                        gold_processed  len_text  len_gold  len_text_sent  \\\n",
       "5908  [Paper is withdrawn by authors.]      1961        30             12   \n",
       "5909  [Paper is withdrawn by authors.]      3665        30             32   \n",
       "5910  [Paper is withdrawn by authors.]      2972        30             18   \n",
       "\n",
       "      len_gold_sent  \n",
       "5908              1  \n",
       "5909              1  \n",
       "5910              1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset['len_gold'] == 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_text</th>\n",
       "      <th>len_gold</th>\n",
       "      <th>len_text_sent</th>\n",
       "      <th>len_gold_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26276.000000</td>\n",
       "      <td>26276.000000</td>\n",
       "      <td>26276.000000</td>\n",
       "      <td>26276.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2712.092366</td>\n",
       "      <td>836.400594</td>\n",
       "      <td>23.283719</td>\n",
       "      <td>6.423999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1700.358477</td>\n",
       "      <td>663.477740</td>\n",
       "      <td>14.786403</td>\n",
       "      <td>4.949147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1586.000000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2323.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3389.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29777.000000</td>\n",
       "      <td>7509.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           len_text      len_gold  len_text_sent  len_gold_sent\n",
       "count  26276.000000  26276.000000   26276.000000   26276.000000\n",
       "mean    2712.092366    836.400594      23.283719       6.423999\n",
       "std     1700.358477    663.477740      14.786403       4.949147\n",
       "min       22.000000     30.000000       1.000000       1.000000\n",
       "25%     1586.000000    411.000000      14.000000       3.000000\n",
       "50%     2323.000000    666.000000      20.000000       5.000000\n",
       "75%     3389.000000   1045.000000      29.000000       8.000000\n",
       "max    29777.000000   7509.000000     308.000000      67.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data filtering through dot products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def embed_text_and_summaries(df : pd.DataFrame, model : SentenceTransformer) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "    text_embeddings = model.encode(df.text.tolist(), convert_to_tensor=True)\n",
    "    # summary_embeddings = model.encode(df.summary.tolist(), convert_to_tensor=True)\n",
    "    summary_embeddings = model.encode(df.gold.tolist(), convert_to_tensor=True)\n",
    "\n",
    "    return text_embeddings, summary_embeddings\n",
    "\n",
    "\n",
    "def compute_dot_products(df : pd.DataFrame, text_embeddings : torch.Tensor, summary_embeddings : torch.Tensor):\n",
    "\n",
    "    df = df.reset_index()\n",
    "    df['index'] = df.index\n",
    "\n",
    "    # group by id\n",
    "    grouped = df.groupby('id')\n",
    "\n",
    "    # for each id gather the id of the text and the summary\n",
    "    ids_per_sample = grouped.index.apply(list).tolist()\n",
    "\n",
    "    # compute the dot product between the text and the summary\n",
    "\n",
    "    metrics = {'proba_of_success' : []}\n",
    "    for text_ids in ids_per_sample:\n",
    "        # shape (num_text, embedding_dim)\n",
    "        text_embedding = text_embeddings[text_ids]\n",
    "        summary_embedding = summary_embeddings[text_ids]\n",
    "\n",
    "        # shape (num_text, num_text=num_summary)\n",
    "        dot_product = torch.matmul(text_embedding, summary_embedding.T)\n",
    "\n",
    "        # apply log softmax\n",
    "        log_softmax = torch.nn.functional.log_softmax(dot_product, dim=0)\n",
    "\n",
    "        # num_text\n",
    "        log_proba_of_success = torch.diag(log_softmax).squeeze()\n",
    "\n",
    "        metrics['proba_of_success'].extend(log_proba_of_success.tolist())\n",
    "\n",
    "    df['proba_of_success'] = metrics['proba_of_success']\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_cossim(summaries_file, result_file, device='cuda'):\n",
    "    # load the model\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2', device=device)\n",
    "    # load the summaries\n",
    "    df = pd.read_csv(summaries_file)\n",
    "    # embedd the text and the summary\n",
    "    text_embeddings, summary_embeddings = embed_text_and_summaries(df, model)\n",
    "    df = compute_dot_products(df, text_embeddings, summary_embeddings)\n",
    "    df.to_csv(result_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_file = \"../../data/merged17-21_filtered_4_no_unique.csv\"\n",
    "res_file = \"../../data/cossimresults/all_merged17-21cossim.csv\"\n",
    "calculate_cossim(sum_file, res_file, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cossim_res = pd.read_csv(\"../../data/cossimresults/all_merged17-21cossim.csv\")\n",
    "cossim_res.drop(columns=['index', 'gold_cleaned', 'gold_length', 'gold_word_count', 'gold_sentences', 'text_cleaned', 'text_length', 'text_word_count', 'text_sentences'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cossim_res['proba_of_success'] = cossim_res.groupby('id')['proba_of_success'].transform('mean')\n",
    "cossim_res.sort_values(by='proba_of_success', ascending=False, inplace=True)\n",
    "checkdf = cossim_res[:200]\n",
    "checkdf = checkdf[checkdf.groupby('id')['id'].transform('count') == 2]\n",
    "checkdf.describe()\n",
    "\n",
    "cossim_res.to_csv(\"../../data/cossimresults/all_merged17-21_cossim-sorted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>gold</th>\n",
       "      <th>proba_of_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>https://openreview.net/forum?id=Hkexw1BtDr</td>\n",
       "      <td>The paper introduces auto-deferring policies (...</td>\n",
       "      <td>This paper proposes a new way to formulate the...</td>\n",
       "      <td>-0.021927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>https://openreview.net/forum?id=Hkexw1BtDr</td>\n",
       "      <td>The paper proposes a Deep RL approach called A...</td>\n",
       "      <td>This paper proposes a new way to formulate the...</td>\n",
       "      <td>-0.021927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>https://openreview.net/forum?id=H1OQukZ0-</td>\n",
       "      <td>Summary of the paper--------------------------...</td>\n",
       "      <td>This paper presents an update to the method of...</td>\n",
       "      <td>-0.051171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>https://openreview.net/forum?id=H1OQukZ0-</td>\n",
       "      <td># Summary of paper--------The paper proposes a...</td>\n",
       "      <td>This paper presents an update to the method of...</td>\n",
       "      <td>-0.051171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>https://openreview.net/forum?id=Byiy-Pqlx</td>\n",
       "      <td>The Neural Turing Machine and related “externa...</td>\n",
       "      <td>The paper presents a Lie-(group) access neural...</td>\n",
       "      <td>-0.058358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>https://openreview.net/forum?id=Byiy-Pqlx</td>\n",
       "      <td>*** Paper Summary ***----------------This pape...</td>\n",
       "      <td>The paper presents a Lie-(group) access neural...</td>\n",
       "      <td>-0.058358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303</th>\n",
       "      <td>https://openreview.net/forum?id=rygixkHKDH</td>\n",
       "      <td>[Summary]-----This paper studies the problem o...</td>\n",
       "      <td>This paper investigates the use non-convex opt...</td>\n",
       "      <td>-0.072678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>https://openreview.net/forum?id=rygixkHKDH</td>\n",
       "      <td>This paper studies the dictionary learning pro...</td>\n",
       "      <td>This paper investigates the use non-convex opt...</td>\n",
       "      <td>-0.072678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14107</th>\n",
       "      <td>https://openreview.net/forum?id=lU5Rs_wCweN</td>\n",
       "      <td>This work aims at accelerating pre-training by...</td>\n",
       "      <td>The authors propose an approach for pre-traini...</td>\n",
       "      <td>-0.087223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14108</th>\n",
       "      <td>https://openreview.net/forum?id=lU5Rs_wCweN</td>\n",
       "      <td>Summary: This paper proposes a method for impr...</td>\n",
       "      <td>The authors propose an approach for pre-traini...</td>\n",
       "      <td>-0.087223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5926</th>\n",
       "      <td>https://openreview.net/forum?id=HJlU-AVtvS</td>\n",
       "      <td>Aiming to resolve the question whether and why...</td>\n",
       "      <td>The authors develop a spectral analysis on the...</td>\n",
       "      <td>-0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925</th>\n",
       "      <td>https://openreview.net/forum?id=HJlU-AVtvS</td>\n",
       "      <td>This paper examined the spectrum of NNGP and N...</td>\n",
       "      <td>The authors develop a spectral analysis on the...</td>\n",
       "      <td>-0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>https://openreview.net/forum?id=BkNUFjR5KQ</td>\n",
       "      <td>The authors present the interesting and import...</td>\n",
       "      <td>This paper proposes a genetic algorithm to sea...</td>\n",
       "      <td>-0.149843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>https://openreview.net/forum?id=BkNUFjR5KQ</td>\n",
       "      <td>The problem is of increasing practical interes...</td>\n",
       "      <td>This paper proposes a genetic algorithm to sea...</td>\n",
       "      <td>-0.149843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>https://openreview.net/forum?id=H1xJjlbAZ</td>\n",
       "      <td>The authors study cases where interpretation o...</td>\n",
       "      <td>The paper tries to show that many of the state...</td>\n",
       "      <td>-0.159099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>https://openreview.net/forum?id=H1xJjlbAZ</td>\n",
       "      <td>The key observation is that it is possible to ...</td>\n",
       "      <td>The paper tries to show that many of the state...</td>\n",
       "      <td>-0.159099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13845</th>\n",
       "      <td>https://openreview.net/forum?id=OOsR8BzCnl5</td>\n",
       "      <td>This paper proposes a reliable multi-view clas...</td>\n",
       "      <td>The paper introduces a new idea for multi-view...</td>\n",
       "      <td>-0.160212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13844</th>\n",
       "      <td>https://openreview.net/forum?id=OOsR8BzCnl5</td>\n",
       "      <td>This paper has proposed a novel trust-based mu...</td>\n",
       "      <td>The paper introduces a new idea for multi-view...</td>\n",
       "      <td>-0.160212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4940</th>\n",
       "      <td>https://openreview.net/forum?id=B1xewR4KvH</td>\n",
       "      <td>This paper proposed a new method called manifo...</td>\n",
       "      <td>This work explores how to leverage structure o...</td>\n",
       "      <td>-0.161141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4939</th>\n",
       "      <td>https://openreview.net/forum?id=B1xewR4KvH</td>\n",
       "      <td>The goal of the paper is clear. However, the p...</td>\n",
       "      <td>This work explores how to leverage structure o...</td>\n",
       "      <td>-0.161141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>https://openreview.net/forum?id=SylpBgrKPH</td>\n",
       "      <td>This paper introduces MissDeepCausal method to...</td>\n",
       "      <td>This paper addresses the problem of causal inf...</td>\n",
       "      <td>-0.171242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4647</th>\n",
       "      <td>https://openreview.net/forum?id=SylpBgrKPH</td>\n",
       "      <td>This contribution considers deep latent-factor...</td>\n",
       "      <td>This paper addresses the problem of causal inf...</td>\n",
       "      <td>-0.171242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862</th>\n",
       "      <td>https://openreview.net/forum?id=r1V0m3C5YQ</td>\n",
       "      <td>Composing polyphonic music is a hard computati...</td>\n",
       "      <td>This paper proposes novel recurrent models for...</td>\n",
       "      <td>-0.178647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>https://openreview.net/forum?id=r1V0m3C5YQ</td>\n",
       "      <td>The paper is well written and presented, givin...</td>\n",
       "      <td>This paper proposes novel recurrent models for...</td>\n",
       "      <td>-0.178647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12128</th>\n",
       "      <td>https://openreview.net/forum?id=V4AVDoFtVM</td>\n",
       "      <td>Summary-----The paper proposes to learn a valu...</td>\n",
       "      <td>This paper proposes to consider value function...</td>\n",
       "      <td>-0.196691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12129</th>\n",
       "      <td>https://openreview.net/forum?id=V4AVDoFtVM</td>\n",
       "      <td>The paper conditions the value function on a r...</td>\n",
       "      <td>This paper proposes to consider value function...</td>\n",
       "      <td>-0.196691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>https://openreview.net/forum?id=rJgD2ySFDr</td>\n",
       "      <td>This paper is out of my research area. I could...</td>\n",
       "      <td>There was some support for this paper, but it ...</td>\n",
       "      <td>-0.210446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5096</th>\n",
       "      <td>https://openreview.net/forum?id=rJgD2ySFDr</td>\n",
       "      <td>This paper focuses on transmitting messages re...</td>\n",
       "      <td>There was some support for this paper, but it ...</td>\n",
       "      <td>-0.210446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854</th>\n",
       "      <td>https://openreview.net/forum?id=BJxYEsAqY7</td>\n",
       "      <td>I do not necessarily see something wrong with ...</td>\n",
       "      <td>The paper describes knowledge distillation met...</td>\n",
       "      <td>-0.211000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3855</th>\n",
       "      <td>https://openreview.net/forum?id=BJxYEsAqY7</td>\n",
       "      <td>In this paper, the authors present two methods...</td>\n",
       "      <td>The paper describes knowledge distillation met...</td>\n",
       "      <td>-0.211000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                id  \\\n",
       "5934    https://openreview.net/forum?id=Hkexw1BtDr   \n",
       "5933    https://openreview.net/forum?id=Hkexw1BtDr   \n",
       "1383     https://openreview.net/forum?id=H1OQukZ0-   \n",
       "1382     https://openreview.net/forum?id=H1OQukZ0-   \n",
       "433      https://openreview.net/forum?id=Byiy-Pqlx   \n",
       "434      https://openreview.net/forum?id=Byiy-Pqlx   \n",
       "5303    https://openreview.net/forum?id=rygixkHKDH   \n",
       "5302    https://openreview.net/forum?id=rygixkHKDH   \n",
       "14107  https://openreview.net/forum?id=lU5Rs_wCweN   \n",
       "14108  https://openreview.net/forum?id=lU5Rs_wCweN   \n",
       "5926    https://openreview.net/forum?id=HJlU-AVtvS   \n",
       "5925    https://openreview.net/forum?id=HJlU-AVtvS   \n",
       "3459    https://openreview.net/forum?id=BkNUFjR5KQ   \n",
       "3460    https://openreview.net/forum?id=BkNUFjR5KQ   \n",
       "1620     https://openreview.net/forum?id=H1xJjlbAZ   \n",
       "1619     https://openreview.net/forum?id=H1xJjlbAZ   \n",
       "13845  https://openreview.net/forum?id=OOsR8BzCnl5   \n",
       "13844  https://openreview.net/forum?id=OOsR8BzCnl5   \n",
       "4940    https://openreview.net/forum?id=B1xewR4KvH   \n",
       "4939    https://openreview.net/forum?id=B1xewR4KvH   \n",
       "4648    https://openreview.net/forum?id=SylpBgrKPH   \n",
       "4647    https://openreview.net/forum?id=SylpBgrKPH   \n",
       "3862    https://openreview.net/forum?id=r1V0m3C5YQ   \n",
       "3861    https://openreview.net/forum?id=r1V0m3C5YQ   \n",
       "12128   https://openreview.net/forum?id=V4AVDoFtVM   \n",
       "12129   https://openreview.net/forum?id=V4AVDoFtVM   \n",
       "5095    https://openreview.net/forum?id=rJgD2ySFDr   \n",
       "5096    https://openreview.net/forum?id=rJgD2ySFDr   \n",
       "3854    https://openreview.net/forum?id=BJxYEsAqY7   \n",
       "3855    https://openreview.net/forum?id=BJxYEsAqY7   \n",
       "\n",
       "                                                    text  \\\n",
       "5934   The paper introduces auto-deferring policies (...   \n",
       "5933   The paper proposes a Deep RL approach called A...   \n",
       "1383   Summary of the paper--------------------------...   \n",
       "1382   # Summary of paper--------The paper proposes a...   \n",
       "433    The Neural Turing Machine and related “externa...   \n",
       "434    *** Paper Summary ***----------------This pape...   \n",
       "5303   [Summary]-----This paper studies the problem o...   \n",
       "5302   This paper studies the dictionary learning pro...   \n",
       "14107  This work aims at accelerating pre-training by...   \n",
       "14108  Summary: This paper proposes a method for impr...   \n",
       "5926   Aiming to resolve the question whether and why...   \n",
       "5925   This paper examined the spectrum of NNGP and N...   \n",
       "3459   The authors present the interesting and import...   \n",
       "3460   The problem is of increasing practical interes...   \n",
       "1620   The authors study cases where interpretation o...   \n",
       "1619   The key observation is that it is possible to ...   \n",
       "13845  This paper proposes a reliable multi-view clas...   \n",
       "13844  This paper has proposed a novel trust-based mu...   \n",
       "4940   This paper proposed a new method called manifo...   \n",
       "4939   The goal of the paper is clear. However, the p...   \n",
       "4648   This paper introduces MissDeepCausal method to...   \n",
       "4647   This contribution considers deep latent-factor...   \n",
       "3862   Composing polyphonic music is a hard computati...   \n",
       "3861   The paper is well written and presented, givin...   \n",
       "12128  Summary-----The paper proposes to learn a valu...   \n",
       "12129  The paper conditions the value function on a r...   \n",
       "5095   This paper is out of my research area. I could...   \n",
       "5096   This paper focuses on transmitting messages re...   \n",
       "3854   I do not necessarily see something wrong with ...   \n",
       "3855   In this paper, the authors present two methods...   \n",
       "\n",
       "                                                    gold  proba_of_success  \n",
       "5934   This paper proposes a new way to formulate the...         -0.021927  \n",
       "5933   This paper proposes a new way to formulate the...         -0.021927  \n",
       "1383   This paper presents an update to the method of...         -0.051171  \n",
       "1382   This paper presents an update to the method of...         -0.051171  \n",
       "433    The paper presents a Lie-(group) access neural...         -0.058358  \n",
       "434    The paper presents a Lie-(group) access neural...         -0.058358  \n",
       "5303   This paper investigates the use non-convex opt...         -0.072678  \n",
       "5302   This paper investigates the use non-convex opt...         -0.072678  \n",
       "14107  The authors propose an approach for pre-traini...         -0.087223  \n",
       "14108  The authors propose an approach for pre-traini...         -0.087223  \n",
       "5926   The authors develop a spectral analysis on the...         -0.097561  \n",
       "5925   The authors develop a spectral analysis on the...         -0.097561  \n",
       "3459   This paper proposes a genetic algorithm to sea...         -0.149843  \n",
       "3460   This paper proposes a genetic algorithm to sea...         -0.149843  \n",
       "1620   The paper tries to show that many of the state...         -0.159099  \n",
       "1619   The paper tries to show that many of the state...         -0.159099  \n",
       "13845  The paper introduces a new idea for multi-view...         -0.160212  \n",
       "13844  The paper introduces a new idea for multi-view...         -0.160212  \n",
       "4940   This work explores how to leverage structure o...         -0.161141  \n",
       "4939   This work explores how to leverage structure o...         -0.161141  \n",
       "4648   This paper addresses the problem of causal inf...         -0.171242  \n",
       "4647   This paper addresses the problem of causal inf...         -0.171242  \n",
       "3862   This paper proposes novel recurrent models for...         -0.178647  \n",
       "3861   This paper proposes novel recurrent models for...         -0.178647  \n",
       "12128  This paper proposes to consider value function...         -0.196691  \n",
       "12129  This paper proposes to consider value function...         -0.196691  \n",
       "5095   There was some support for this paper, but it ...         -0.210446  \n",
       "5096   There was some support for this paper, but it ...         -0.210446  \n",
       "3854   The paper describes knowledge distillation met...         -0.211000  \n",
       "3855   The paper describes knowledge distillation met...         -0.211000  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cossim_res.head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
