{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alialhousseini/glimpse-mds/blob/main/NLP_main_notebook3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "collapsed": true,
        "id": "Zw-RQzb6OZXy",
        "outputId": "6cbc74a1-8497-42dc-af21-9a79f8cc320d"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEYXb3BiQ8ym",
        "outputId": "ed95c122-3f2d-410f-ac46-66ace0b8fd8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'glimpse-mds'...\n",
            "remote: Enumerating objects: 320, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 320 (delta 25), reused 40 (delta 14), pack-reused 257 (from 1)\u001b[K\n",
            "Receiving objects: 100% (320/320), 32.91 MiB | 17.53 MiB/s, done.\n",
            "Resolving deltas: 100% (175/175), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/alialhousseini/glimpse-mds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DNVb_lnRFJ2",
        "outputId": "fbeeeacb-576c-4ea5-a2b7-4f1538febbaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è¨ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:14\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg3boMnMRZZh"
      },
      "outputs": [],
      "source": [
        "# Define the path for the new environment\n",
        "env_path = '/content/glimpse_env'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3Qv0rFyRiia",
        "outputId": "7dd20743-df09-42a8-e648-299c948f98dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 23.11.0\n",
            "    latest version: 24.11.2\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /content/glimpse_env\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.10\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    bzip2-1.0.8                |       h4bc722e_7         247 KB  conda-forge\n",
            "    ca-certificates-2024.12.14 |       hbcca054_0         153 KB  conda-forge\n",
            "    ld_impl_linux-64-2.43      |       h712a8e2_2         654 KB  conda-forge\n",
            "    libgcc-14.2.0              |       h77fa898_1         829 KB  conda-forge\n",
            "    libgcc-ng-14.2.0           |       h69a702a_1          53 KB  conda-forge\n",
            "    libgomp-14.2.0             |       h77fa898_1         450 KB  conda-forge\n",
            "    liblzma-5.6.3              |       hb9d3cd8_1         109 KB  conda-forge\n",
            "    libsqlite-3.47.2           |       hee588c1_0         853 KB  conda-forge\n",
            "    libxcrypt-4.4.36           |       hd590300_1          98 KB  conda-forge\n",
            "    libzlib-1.3.1              |       hb9d3cd8_2          60 KB  conda-forge\n",
            "    ncurses-6.5                |       he02047a_1         868 KB  conda-forge\n",
            "    openssl-3.4.0              |       hb9d3cd8_0         2.8 MB  conda-forge\n",
            "    pip-24.3.1                 |     pyh8b19718_2         1.2 MB  conda-forge\n",
            "    python-3.10.16             |he725a3c_1_cpython        24.0 MB  conda-forge\n",
            "    setuptools-75.6.0          |     pyhff2d567_1         756 KB  conda-forge\n",
            "    tzdata-2024b               |       hc8b5060_0         119 KB  conda-forge\n",
            "    wheel-0.45.1               |     pyhd8ed1ab_1          61 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        33.2 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h4bc722e_7 \n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2024.12.14-hbcca054_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.43-h712a8e2_2 \n",
            "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 \n",
            "  libgcc             conda-forge/linux-64::libgcc-14.2.0-h77fa898_1 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-14.2.0-h69a702a_1 \n",
            "  libgomp            conda-forge/linux-64::libgomp-14.2.0-h77fa898_1 \n",
            "  liblzma            conda-forge/linux-64::liblzma-5.6.3-hb9d3cd8_1 \n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.47.2-hee588c1_0 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 \n",
            "  libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.5-he02047a_1 \n",
            "  openssl            conda-forge/linux-64::openssl-3.4.0-hb9d3cd8_0 \n",
            "  pip                conda-forge/noarch::pip-24.3.1-pyh8b19718_2 \n",
            "  python             conda-forge/linux-64::python-3.10.16-he725a3c_1_cpython \n",
            "  readline           conda-forge/linux-64::readline-8.2-h8228510_1 \n",
            "  setuptools         conda-forge/noarch::setuptools-75.6.0-pyhff2d567_1 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 \n",
            "  tzdata             conda-forge/noarch::tzdata-2024b-hc8b5060_0 \n",
            "  wheel              conda-forge/noarch::wheel-0.45.1-pyhd8ed1ab_1 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "python-3.10.16       | 24.0 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "openssl-3.4.0        | 2.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "pip-24.3.1           | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.47.2     | 853 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 829 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 450 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 153 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024b         | 119 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.6.3        | 109 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 61 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libzlib-1.3.1        | 60 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.16       | 24.0 MB   | :   0% 0.0006501682504795408/1 [00:00<04:00, 241.06s/it]\n",
            "openssl-3.4.0        | 2.8 MB    | :   1% 0.005558673111072358/1 [00:00<00:28, 28.34s/it]\u001b[A\n",
            "\n",
            "pip-24.3.1           | 1.2 MB    | :   1% 0.013158613334018679/1 [00:00<00:12, 12.28s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | :   2% 0.018427913610156946/1 [00:00<00:08,  8.87s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.16       | 24.0 MB   | :   9% 0.09362422806905386/1 [00:00<00:02,  2.24s/it]   \n",
            "openssl-3.4.0        | 2.8 MB    | :  67% 0.6670407733286831/1 [00:00<00:00,  3.16it/s]  \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | :   2% 0.021161069005956715/1 [00:00<00:15, 15.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.16       | 24.0 MB   | :  25% 0.24771410343270503/1 [00:00<00:00,  1.14s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | :   2% 0.024482562300978315/1 [00:00<00:13, 14.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.16       | 24.0 MB   | :  43% 0.42716054056505826/1 [00:00<00:00,  1.21it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 153 KB    | :  10% 0.10429822774495824/1 [00:00<00:03,  4.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | :   6% 0.06481448515129577/1 [00:00<00:06,  7.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024b         | 119 KB    | :  13% 0.1339065335011524/1 [00:00<00:03,  3.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.16       | 24.0 MB   | :  70% 0.7041322152693427/1 [00:00<00:00,  1.68it/s] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 61 KB     | :  26% 0.2603486358074717/1 [00:00<00:01,  2.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.6.3        | 109 KB    | :  15% 0.14742828348270526/1 [00:00<00:03,  3.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | :  16% 0.163198629386511/1 [00:00<00:03,  3.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.16       | 24.0 MB   | :  92% 0.9154368966751933/1 [00:00<00:00,  1.82it/s]\n",
            "\n",
            "pip-24.3.1           | 1.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.00it/s]                 \u001b[A\u001b[A\n",
            "\n",
            "pip-24.3.1           | 1.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.47.2     | 853 KB    | : 100% 1.0/1 [00:01<00:00,  1.04s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.47.2     | 853 KB    | : 100% 1.0/1 [00:01<00:00,  1.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "openssl-3.4.0        | 2.8 MB    | : 100% 1.0/1 [00:01<00:00,  3.16it/s]               \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | : 100% 1.0/1 [00:01<00:00,  1.36s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | : 100% 1.0/1 [00:01<00:00,  1.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | : 100% 1.0/1 [00:01<00:00,  1.84s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | : 100% 1.0/1 [00:01<00:00,  1.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 829 KB    | : 100% 1.0/1 [00:02<00:00,  1.97s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 829 KB    | : 100% 1.0/1 [00:02<00:00,  1.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 450 KB    | : 100% 1.0/1 [00:02<00:00,  2.04s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 450 KB    | : 100% 1.0/1 [00:02<00:00,  2.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 153 KB    | : 100% 1.0/1 [00:02<00:00,  2.10s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 153 KB    | : 100% 1.0/1 [00:02<00:00,  2.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | : 100% 1.0/1 [00:02<00:00,  2.13s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | : 100% 1.0/1 [00:02<00:00,  2.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | : 100% 1.0/1 [00:02<00:00,  2.34s/it]                 \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | : 100% 1.0/1 [00:02<00:00,  2.34s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libzlib-1.3.1        | 60 KB     | : 100% 1.0/1 [00:02<00:00,  2.42s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libzlib-1.3.1        | 60 KB     | : 100% 1.0/1 [00:02<00:00,  2.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 61 KB     | : 100% 1.0/1 [00:02<00:00,  2.47s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 61 KB     | : 100% 1.0/1 [00:02<00:00,  2.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.6.3        | 109 KB    | : 100% 1.0/1 [00:02<00:00,  2.41s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.6.3        | 109 KB    | : 100% 1.0/1 [00:02<00:00,  2.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | : 100% 1.0/1 [00:02<00:00,  2.44s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | : 100% 1.0/1 [00:02<00:00,  2.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-14.2.0     | 53 KB     | : 100% 1.0/1 [00:02<00:00,  2.63s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-14.2.0     | 53 KB     | : 100% 1.0/1 [00:02<00:00,  2.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024b         | 119 KB    | : 100% 1.0/1 [00:02<00:00,  2.66s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: | \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate /content/glimpse_env\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the Conda environment in the specified folder\n",
        "!conda create --prefix \"$env_path\" python=3.11.8 -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_Cq1BZpRp0O"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!source activate /content/glimpse_env && pip install -r /content/glimpse-mds/requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jskW2ZoW3NH1"
      },
      "source": [
        "________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-IBiaXV3NH2"
      },
      "source": [
        "# 1. Extension 1: Use an ensemble set of models for producing RSA scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lQ6OPoo3NH2"
      },
      "source": [
        "| **Model**           | **Small Definition**                                                                                                         | **Model Ability and Performance**                                                                   | **Why Choose This**                                                                                       | **Purpose**                                                                                      |\n",
        "|----------------------|-----------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|\n",
        "| **BART**            | A transformer model optimized for sequence-to-sequence tasks like summarization and translation.                           | Focuses on fluency and readability with strong abstractive summarization capabilities.              | Pretrained on a diverse dataset, excels in generating coherent and fluent summaries.                      | Abstractive summarization and text generation tasks.                                            |\n",
        "| **PEGASUS**         | A transformer model designed for summarization with gap-sentence generation pretraining.                                    | Excels at abstractive summarization and capturing document essence.                                 | Strong performance on summarization benchmarks like CNN/DailyMail and XSum.                               | Creating concise and coherent abstractive summaries.                                            |\n",
        "| **T5**              | A unified text-to-text transformer model capable of handling multiple NLP tasks.                                            | Balances fluency, factual consistency, and flexibility across tasks.                                | Suitable for multitask setups with state-of-the-art results on summarization and NLI.                     | Summarization, translation, and text classification.                                            |\n",
        "| **LED**             | A long-context version of BART tailored for summarizing long documents.                                                     | Processes up to 16,384 tokens, maintaining coherence and relevance over long contexts.              | Handles lengthy academic or technical documents effectively.                                              | Summarization of research papers, reports, and other long-form texts.                          |\n",
        "| **BigBird-Pegasus** | A sparse-attention model designed for efficient processing of long documents.                                               | Balances computational efficiency with performance on long-form summarization tasks.                | Efficiently handles long contexts while preserving critical information.                                  | Summarization and classification for long texts.                                                |\n",
        "| **PEGASUS (XSUM)**  | A PEGASUS model fine-tuned specifically on the XSum dataset for abstractive summarization.                                  | Produces highly concise summaries but can sometimes lose factual consistency.                       | Ideal for tasks requiring short, highly abstractive summaries.                                            | Summarizing news articles or brief documents.                                                   |\n",
        "| **DistilBART**      | A distilled version of BART with faster inference and smaller size.                                                         | Slightly reduced fluency compared to BART but much faster and more efficient.                       | Useful for scenarios with computational constraints.                                                      | Quick summarization and inference on resource-limited systems.                                 |\n",
        "| **mBART**           | A multilingual version of BART pre-trained on multiple languages.                                                           | Handles cross-lingual summarization and translation tasks effectively.                              | Ideal for multilingual datasets and scenarios involving diverse languages.                                | Summarization and translation for non-English or multilingual texts.                           |\n",
        "| **Flan-T5**         | A fine-tuned version of T5 for enhanced task performance, including summarization and reasoning.                            | Improves generalization and performance across multiple NLP tasks.                                  | Great for zero-shot and few-shot setups, with excellent task-specific adaptation.                         | Summarization, classification, and text reasoning.                                              |\n",
        "| **BERTSUM**         | A fine-tuned BERT model for extractive summarization tasks.                                                                 | Excels at identifying and extracting key sentences from texts.                                      | Reliable for extracting main points without paraphrasing.                                                 | Extractive summarization of structured documents.                                               |\n",
        "| **FactPEGASUS**     | A fine-tuned PEGASUS model for ensuring factual consistency in summaries.                                                    | Focuses on generating factually accurate abstractive summaries.                                     | Essential for tasks where factual correctness is critical.                                                | Summarization for sensitive or factual information.                                             |\n",
        "| **CTRLsumm**        | A fine-tuned model designed for conversational summarization.                                                               | Captures conversational nuances and preserves dialogue structure in summaries.                      | Ideal for summarizing meetings, chats, or interview transcripts.                                          | Summarization of conversational or dialogue-based content.                                      |\n",
        "| **SciBERT**         | A BERT model trained on scientific literature.                                                                              | Captures domain-specific vocabulary and syntax effectively.                                         | Tailored for summarizing or analyzing scholarly articles and scientific texts.                            | Text summarization, classification, and entity recognition in scientific domains.               |\n",
        "| **ALL-MPNET**       | A sentence transformer optimized for semantic similarity tasks.                                                              | Measures semantic similarity with high accuracy.                                                    | Ideal for evaluating consistency between source text and summaries.                                       | Consistency checking and similarity analysis.                                                   |\n",
        "| **XLM-ROBERTA**     | A multilingual transformer model with strong cross-lingual understanding capabilities.                                       | Excels in multilingual understanding and summarization tasks.                                       | Suitable for multilingual datasets or cross-lingual consistency evaluation.                               | Multilingual summarization and text classification.                                             |\n",
        "| **LongFormer-LARGE**| A transformer optimized for handling long contexts efficiently using sparse attention.                                       | Processes long documents with improved computational efficiency and accuracy.                       | Handles dense academic or technical texts requiring long-form attention.                                  | Summarization and question answering for long-form texts.                                       |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8CRIj3USAL3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lRHvP9tp3NH3"
      },
      "outputs": [],
      "source": [
        "def consensus_scores_based_summaries(sample, n_consensus=3, n_dissensus=3):\n",
        "    consensus_samples = sample['consensuality_scores'].sort_values(ascending=True).head(n_consensus).index.tolist()\n",
        "    disensus_samples = sample['consensuality_scores'].sort_values(ascending=False).head(n_dissensus).index.tolist()\n",
        "\n",
        "    consensus = \".\".join(consensus_samples)\n",
        "    disensus = \".\".join(disensus_samples)\n",
        "\n",
        "    return consensus + \"\\n\\n\" + disensus\n",
        "\n",
        "\n",
        "def rsa_scores_based_summaries(sample, n_consensus=3, n_rsa_speaker=3):\n",
        "    consensus_samples = sample['consensuality_scores'].sort_values(ascending=True).head(n_consensus).index.tolist()\n",
        "    rsa = sample['best_rsa'].tolist()[:n_rsa_speaker]\n",
        "\n",
        "    consensus = \".\".join(consensus_samples)\n",
        "    rsa = \".\".join(rsa)\n",
        "\n",
        "    return consensus + \"\\n\\n\" + rsa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd glimpse-mds/"
      ],
      "metadata": {
        "id": "AEGoAql24tQf",
        "outputId": "4acca4aa-2cd7-4956-eed2-89c217715463",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/glimpse-mds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now path is fixed"
      ],
      "metadata": {
        "id": "k5kHN27h5GVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "from pathlib import Path\n",
        "test = Path('data/all_reviews_2017.csv')\n",
        "test.is_file()"
      ],
      "metadata": {
        "id": "X4a1uToW5JrI",
        "outputId": "93c0355d-a361-4d71-a849-462ab086ee5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install datasets\n",
        "!pip install tqdm\n",
        "!pip install transformers\n",
        "!pip install nltk\n",
        "!pip install pickle\n",
        "!pip install numpy\n",
        "!pip install operator"
      ],
      "metadata": {
        "id": "uQjh13oS6UQS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import Dataset\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch\n",
        "from typing import List, Dict\n",
        "import nltk\n",
        "from rsasumm.rsa_reranker import RSAReranking\n",
        "import pickle\n",
        "import re\n",
        "import numpy as np\n",
        "from functools import reduce\n",
        "import operator\n",
        "import random\n",
        "import json\n",
        "import os\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "vCVqv9L95WCI",
        "outputId": "1adc3bd1-5a1a-44b6-ee3b-b1f85e8f3e3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_random_seed(seed: int):\n",
        "    random.seed(seed)  # For Python's random\n",
        "    np.random.seed(seed)  # For NumPy\n",
        "    torch.manual_seed(seed)  # For PyTorch on CPU\n",
        "    torch.cuda.manual_seed(seed)  # For PyTorch on GPU\n",
        "\n",
        "\n",
        "set_random_seed(42)"
      ],
      "metadata": {
        "id": "x5yDtkIn5i9f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9znrPfI3NH8"
      },
      "outputs": [],
      "source": [
        "\n",
        "class SummaryGenerator:\n",
        "\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "    def __init__(self, model_name: str = 'BART', model=model, tokenizer=tokenizer, device=\"cuda\"):\n",
        "        self.model_name = model_name\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "        self.generation_config = {\n",
        "            \"max_new_tokens\": 200,\n",
        "            \"do_sample\": True,\n",
        "            \"top_p\": 0.95,\n",
        "            \"temperature\": 1.0,\n",
        "            \"num_return_sequences\": 8,\n",
        "            \"num_beams\": 1,\n",
        "            \"early_stopping\": True,\n",
        "            \"min_length\": 0,\n",
        "        }\n",
        "\n",
        "    def evaluate_summarizer(self, dataset_path: Path, batch_size: int, trimming: bool, checkpoint_path: str) -> Dataset:\n",
        "        \"\"\"\n",
        "        @param model: The model used to generate the summaries\n",
        "        @param tokenizer: The tokenizer used to tokenize the text and the summary\n",
        "        @param dataset: A dataset with the text\n",
        "        @param decoding_config: Dictionary with the decoding config\n",
        "        @param batch_size: The batch size used to generate the summaries\n",
        "        @return: The same dataset with the summaries added\n",
        "        \"\"\"\n",
        "        try:\n",
        "            dataset = pd.read_csv(dataset_path)\n",
        "        except:\n",
        "            raise ValueError(f\"Unknown dataset {dataset_path}\")\n",
        "\n",
        "        # make a dataset from the dataframe\n",
        "        dataset = Dataset.from_pandas(dataset)\n",
        "\n",
        "        # create a dataloader\n",
        "        dataloader = DataLoader(\n",
        "            dataset, batch_size=batch_size, shuffle=False, drop_last=trimming)\n",
        "\n",
        "        # Checkpoint file to save progress\n",
        "        if os.path.exists(checkpoint_path):\n",
        "            with open(checkpoint_path, \"r\") as f:\n",
        "                checkpoint = json.load(f)\n",
        "        else:\n",
        "            checkpoint = {\"processed_batches\": 0, \"summaries\": []}\n",
        "\n",
        "        summaries = checkpoint[\"summaries\"]\n",
        "        print(\"Generating summaries...\")\n",
        "\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        for batch_idx, batch in enumerate(tqdm(dataloader)):\n",
        "            # Skip already processed batches\n",
        "            if batch_idx < checkpoint[\"processed_batches\"]:\n",
        "                continue\n",
        "\n",
        "            text = batch[\"text\"]\n",
        "\n",
        "            inputs = self.tokenizer(\n",
        "                text,\n",
        "                max_length=min(self.tokenizer.model_max_length,\n",
        "                               768),  # Adjust max_length\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "            # move inputs to device\n",
        "            inputs = {key: value.to(self.device)\n",
        "                      for key, value in inputs.items()}\n",
        "\n",
        "            # generate summaries\n",
        "            try:\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    outputs = self.model.generate(\n",
        "                        **inputs, **self.generation_config)\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Error during generation: {e}\")\n",
        "                print(f\"Input shape: {inputs['input_ids'].shape}\")\n",
        "                # Save progress before raising an error\n",
        "                checkpoint[\"processed_batches\"] = batch_idx\n",
        "                checkpoint[\"summaries\"] = summaries\n",
        "                with open(checkpoint_path, \"w\") as f:\n",
        "                    json.dump(checkpoint, f)\n",
        "                raise\n",
        "\n",
        "            total_size = outputs.numel()  # Total number of elements in the tensor\n",
        "            # Target size of the last dimension\n",
        "            target_size = batch_size * outputs.shape[-1]\n",
        "            # Calculate the required padding size to make the total number of elements divisible by the target size\n",
        "            pad_size = (target_size - (total_size % target_size)) % target_size\n",
        "\n",
        "            # Pad the tensor with zeros to make the total number of elements divisible by the target size\n",
        "            if not trimming and pad_size != 0:\n",
        "                outputs = torch.nn.functional.pad(\n",
        "                    outputs, (0, 0, 0, pad_size // outputs.shape[-1]))\n",
        "\n",
        "            # output : (batch_size * num_return_sequences, max_length)\n",
        "            try:\n",
        "                outputs = outputs.reshape(batch_size, -1, outputs.shape[-1])\n",
        "            except Exception as e:\n",
        "                print(f\"Error reshaping outputs: {e}\")\n",
        "                raise ValueError(f\"Cannot reshape tensor of size {outputs.numel()} into shape \"\n",
        "                                 f\"({batch_size}, -1, {outputs.shape[-1]}).\")\n",
        "\n",
        "            # decode summaries\n",
        "            for b in range(batch_size):\n",
        "                summaries.append(\n",
        "                    [\n",
        "                        self.tokenizer.decode(\n",
        "                            outputs[b, i],\n",
        "                            skip_special_tokens=True,\n",
        "                        )\n",
        "                        for i in range(outputs.shape[1])\n",
        "                    ]\n",
        "                )\n",
        "\n",
        "            # Save progress after processing each batch\n",
        "            checkpoint[\"processed_batches\"] = batch_idx + 1\n",
        "            checkpoint[\"summaries\"] = summaries\n",
        "            with open(checkpoint_path, \"w\") as f:\n",
        "                json.dump(checkpoint, f)\n",
        "\n",
        "            # if trimming the last batch, remove them from the dataset\n",
        "            if trimming:\n",
        "                dataset = dataset.select(range(len(summaries)))\n",
        "\n",
        "        # add summaries to the huggingface dataset\n",
        "        dataset = dataset.map(lambda example: {\"summary\": summaries.pop(0)})\n",
        "\n",
        "        # Clean up the checkpoint file after successful completion\n",
        "        if os.path.exists(checkpoint_path):\n",
        "            os.remove(checkpoint_path)\n",
        "\n",
        "        return dataset\n",
        "\n",
        "    def generate_abstractive_summary(self, dataset_path: Path, batch_size: int, trimming: bool):\n",
        "        self.tokenizer.pad_token = self.tokenizer.unk_token\n",
        "        self.tokenizer.pad_token_id = self.tokenizer.unk_token_id\n",
        "\n",
        "        dataset = self.evaluate_summarizer(\n",
        "            dataset_path, batch_size, trimming, checkpoint_path=\"summarizer_checkpoint.json\"\n",
        "        )\n",
        "\n",
        "        df_dataset = dataset.to_pandas()\n",
        "        df_dataset = df_dataset.explode('summary')\n",
        "        df_dataset = df_dataset.reset_index()\n",
        "        # add an idx with  the id of the summary for each example\n",
        "        df_dataset['id_candidate'] = df_dataset.groupby(['index']).cumcount()\n",
        "\n",
        "        output_path = Path(\n",
        "            f\"data/candidates/{self.model_name}_{dataset_path.stem}_-_abstr.csv\")\n",
        "        # create output dir if it doesn't exist\n",
        "        if not output_path.parent.exists():\n",
        "            output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        df_dataset.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
        "        print('done')\n",
        "\n",
        "    def generate_extractive_summary(self, dataset_path: Path):\n",
        "        try:\n",
        "            dataset = pd.read_csv(dataset_path)\n",
        "        except:\n",
        "            raise ValueError(f\"Unknown dataset {dataset_path}\")\n",
        "\n",
        "        # make a dataset from the dataframe\n",
        "        dataset = Dataset.from_pandas(dataset)\n",
        "\n",
        "        summaries = []\n",
        "\n",
        "        # (tqdm library for progress bar)\n",
        "        for sample in tqdm(dataset):\n",
        "            text = sample[\"text\"]\n",
        "\n",
        "            # Replace any set of successive dashes (e.g., --, ----, -----) with a newline\n",
        "            text = re.sub(r'-{2,}', '\\n', text)\n",
        "\n",
        "            # Remove patterns like \".2-\" or isolated numerics with hyphens\n",
        "            text = re.sub(r'\\.\\d+-', '', text)\n",
        "\n",
        "            # Replace multiple newlines or spaces with a single newline or space\n",
        "            # Replace multiple newlines with one\n",
        "            text = re.sub(r'\\n+', '\\n', text)\n",
        "            # Replace multiple spaces with one\n",
        "            text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "            # Remove any remaining unwanted characters (e.g., control characters)\n",
        "            # Remove non-ASCII characters\n",
        "            text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
        "\n",
        "            # To be discussed\n",
        "            text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "            sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "            # remove empty sentences\n",
        "            sentences = [sentence for sentence in sentences if sentence != \"\"]\n",
        "\n",
        "            # Filter out short or meaningless sentences\n",
        "            sentences = [sent for sent in sentences if len(sent) > 8]\n",
        "\n",
        "            summaries.append(sentences)\n",
        "\n",
        "        # add summaries to the huggingface dataset\n",
        "        dataset = dataset.map(lambda example: {\"summary\": summaries.pop(0)})\n",
        "\n",
        "        df_dataset = dataset.to_pandas()\n",
        "        df_dataset = df_dataset.explode(\"summary\")\n",
        "        df_dataset = df_dataset.reset_index()\n",
        "        # add an idx with  the id of the summary for each example\n",
        "        df_dataset[\"id_candidate\"] = df_dataset.groupby([\"index\"]).cumcount()\n",
        "\n",
        "        output_path = f\"data/candidates/{dataset_path.stem}_-_extr.csv\"\n",
        "        output_path = Path(output_path)\n",
        "        # create output dir if it doesn't exist\n",
        "        if not output_path.parent.exists():\n",
        "            output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        df_dataset.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
        "        print('done')\n",
        "\n",
        "    def change_model(self, model_name, model, tokenizer):\n",
        "        self.model_name = model_name\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_for_likelihood_computation = {\n",
        "    'model_1':\n",
        "        {\n",
        "            'model_id': \"facebook/bart-large-cnn\",\n",
        "            'model_name': \"BART\"\n",
        "        },\n",
        "    'model_2':\n",
        "        {\n",
        "            'model_id': \"Falconsai/text_summarization\",\n",
        "            'model_name': \"Falcon\"\n",
        "        },\n",
        "    'model_3':\n",
        "        {\n",
        "            'model_id': \"google/pegasus-xsum\",\n",
        "            'model_name': \"PEGASUS-XSUM\"\n",
        "        },\n",
        "    'model_4':\n",
        "        {\n",
        "            'model_id': \"google/bigbird-pegasus-large-arxiv\",\n",
        "            'model_name': \"PEGASUS-BigBird-Arxiv\"\n",
        "        },\n",
        "    'model_5':\n",
        "        {\n",
        "            'model_id': \"google/pegasus-arxiv\",\n",
        "            'model_name': \"PEGASUS-Arxiv\"\n",
        "        }\n",
        "}\n",
        "\n",
        "path_candidates = Path(\"data/candidates\")\n",
        "\n",
        "for model_count, model_info in model_for_likelihood_computation.items():\n",
        "    # Load the model and tokenizer\n",
        "    model_id = model_info['model_id']\n",
        "    model_name = model_info['model_name']\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "    for file in path_candidates.glob('*.csv'):\n",
        "        # For each dataset we want to do the following\n",
        "        # Extract LM_probas for each dataframe\n",
        "        # Save them in a pkl file for each 'paper' (id)\n",
        "        # Save the pkl files in a folder named after the dataset and the model used\n",
        "\n",
        "        results = []\n",
        "        curr_ds = pd.read_csv(file)\n",
        "\n",
        "        # Name is a tuple e.g. ('id_name',)\n",
        "        # group is a GroupedByKey DataFrame\n",
        "\n",
        "        for name, group in tqdm(curr_ds.groupby([\"id\"])):\n",
        "\n",
        "            rsa_reranker = RSAReranking(\n",
        "                model,  # model on which we want to compute the RSA\n",
        "                tokenizer,  # tokenizer for the model\n",
        "                device='cuda',\n",
        "                candidates=group.summary.unique().tolist(),\n",
        "                source_texts=group.text.unique().tolist(),\n",
        "                batch_size=16,\n",
        "                rationality=1,\n",
        "            )\n",
        "            # print(len(group.summary.unique().tolist()))\n",
        "            # print(len(group.text.unique().tolist()))\n",
        "            lm_probas = rsa_reranker.likelihood_matrix()\n",
        "            # print(lm_probas.shape)\n",
        "            lm_probas = lm_probas.cpu().numpy()\n",
        "            lm_probas_df = pd.DataFrame(lm_probas)\n",
        "            lm_probas_df.index = group.text.unique().tolist()\n",
        "            lm_probas_df.columns = group.summary.unique().tolist()\n",
        "            gold = group['gold'].tolist()[0]\n",
        "\n",
        "            results.append(\n",
        "                {\n",
        "                    \"id\": name,\n",
        "                    \"language_model_proba_df\": lm_probas_df,\n",
        "                    \"gold\": gold,\n",
        "                    \"rationality\": 1,  # hyperparameter\n",
        "                    \"text_candidates\": group\n",
        "                }\n",
        "            )\n",
        "\n",
        "        # Save the results\n",
        "        opt_dir = Path(f'data/lm_probas/')\n",
        "        if not opt_dir.exists():\n",
        "            opt_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        opt_path = Path(f\"data/lm_probas/{file.stem}-_-{model_name}.pkl\")\n",
        "        results = {\"results\": results}\n",
        "        with open(opt_path, 'wb') as f:\n",
        "            pickle.dump(results, f)\n",
        "    print(f'{file} is done')\n",
        "\n",
        "print('ALL DONE :)')\n"
      ],
      "metadata": {
        "id": "YeWOOUGs57bs",
        "outputId": "3a5168fd-b1a9-4ab6-b280-e07ef6171a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "6bee46fe7bfc441f82955ff273a2936a",
            "ea7481f355fa4822bd2c967ed3da6bbb",
            "beed573edde84babbf821932d63835d5",
            "5763bd74ad764f42b65805db97108a96",
            "e5d4d31077314ce6881c69462ea99291",
            "498ce3b93a8945f198de2dd0f579d16d",
            "1c6274b4529541d89978549e0e63feb5",
            "875067ab7ddc4264b5d151b0ed808de4",
            "25c2cc560a634bfe8b4a89244b12a255",
            "219b4a0131b84520b83a23e626943d56",
            "87a35a723503461dab05100a48655b88",
            "38054de2130e4d61a095f201838b8d68",
            "8cfc795c380d49d195a2bc60bad15cad",
            "3f2b147784784796842f4ff90441b058",
            "5deef09776194ccb9a2be90e0c9e4aaf",
            "8a0d884c14fe4adc9be00be1f462d8cc",
            "714be870bc85433bab02f416d6458970",
            "e7ccd240e04c40caa250e1a6a7f3ef23",
            "4175504c3d584c4cb8489d2b24711266",
            "6601510c409543b9bc27643c15cf03d3",
            "44a82e96d40648698389accbf90c6484",
            "bf850f8a295f43a58328a5a87362276b",
            "d188718be3404e78a2d9125038fe97a7",
            "a8fa7311c24f4ef1bdbf77ad253b02a4",
            "5239c599a4dd4177be6fc57c335f1ed0",
            "ff2e0dc54b874b59964bde51fc12beaf",
            "d65f208c799b4276acacd3747cbcc7eb",
            "ad99edef44224d73a1bbe2b3def49926",
            "f2051db728be431c99d08d6fa046d34d",
            "a1c63ab1f70d499493e73125782c9c6e",
            "e1f064b4ff7c49a1b3704935a5d40ca5",
            "82be939250294007ad7992d97e25cf44",
            "008adccbd0bd416e8748065dc8f41e2d",
            "af7a2c7ebffe4c29ba4497c186335c44",
            "de7de068051140f093e3de6ca9d778ad",
            "fff3861f5f664a1bb1a9043fdaffb556",
            "5607c5e49d1a453f9cc13a7c12231995",
            "3209261d4cdb4c63b90be9c8417ba1ac",
            "d0f5e2f4295c4498b559a79fde4e720e",
            "1447ac08e47543ab9a40bbfa26b95298",
            "32f79780dad14f139e132c12666ba3bb",
            "9772787278c5437e8e67437f0c371129",
            "dfa98006e8294e749b40d5c2ffbc5edb",
            "ccf1f6e6aed44cb48e1fd2af78272035"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bee46fe7bfc441f82955ff273a2936a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38054de2130e4d61a095f201838b8d68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d188718be3404e78a2d9125038fe97a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af7a2c7ebffe4c29ba4497c186335c44"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "########################################################################\n",
        "\n",
        "def elementwise_max(dfs):\n",
        "    \"\"\"\n",
        "    dfs: list of DataFrames (same index/columns)\n",
        "    \"\"\"\n",
        "    return reduce(lambda x, y: x.combine(y, func=max), dfs)\n",
        "\n",
        "# Now we can write a script that takes the set of LM_probas for each dataset and (set) of models\n",
        "# and aggregate them to get the final ranking\n",
        "\n",
        "# We define a set of model names, this set represents the set of models we want to aggregate their results\n",
        "# In addition we define a methodology of aggregation(e.g. mean, max, weighted_avg, etc.)\n",
        "\n",
        "model_names = [\"BART\", \"PEGASUS\"]\n",
        "\n",
        "# We need to find for each set of common datasets, the models we are looking for:\n",
        "lm_probas_path = Path(\"data/lm_probas\")\n",
        "lm_probas_files = list(lm_probas_path.glob(\"*.pkl\"))\n",
        "# Filter out the files that do not contain the models we are looking for\n",
        "# So we keep only the files that contain the models we are looking for\n",
        "lm_probas_files = [file for file in lm_probas_files if any(\n",
        "    model_name in file.stem.split('-_-')[-1] for model_name in model_names)]\n",
        "\n",
        "# Now for each file, we collect filenames together to be processed\n",
        "files_and_pickles = {}\n",
        "for file in lm_probas_files:\n",
        "    filename = file.stem.split('-_-')[0]\n",
        "    if filename not in files_and_pickles:\n",
        "        files_and_pickles[filename] = [file]\n",
        "    else:\n",
        "        files_and_pickles[filename].append(file)\n",
        "\n",
        "method = \"mean\"\n",
        "\n",
        "# Now we can aggregate the results\n",
        "# We will aggregate the results for each dataset\n",
        "for filename, files in files_and_pickles.items():\n",
        "    # We iterate over the dict\n",
        "    # filename is the name of the dataset\n",
        "    # files is a list of paths to the pkl files\n",
        "\n",
        "    # Load the results for each model\n",
        "    pkls = [pd.read_pickle(f) for f in files]\n",
        "    # Go to results\n",
        "    pkls = [f['results'] for f in pkls]\n",
        "    # Now pkls is a list of lists of dictionaries [ [{},{},{}], [{},{},{}], ...]\n",
        "    # We want to access the language_model_proba_df for each dictionary in parallel\n",
        "    # i.e. [ [{a1},{b1},{c1}], [{a2},{b2},{c2}], ...] -> [ {a_i}, {b_i}, {c_i} ]\n",
        "\n",
        "    # Results\n",
        "    results = []\n",
        "    for i in range(len(pkls[0])):  # iterate over the dictionaries\n",
        "        # index 'i' is shared\n",
        "        set_of_dicts = [pkls[j][i] for j in range(len(pkls))]\n",
        "        # set_of_dicts is a list of dictionaries that share the same index\n",
        "        # [{a1}, {a2}, {a3}, ...]\n",
        "        # Now we want to aggregate the language_model_proba_df for each dictionary\n",
        "        new_dict = {}\n",
        "        new_dict['id'] = set_of_dicts[0]['id']\n",
        "        new_dict['gold'] = set_of_dicts[0]['gold']\n",
        "        new_dict['rationality'] = set_of_dicts[0]['rationality']\n",
        "        new_dict['text_candidates'] = set_of_dicts[0]['text_candidates']\n",
        "        # Now we want to aggregate the language_model_proba_df\n",
        "        # THIS HAS TO BE DONE ACCORDING TO A METHOD (max, weighted_avg, etc.)\n",
        "        set_of_dfs = [d['language_model_proba_df'] for d in set_of_dicts]\n",
        "\n",
        "        # Additional check of consistency\n",
        "        ref_index = set_of_dfs[0].index\n",
        "        ref_columns = set_of_dfs[0].columns\n",
        "\n",
        "        for t, df in enumerate(set_of_dfs[1:], start=2):\n",
        "            # Compare sets OR compare ordered lists\n",
        "            if not df.index.equals(ref_index):\n",
        "                raise ValueError(\n",
        "                    f\"DataFrame #{i} index does not match the reference. \"\n",
        "                    f\"Expected {list(ref_index)}, got {list(df.index)}.\"\n",
        "                )\n",
        "            if not df.columns.equals(ref_columns):\n",
        "                raise ValueError(\n",
        "                    f\"DataFrame #{i} columns do not match the reference. \"\n",
        "                    f\"Expected {list(ref_columns)}, got {list(df.columns)}.\"\n",
        "                )\n",
        "\n",
        "        if method == \"mean\":\n",
        "\n",
        "            # To aggregation safely\n",
        "            df_sum = reduce(operator.add, set_of_dfs)\n",
        "            df_agg = df_sum / len(set_of_dfs)\n",
        "\n",
        "        if method == \"max\":\n",
        "            df_agg = elementwise_max(set_of_dfs)\n",
        "\n",
        "        # Save it!\n",
        "        new_dict['language_model_proba_df'] = df_agg\n",
        "\n",
        "        # Save model names used as well\n",
        "        new_dict['model_names'] = model_names\n",
        "\n",
        "        results.append(new_dict)\n",
        "\n",
        "    results = {\"results\": results}\n",
        "    # Save the results\n",
        "    opt_dir = Path(f'data/agg_lms/')\n",
        "    if not opt_dir.exists():\n",
        "        opt_dir.mkdir(parents=True, exist_ok=True)\n",
        "    opt_path = Path(f\"data/agg_lms/{filename}.pkl\")\n",
        "    with open(opt_path, 'wb') as f:\n",
        "        pickle.dump(results, f)\n",
        "########################################################################\n"
      ],
      "metadata": {
        "id": "718F4AYU6Dpc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6bee46fe7bfc441f82955ff273a2936a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea7481f355fa4822bd2c967ed3da6bbb",
              "IPY_MODEL_beed573edde84babbf821932d63835d5",
              "IPY_MODEL_5763bd74ad764f42b65805db97108a96"
            ],
            "layout": "IPY_MODEL_e5d4d31077314ce6881c69462ea99291"
          }
        },
        "ea7481f355fa4822bd2c967ed3da6bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_498ce3b93a8945f198de2dd0f579d16d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1c6274b4529541d89978549e0e63feb5",
            "value": "config.json:‚Äá100%"
          }
        },
        "beed573edde84babbf821932d63835d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_875067ab7ddc4264b5d151b0ed808de4",
            "max": 1585,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25c2cc560a634bfe8b4a89244b12a255",
            "value": 1585
          }
        },
        "5763bd74ad764f42b65805db97108a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_219b4a0131b84520b83a23e626943d56",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_87a35a723503461dab05100a48655b88",
            "value": "‚Äá1.58k/1.58k‚Äá[00:00&lt;00:00,‚Äá125kB/s]"
          }
        },
        "e5d4d31077314ce6881c69462ea99291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "498ce3b93a8945f198de2dd0f579d16d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6274b4529541d89978549e0e63feb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "875067ab7ddc4264b5d151b0ed808de4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25c2cc560a634bfe8b4a89244b12a255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "219b4a0131b84520b83a23e626943d56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a35a723503461dab05100a48655b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38054de2130e4d61a095f201838b8d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cfc795c380d49d195a2bc60bad15cad",
              "IPY_MODEL_3f2b147784784796842f4ff90441b058",
              "IPY_MODEL_5deef09776194ccb9a2be90e0c9e4aaf"
            ],
            "layout": "IPY_MODEL_8a0d884c14fe4adc9be00be1f462d8cc"
          }
        },
        "8cfc795c380d49d195a2bc60bad15cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_714be870bc85433bab02f416d6458970",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e7ccd240e04c40caa250e1a6a7f3ef23",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "3f2b147784784796842f4ff90441b058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4175504c3d584c4cb8489d2b24711266",
            "max": 1625222120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6601510c409543b9bc27643c15cf03d3",
            "value": 1625222120
          }
        },
        "5deef09776194ccb9a2be90e0c9e4aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44a82e96d40648698389accbf90c6484",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bf850f8a295f43a58328a5a87362276b",
            "value": "‚Äá1.63G/1.63G‚Äá[00:11&lt;00:00,‚Äá146MB/s]"
          }
        },
        "8a0d884c14fe4adc9be00be1f462d8cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "714be870bc85433bab02f416d6458970": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7ccd240e04c40caa250e1a6a7f3ef23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4175504c3d584c4cb8489d2b24711266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6601510c409543b9bc27643c15cf03d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44a82e96d40648698389accbf90c6484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf850f8a295f43a58328a5a87362276b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d188718be3404e78a2d9125038fe97a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8fa7311c24f4ef1bdbf77ad253b02a4",
              "IPY_MODEL_5239c599a4dd4177be6fc57c335f1ed0",
              "IPY_MODEL_ff2e0dc54b874b59964bde51fc12beaf"
            ],
            "layout": "IPY_MODEL_d65f208c799b4276acacd3747cbcc7eb"
          }
        },
        "a8fa7311c24f4ef1bdbf77ad253b02a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad99edef44224d73a1bbe2b3def49926",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f2051db728be431c99d08d6fa046d34d",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "5239c599a4dd4177be6fc57c335f1ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1c63ab1f70d499493e73125782c9c6e",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1f064b4ff7c49a1b3704935a5d40ca5",
            "value": 363
          }
        },
        "ff2e0dc54b874b59964bde51fc12beaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82be939250294007ad7992d97e25cf44",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_008adccbd0bd416e8748065dc8f41e2d",
            "value": "‚Äá363/363‚Äá[00:00&lt;00:00,‚Äá31.5kB/s]"
          }
        },
        "d65f208c799b4276acacd3747cbcc7eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad99edef44224d73a1bbe2b3def49926": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2051db728be431c99d08d6fa046d34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1c63ab1f70d499493e73125782c9c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1f064b4ff7c49a1b3704935a5d40ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82be939250294007ad7992d97e25cf44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008adccbd0bd416e8748065dc8f41e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af7a2c7ebffe4c29ba4497c186335c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de7de068051140f093e3de6ca9d778ad",
              "IPY_MODEL_fff3861f5f664a1bb1a9043fdaffb556",
              "IPY_MODEL_5607c5e49d1a453f9cc13a7c12231995"
            ],
            "layout": "IPY_MODEL_3209261d4cdb4c63b90be9c8417ba1ac"
          }
        },
        "de7de068051140f093e3de6ca9d778ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0f5e2f4295c4498b559a79fde4e720e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1447ac08e47543ab9a40bbfa26b95298",
            "value": "vocab.json:‚Äá100%"
          }
        },
        "fff3861f5f664a1bb1a9043fdaffb556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32f79780dad14f139e132c12666ba3bb",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9772787278c5437e8e67437f0c371129",
            "value": 898823
          }
        },
        "5607c5e49d1a453f9cc13a7c12231995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfa98006e8294e749b40d5c2ffbc5edb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ccf1f6e6aed44cb48e1fd2af78272035",
            "value": "‚Äá899k/899k‚Äá[00:00&lt;00:00,‚Äá5.83MB/s]"
          }
        },
        "3209261d4cdb4c63b90be9c8417ba1ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0f5e2f4295c4498b559a79fde4e720e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1447ac08e47543ab9a40bbfa26b95298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32f79780dad14f139e132c12666ba3bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9772787278c5437e8e67437f0c371129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfa98006e8294e749b40d5c2ffbc5edb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccf1f6e6aed44cb48e1fd2af78272035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}