Id,summary,text,gold
"('https://openreview.net/forum?id=B12Js_yRb',)","-Pros:
---1..---- The proposed algorithm doesn’t handle symmetry breaking when two edges are equally confident (in 4.2.2 it basically scales down both edges)..--- - The proposed model can be easily applied to any VQA model using soft attention.

-Contribution:
---- This paper proposes a new object counting module which operates on a graph of object proposals..Also, key experiments are missing: 1) NMS baseline 2) Comparison with VQA counting work  (Chattopadhyay et al., 2017)..-[1] Kulesza, Alex, and Ben Taskar.","Summary: --------- This paper proposes a hand-designed network architecture on a graph of object proposals to perform soft non-maximum suppression to get object count.----------------Contribution:--------- This paper proposes a new object counting module which operates on a graph of object proposals.----------------Clarity:--------- The paper is well written and clarity is good. Figure 2 & 3 helps the readers understand the core algorithm.----------------Pros:--------- De-duplication modules of inter and intra object edges are interesting.--------- The proposed method improves the baseline by 5% on counting questions.----------------Cons:--------- The proposed model is pretty hand-crafted. I would recommend the authors to use something more general, like graph convolutional neural networks (Kipf & Welling, 2017) or graph gated neural networks (Li et al., 2016).--------- One major bottleneck of the model is that the proposals are not jointly finetuned. So if the proposals are missing a single object, this cannot really be counted. In short, if the proposals don’t have 100% recall, then the model is then trained with a biased loss function which asks it to count all the objects even if some are already missing from the proposals. The paper didn’t study what is the recall of the proposals and how sensitive the threshold is.--------- The paper doesn’t study a simple baseline that just does NMS on the proposal domain.--------- The paper doesn’t compare experiment numbers with (Chattopadhyay et al., 2017).--------- The proposed algorithm doesn’t handle symmetry breaking when two edges are equally confident (in 4.2.2 it basically scales down both edges). This is similar to a density map approach and the problem is that the model doesn’t develop a notion of instance.--------- Compared to (Zhou et al., 2017), the proposed model does not improve much on the counting questions.--------- Since the authors have mentioned in the related work, it would also be more convincing if they show experimental results on CL----------------Conclusion:--------- I feel that the motivation is good, but the proposed model is too hand-crafted. Also, key experiments are missing: 1) NMS baseline 2) Comparison with VQA counting work  (Chattopadhyay et al., 2017). Therefore I recommend reject.----------------References:--------- Kipf, T.N., Welling, M., Semi-Supervised Classification with Graph Convolutional Networks. ICLR 2017.--------- Li, Y., Tarlow, D., Brockschmidt, M., Zemel, R. Gated Graph Sequence Neural Networks. ICLR 2016.----------------Update:--------Thank you for the rebuttal. The paper is revised and I saw NMS baseline is added. I understood the reason not to compare with certain related work. The rebuttal is convincing and I decided to increase my rating, because adding the proposed counting module achieve 5% increase in counting accuracy. However, I am a little worried that the proposed model may be hard to reproduce due to its complexity and therefore choose to give a 6. This paper tackles the object counting problem in visual question answering. It is based on the two-stage method that object proposals are generated from the first stage with attention. It proposes many heuristics to use the object feature and attention weights to find the correct count.  In general, it treats all object proposals as nodes on the graph. With various agreement measures, it removes or merges edges and count the final nodes. The method is evaluated on one synthetic toy dataset and one VQA v2 benchmark dataset. The experimental results on counting are promising.  Although counting is important in VQA, the method is solving a very specific problem which cannot be generalized to other representation learning problems.  Additionally, this method is built on a series of heuristics without sound theoretically justification, and these heuristics cannot be easily adapted to other machine learning applications. I thus believe the overall contribution is not sufficient for ICLR.----------------Pros:--------1. Well written paper with clear presentation of the method. --------2. Useful for object counting problem.--------3. Experimental performance is convincing. ----------------Cons:--------1. The application range of the method is very limited. --------2. The technique is built on a lot of heuristics without theoretical consideration. ----------------Other comments and questions:----------------1. The determinantal point processes [1] should be able to help with the correct counting the objects with proper construction of the similarity kernel.  It may also lead to simpler solutions. For example, it can be used for deduplication using A (eq 1) as the similarity matrix. ----------------2. Can the author provide analysis on scalability the proposed method? When the number of objects is very large, the graph could be huge. What are the memory requirements and computational complexity of the proposed method?  --------In the end of section 3, it mentioned that ""without normalization,"" the method will not scale to an arbitrary number of objects. I think that it will only be a problem for extremely large numbers. I wonder whether the proposed method scales. ----------------3. Could the authors provide more insights on why the structured attention (etc) did not significantly improve the result? Theoritically, it solves the soft attention problems. ----------------4. The definition of output confidence (section 4.3.1) needs more motivation and theoretical justification. ----------------[1] Kulesza, Alex, and Ben Taskar. ""Determinantal point processes for machine learning."" Foundations and Trends® in Machine Learning 5.2–3 (2012): 123-286. Summary-------- - This paper mainly focuses on a counting problem in visual question answering (VQA) using attention mechanism. The authors propose a differentiable counting component, which explicitly counts the number of objects. Given attention weights and corresponding proposals, the model deduplicates overlapping proposals by eliminating intra-object edges and inter-object edges using graph representation for proposals. In experiments, the effectiveness of proposed model is clearly shown in counting questions on both a synthetic toy dataset and the widely used VQA v2 dataset.----------------Strengths-------- - The proposed model begins with reasonable motivation and shows its effectiveness in experiments clearly. -------- - The architecture of the proposed model looks natural and all components seem to have clear contribution to the model.-------- - The proposed model can be easily applied to any VQA model using soft attention. -------- - The paper is well written and the contribution is clear.----------------Weaknesses-------- - Although the proposed model is helpful to model counting information in VQA, it fails to show improvement with respect to a couple of important baselines: prediction from image representation only and from the combination of image representation and attention weights. -------- - Qualitative examples of intermediate values in counting component--adjacency matrix (A), distance matrix (D) and count matrix (C)--need to be presented to show the contribution of each part, especially in the real examples that are not compatible with the strong assumptions in modeling counting component.----------------Comments-------- - It is not clear if the value of count ""c"" is same with the final answer in counting questions. ",We have released our code at https://github.com/Cyanogenoid/vqa-counting
"('https://openreview.net/forum?id=B13njo1R-',)","Or knowing 3 is enough)..--- 
---Or is it to obtain a multitask solution while maximizing transfer (where you always have access to all tasks, but you chose to sequentilize them to improve transfer)?.-Going then to Figure 3, I almost fill that the MultiTasker might be used to simulate two separate baselines.

Is it to learn a continual learning solution?.This paper aims to learn a single policy that can perform a variety of tasks that were experienced sequentially..Hi, 


-This was a nice read.","Hi, ----------------This was a nice read. I think overall it is a good idea. But I find the paper lacking a lot of details and to some extend confusing. --------Here are a few comments that I have:----------------Figure 2 is very confusing for me. Please first of all make the figures much larger. ICLR does not have a strict page limit, and the figures you have are hard to impossible to read. So you train in (a) on the steps task until 350k steps? Is (b), (d),(c) in a sequence or is testing moving from plain to different things? The plot does not explicitly account for the distillation phase. Or at least not in an intuitive way. But if the goal is transfer, then actually PLAID is slower than the MultiTasker because it has an additional cost to pay (in frames and times) for the distillation phase right? Or is this counted. ----------------Going then to Figure 3, I almost fill that the MultiTasker might be used to simulate two separate baselines. Indeed, because the retention of tasks is done by distilling all of them jointly, one baseline is to keep finetuning a model through the 5 stages, and then at the end after collecting the 5 policies you can do a single consolidation step that compresses all. So it will be quite important to know if the frequent integration steps of PLAID are helpful (do knowing 1,2 and 3 helps you learn 4 better? Or knowing 3 is enough). ----------------Where exactly is input injection used? Is it experiments from figure 3. What input is injecting? What do you do when you go back to the task that doesn't have the input, feed 0? What happens if 0 has semantics ? ----------------Please say in the main text that details in terms of architecture and so on are given in the appendix. And do try to copy a bit more of them in the main text where reasonable. ----------------What is the role of PLAID? Is it to learn a continual learning solution? So if I have 100 tasks, do I need to do 100-way distillation at the end to consolidate all skills? Will this be feasible? Wouldn't the fact of having data from all the 100 tasks at the end contradict the traditional formulation of continual learning? -------- --------Or is it to obtain a multitask solution while maximizing transfer (where you always have access to all tasks, but you chose to sequentilize them to improve transfer)?  And even then maximize transfer with respect to what? Frames required from the environment? If that are you reusing the frames you used during training to distill? Can we afford to keep all of those frames around? If not we have to count the distillation frames as well. Also more baselines are needed. A simple baseline is just finetunning as going from one task to another, and just at the end distill all the policies found through out the way.  Or at least have a good argument of why this is suboptimal compared to PLAID. ----------------I think the idea of the paper is interesting and I'm willing to increase (and indeed decrease) my score. But I want to make sure the authors put a bit more effort into cleaning up the paper, making it more clear and easy to read. Providing at least one more baseline (if not more considering the other things cited by them).  This paper describes PLAID, a method for sequential learning and consolidation of behaviours via policy distillation; the proposed method is evaluated in the context of bipedal motor control across several terrain types, which follow a natural curriculum.----------------Pros:--------- PLAID masters several distinct tasks in sequence, building up “skills” by learning “related” tasks of increasing difficulty.--------- Although the main focus of this paper is on continual learning of “related” tasks, the authors acknowledge this limitation and convincingly argue for the chosen task domain.----------------Cons:--------- PLAID seems designed to work with task curricula, or sequences of deeply related tasks; for this regime, classical transfer learning approaches are known to work well (e.g finetunning), and it is not clear whether the method is applicable beyond this well understood case.--------- Are the experiments single runs? Due to the high amount of variance in single RL experiments it is recommended to perform several re-runs and argue about mean behaviour.----------------Clarifications:--------- What is the zero-shot performance of policies learned on the first few tasks, when tested directly on subsequent tasks?--------- How were the network architecture and network size chosen, especially for the multitasker? Would policies generalize to later tasks better with larger, or smaller networks?--------- Was any kind of regularization used, how does it influence task performance vs. transfer?--------- I find figure 1 (c) somewhat confusing. Is performance maintained only on the last 2 tasks, or all previously seen tasks? That’s what the figure suggests at first glance, but that’s a different goal compared to the learning strategies described in figures 1 (a) and (b). This paper aims to learn a single policy that can perform a variety of tasks that were experienced sequentially. The approach is to learn a policy for task 1, then for each task k+1: copy distilled policy that can perform tasks 1-k, finetune to task k+1, and distill again with the additional task. The results show that this PLAID algorithm outperforms a network trained on all tasks simultaneously. ----------------Questions:--------- When distilling the policies, do you start from a randomly initialized policy, or do you start from the expert policy network?--------- What data do you use for the distillation? Section 4.1 states""We use a method similar to the DAGGER algorithm"", but what is your method. If you generate trajectories form the student network, and label them with the expert actions, does that mean all previous expert policies need to be kept in memory?--------- I do not understand the purpose of ""input injection"" nor where it is used in the paper. ----------------Strengths:--------- The method is simple but novel. The results support the method's utility.--------- The testbed is nice; the tasks seem significantly different from each other. It seems that no reward shaping is used.--------- Figure 3 is helpful for understanding the advantage of PLAID vs MultiTasker.----------------Weaknesses:--------- Figure 2: the plots are too small.--------- Distilling may hurt performance ( Figure 2.d)--------- The method lacks details (see Questions above)--------- No comparisons with prior work are provided. The paper cites many previous approaches to this but does not compare against any of them. --------- A second testbed (such as navigation or manipulation) would bring the paper up a notch. ----------------In conclusion, the paper's approach to multitask learning is a clever combination of prior work. The method is clear but not precisely described. The results are promising. I think that this is a good approach to the problem that could be used in real-world scenarios. With some filling out, this could be a great paper.","The authors propose an architecture that uses a curriculum and multi-task distillation to gain higher performance without forgetting. The paper is largely a smart composition of known methods, and it requires keeping data from all tasks to do the distillation, so it is not truly a scalable continual learning approach. There were a lot of concerns about clarity in the manuscript, but many of these have been assuaged by an update to the paper. This is a borderline paper, but the author's rebuttal and update probably tip it towards acceptance. "
"('https://openreview.net/forum?id=B14TlG-RW',)","-Secondly, none of the above three ideas are well evaluated in terms of both speedup and RC performance, and I will comment in details as follows:


-(1) The CNN+self-attention was mainly borrowing the idea from (Vaswani et al., 2017a) from NMT to RC..---- what do ‘data aug’ x 2 or x 3 exactly mean?.-Firstly, I suggest the authors rewrite the end of the introduction.

Summary:


-This paper proposes a non-recurrent model for reading comprehension which used only convolutions and attention..-(2) I feel that the model design is the main reason for the good overall RC performance..But it turns out that the above improvements are achieved with at least three different ideas: (1) the CNN+self-attention module; (2) the entire model architecture design; and (3) the data augmentation method.","Summary:----------------This paper proposes a non-recurrent model for reading comprehension which used only convolutions and attention. The goal is to avoid recurrent which is sequential and hence a bottleneck during both training and inference. Authors also propose a paraphrasing based data augmentation method which helps in improving the performance. Proposed method performs better than existing models in SQuAD dataset while being much faster in training and inference.----------------My Comments:----------------The proposed model is convincing and the paper is well written.----------------1. Why don’t you report your model performance without data augmentation in Table 1? Is it because it does not achieve SOTA? The proposed data augmentation is a general one and it can be used to improve the performance of other models as well. So it does not make sense to compare your model + data augmentation against other models without data augmentation. I think it is ok to have some deterioration in the performance as you have a good speedup when compared to other models.----------------2. Can you mention your leaderboard test accuracy in the rebuttal?----------------3. The paper can be significantly strengthened by adding at least one more reading comprehension dataset. That will show the generality of the proposed architecture. Given the sufficient time for rebuttal, I am willing to increase my score if authors report results in an additional dataset in the revision.----------------4. Are you willing to release your code to reproduce the results?------------------------Minor comments:----------------1. You mention 4X to 9X for inference speedup in abstract and then 4X to 10X speedup in Intro. Please be consistent.--------2. In the first contribution bullet point, “that exclusive built upon” should be “that is exclusively built upon”. This paper presents a reading comprehension model using convolutions and attention. This model does not use any recurrent operation but it is not per se simpler than a recurrent model. Furthermore, the authors proposed an interesting idea to augment additional training data by paraphrasing based on off-the-shelf neural machine translation.  On SQuAD dataset, their results show some small improvements using the proposed augmentation technique. Their best results, however, do not outperform the best results reported on the leader board.----------------Overall, this is an interesting study on SQuAD dataset. I would like to see results on more datasets and more discussion on the data augmentation technique. At the moment, the description in section 3 is fuzzy in my opinion. Interesting information could be:--------- how is the performance of the NMT system? --------- how many new data points are finally added into the training data set?--------- what do ‘data aug’ x 2 or x 3 exactly mean? This paper proposes two contributions: first, applying CNNs+self-attention modules instead of LSTMs, which could result in significant speedup and good RC performance; second, enhancing the RC model training with passage paraphrases generated by a neural paraphrasing model, which could improve the RC performance marginally.----------------Firstly, I suggest the authors rewrite the end of the introduction. The current version tends to mix everything together and makes the misleading claim. When I read the paper, I thought the speeding up mechanism could give both speed up and performance boost, and lead to the 82.2 F1. But it turns out that the above improvements are achieved with at least three different ideas: (1) the CNN+self-attention module; (2) the entire model architecture design; and (3) the data augmentation method. ----------------Secondly, none of the above three ideas are well evaluated in terms of both speedup and RC performance, and I will comment in details as follows:----------------(1) The CNN+self-attention was mainly borrowing the idea from (Vaswani et al., 2017a) from NMT to RC. The novelty is limited but it is a good idea to speed up the RC models. However, as the authors hoped to claim that this module could contribute to both speedup and RC performance, it will be necessary to show the RC performance of the same model architecture, but replacing the CNNs with LSTMs. Only if the proposed architecture still gives better results, the claims in the introduction can be considered correct.----------------(2) I feel that the model design is the main reason for the good overall RC performance. However, in the paper there is no motivation about why the architecture was designed like this. Moreover, the whole model architecture is only evaluated on the SQuAD dataset. As a result, it is not convincing that the system design has good generalization. If in (1) it is observed that using LSTMs in the model instead of CNNs could give on par or better results, it will be necessary to test the proposed model architecture on multiple datasets, as well as conducting more ablation tests about the model architecture itself.----------------(3) I like the idea of data augmentation with paraphrasing. Currently, the improvement is only marginal, but there seems many other things to play with. For example, training NMT models with larger parallel corpora; training NMT models with different language pairs with English as the pivot; and better strategies to select the generated passages for data augmentation.----------------I am looking forward to the test performance of this work on SQuAD.","This work replaces the RNN layer of square with a self-attention and convolution, achieving a big speed up and performance gains, particularly with data augmentation. The work is mostly clear presented, one reviewer found it ""well-written"" although there was a complaint the work did not clear separate out the novel aspects. In terms of results the work is clearly of high quality, producing top numbers on the shared task. There were some initial complaints of only using the SQuAD dataset, but the authors have now included additional results that diversify the experiments. Perhaps the largest concern is novelty. The idea of non-RNN self-attention is now widely known, and there are several systems that are applying it. Reviewers felt that while this system does it well, it is maybe less novel or significant than other possible work. "
