{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alialhousseini/glimpse-mds/blob/main/NLP_main_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "collapsed": true,
        "id": "Zw-RQzb6OZXy",
        "outputId": "6cbc74a1-8497-42dc-af21-9a79f8cc320d"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEYXb3BiQ8ym",
        "outputId": "e29bbfb4-f8d1-4f56-fc77-39bdcbcfa9d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'glimpse-mds'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (239/239), done.\u001b[K\n",
            "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
            "remote: Total 239 (delta 137), reused 197 (delta 95), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (239/239), 31.63 MiB | 13.22 MiB/s, done.\n",
            "Resolving deltas: 100% (137/137), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/alialhousseini/glimpse-mds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DNVb_lnRFJ2",
        "outputId": "13aa3655-5d0d-4fc0-bc1d-8fe8e9444126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è¨ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:10\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg3boMnMRZZh"
      },
      "outputs": [],
      "source": [
        "# Define the path for the new environment\n",
        "env_path = '/content/glimpse_env'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3Qv0rFyRiia",
        "outputId": "6176b362-e9cd-497d-caae-f9763cfafe29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 23.11.0\n",
            "    latest version: 24.11.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /content/glimpse_env\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.10\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    bzip2-1.0.8                |       h4bc722e_7         247 KB  conda-forge\n",
            "    ca-certificates-2024.8.30  |       hbcca054_0         155 KB  conda-forge\n",
            "    ld_impl_linux-64-2.43      |       h712a8e2_2         654 KB  conda-forge\n",
            "    libgcc-14.2.0              |       h77fa898_1         829 KB  conda-forge\n",
            "    libgcc-ng-14.2.0           |       h69a702a_1          53 KB  conda-forge\n",
            "    libgomp-14.2.0             |       h77fa898_1         450 KB  conda-forge\n",
            "    libsqlite-3.47.0           |       hadc24fc_1         855 KB  conda-forge\n",
            "    libxcrypt-4.4.36           |       hd590300_1          98 KB  conda-forge\n",
            "    libzlib-1.3.1              |       hb9d3cd8_2          60 KB  conda-forge\n",
            "    ncurses-6.5                |       he02047a_1         868 KB  conda-forge\n",
            "    openssl-3.4.0              |       hb9d3cd8_0         2.8 MB  conda-forge\n",
            "    pip-24.3.1                 |     pyh8b19718_0         1.2 MB  conda-forge\n",
            "    python-3.10.15             |h4a871b0_2_cpython        24.1 MB  conda-forge\n",
            "    setuptools-75.6.0          |     pyhff2d567_1         756 KB  conda-forge\n",
            "    tzdata-2024b               |       hc8b5060_0         119 KB  conda-forge\n",
            "    wheel-0.45.1               |     pyhd8ed1ab_0          62 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        33.2 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h4bc722e_7 \n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2024.8.30-hbcca054_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.43-h712a8e2_2 \n",
            "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 \n",
            "  libgcc             conda-forge/linux-64::libgcc-14.2.0-h77fa898_1 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-14.2.0-h69a702a_1 \n",
            "  libgomp            conda-forge/linux-64::libgomp-14.2.0-h77fa898_1 \n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.47.0-hadc24fc_1 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 \n",
            "  libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.5-he02047a_1 \n",
            "  openssl            conda-forge/linux-64::openssl-3.4.0-hb9d3cd8_0 \n",
            "  pip                conda-forge/noarch::pip-24.3.1-pyh8b19718_0 \n",
            "  python             conda-forge/linux-64::python-3.10.15-h4a871b0_2_cpython \n",
            "  readline           conda-forge/linux-64::readline-8.2-h8228510_1 \n",
            "  setuptools         conda-forge/noarch::setuptools-75.6.0-pyhff2d567_1 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 \n",
            "  tzdata             conda-forge/noarch::tzdata-2024b-hc8b5060_0 \n",
            "  wheel              conda-forge/noarch::wheel-0.45.1-pyhd8ed1ab_0 \n",
            "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "python-3.10.15       | 24.1 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "openssl-3.4.0        | 2.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "pip-24.3.1           | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.47.0     | 855 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 829 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 450 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 155 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024b         | 119 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 62 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libzlib-1.3.1        | 60 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.15       | 24.1 MB   | :   0% 0.0025881930044147692/1 [00:00<00:39, 40.03s/it]\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.47.0     | 855 KB    | :   2% 0.018717105977158824/1 [00:00<00:05,  5.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "openssl-3.4.0        | 2.8 MB    | :   1% 0.005558673111072358/1 [00:00<00:19, 19.77s/it]\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | :   2% 0.018427913610156946/1 [00:00<00:05,  5.99s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "python-3.10.15       | 24.1 MB   | :  18% 0.17664417255130802/1 [00:00<00:00,  1.02it/s]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 829 KB    | :   2% 0.019303795604097816/1 [00:00<00:10, 10.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "openssl-3.4.0        | 2.8 MB    | :  93% 0.9338570826601562/1 [00:00<00:00,  5.24it/s]  \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | :   2% 0.021161069005956715/1 [00:00<00:10, 10.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | :   2% 0.024482562300978315/1 [00:00<00:09, 10.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.47.0     | 855 KB    | : 100% 1.0/1 [00:00<00:00,  4.16it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.47.0     | 855 KB    | : 100% 1.0/1 [00:00<00:00,  4.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.15       | 24.1 MB   | :  31% 0.30734791927425387/1 [00:00<00:00,  1.15it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | :   6% 0.06481448515129577/1 [00:00<00:04,  4.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 155 KB    | :  10% 0.10304208096702577/1 [00:00<00:02,  3.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | :  16% 0.163198629386511/1 [00:00<00:01,  2.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024b         | 119 KB    | :  13% 0.1339065335011524/1 [00:00<00:02,  2.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 62 KB     | :  26% 0.26007174830947016/1 [00:00<00:01,  1.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libzlib-1.3.1        | 60 KB     | :  27% 0.2687531781572429/1 [00:00<00:00,  1.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.15       | 24.1 MB   | :  93% 0.9291612885849022/1 [00:00<00:00,  1.84it/s]\n",
            "\n",
            "pip-24.3.1           | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.07it/s]                 \u001b[A\u001b[A\n",
            "\n",
            "pip-24.3.1           | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 829 KB    | : 100% 1.0/1 [00:01<00:00,  1.05s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 829 KB    | : 100% 1.0/1 [00:01<00:00,  1.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | : 100% 1.0/1 [00:01<00:00,  1.56s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | : 100% 1.0/1 [00:01<00:00,  1.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | : 100% 1.0/1 [00:01<00:00,  1.62s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | : 100% 1.0/1 [00:01<00:00,  1.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "openssl-3.4.0        | 2.8 MB    | : 100% 1.0/1 [00:01<00:00,  5.24it/s]               \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 450 KB    | : 100% 1.0/1 [00:02<00:00,  2.01s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 450 KB    | : 100% 1.0/1 [00:02<00:00,  2.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | : 100% 1.0/1 [00:02<00:00,  2.07s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | : 100% 1.0/1 [00:02<00:00,  2.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 155 KB    | : 100% 1.0/1 [00:02<00:00,  2.11s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 155 KB    | : 100% 1.0/1 [00:02<00:00,  2.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | : 100% 1.0/1 [00:02<00:00,  2.18s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | : 100% 1.0/1 [00:02<00:00,  2.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | : 100% 1.0/1 [00:02<00:00,  2.58s/it]                 \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | : 100% 1.0/1 [00:02<00:00,  2.58s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 62 KB     | : 100% 1.0/1 [00:02<00:00,  2.75s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 62 KB     | : 100% 1.0/1 [00:02<00:00,  2.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024b         | 119 KB    | : 100% 1.0/1 [00:02<00:00,  2.66s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024b         | 119 KB    | : 100% 1.0/1 [00:02<00:00,  2.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libzlib-1.3.1        | 60 KB     | : 100% 1.0/1 [00:02<00:00,  2.78s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libzlib-1.3.1        | 60 KB     | : 100% 1.0/1 [00:02<00:00,  2.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-14.2.0     | 53 KB     | : 100% 1.0/1 [00:02<00:00,  2.87s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate /content/glimpse_env\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the Conda environment in the specified folder\n",
        "!conda create --prefix \"$env_path\" python=3.10 -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_Cq1BZpRp0O"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!source activate /content/glimpse_env && pip install -r /content/glimpse-mds/requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Extension 1: Use an ensemble set of models for producing RSA scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| **Model**           | **Small Definition**                                                                                                         | **Model Ability and Performance**                                                                   | **Why Choose This**                                                                                       | **Purpose**                                                                                      |\n",
        "|----------------------|-----------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|\n",
        "| **BART**            | A transformer model optimized for sequence-to-sequence tasks like summarization and translation.                           | Focuses on fluency and readability with strong abstractive summarization capabilities.              | Pretrained on a diverse dataset, excels in generating coherent and fluent summaries.                      | Abstractive summarization and text generation tasks.                                            |\n",
        "| **PEGASUS**         | A transformer model designed for summarization with gap-sentence generation pretraining.                                    | Excels at abstractive summarization and capturing document essence.                                 | Strong performance on summarization benchmarks like CNN/DailyMail and XSum.                               | Creating concise and coherent abstractive summaries.                                            |\n",
        "| **T5**              | A unified text-to-text transformer model capable of handling multiple NLP tasks.                                            | Balances fluency, factual consistency, and flexibility across tasks.                                | Suitable for multitask setups with state-of-the-art results on summarization and NLI.                     | Summarization, translation, and text classification.                                            |\n",
        "| **LED**             | A long-context version of BART tailored for summarizing long documents.                                                     | Processes up to 16,384 tokens, maintaining coherence and relevance over long contexts.              | Handles lengthy academic or technical documents effectively.                                              | Summarization of research papers, reports, and other long-form texts.                          |\n",
        "| **BigBird-Pegasus** | A sparse-attention model designed for efficient processing of long documents.                                               | Balances computational efficiency with performance on long-form summarization tasks.                | Efficiently handles long contexts while preserving critical information.                                  | Summarization and classification for long texts.                                                |\n",
        "| **PEGASUS (XSUM)**  | A PEGASUS model fine-tuned specifically on the XSum dataset for abstractive summarization.                                  | Produces highly concise summaries but can sometimes lose factual consistency.                       | Ideal for tasks requiring short, highly abstractive summaries.                                            | Summarizing news articles or brief documents.                                                   |\n",
        "| **DistilBART**      | A distilled version of BART with faster inference and smaller size.                                                         | Slightly reduced fluency compared to BART but much faster and more efficient.                       | Useful for scenarios with computational constraints.                                                      | Quick summarization and inference on resource-limited systems.                                 |\n",
        "| **mBART**           | A multilingual version of BART pre-trained on multiple languages.                                                           | Handles cross-lingual summarization and translation tasks effectively.                              | Ideal for multilingual datasets and scenarios involving diverse languages.                                | Summarization and translation for non-English or multilingual texts.                           |\n",
        "| **Flan-T5**         | A fine-tuned version of T5 for enhanced task performance, including summarization and reasoning.                            | Improves generalization and performance across multiple NLP tasks.                                  | Great for zero-shot and few-shot setups, with excellent task-specific adaptation.                         | Summarization, classification, and text reasoning.                                              |\n",
        "| **BERTSUM**         | A fine-tuned BERT model for extractive summarization tasks.                                                                 | Excels at identifying and extracting key sentences from texts.                                      | Reliable for extracting main points without paraphrasing.                                                 | Extractive summarization of structured documents.                                               |\n",
        "| **FactPEGASUS**     | A fine-tuned PEGASUS model for ensuring factual consistency in summaries.                                                    | Focuses on generating factually accurate abstractive summaries.                                     | Essential for tasks where factual correctness is critical.                                                | Summarization for sensitive or factual information.                                             |\n",
        "| **CTRLsumm**        | A fine-tuned model designed for conversational summarization.                                                               | Captures conversational nuances and preserves dialogue structure in summaries.                      | Ideal for summarizing meetings, chats, or interview transcripts.                                          | Summarization of conversational or dialogue-based content.                                      |\n",
        "| **SciBERT**         | A BERT model trained on scientific literature.                                                                              | Captures domain-specific vocabulary and syntax effectively.                                         | Tailored for summarizing or analyzing scholarly articles and scientific texts.                            | Text summarization, classification, and entity recognition in scientific domains.               |\n",
        "| **ALL-MPNET**       | A sentence transformer optimized for semantic similarity tasks.                                                              | Measures semantic similarity with high accuracy.                                                    | Ideal for evaluating consistency between source text and summaries.                                       | Consistency checking and similarity analysis.                                                   |\n",
        "| **XLM-ROBERTA**     | A multilingual transformer model with strong cross-lingual understanding capabilities.                                       | Excels in multilingual understanding and summarization tasks.                                       | Suitable for multilingual datasets or cross-lingual consistency evaluation.                               | Multilingual summarization and text classification.                                             |\n",
        "| **LongFormer-LARGE**| A transformer optimized for handling long contexts efficiently using sparse attention.                                       | Processes long documents with improved computational efficiency and accuracy.                       | Handles dense academic or technical texts requiring long-form attention.                                  | Summarization and question answering for long-form texts.                                       |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U8CRIj3USAL3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def consensus_scores_based_summaries(sample, n_consensus=3, n_dissensus=3):\n",
        "    consensus_samples = sample['consensuality_scores'].sort_values(ascending=True).head(n_consensus).index.tolist()\n",
        "    disensus_samples = sample['consensuality_scores'].sort_values(ascending=False).head(n_dissensus).index.tolist()\n",
        "    \n",
        "    consensus = \".\".join(consensus_samples)\n",
        "    disensus = \".\".join(disensus_samples)\n",
        "    \n",
        "    return consensus + \"\\n\\n\" + disensus\n",
        "    \n",
        "    \n",
        "def rsa_scores_based_summaries(sample, n_consensus=3, n_rsa_speaker=3):\n",
        "    consensus_samples = sample['consensuality_scores'].sort_values(ascending=True).head(n_consensus).index.tolist()\n",
        "    rsa = sample['best_rsa'].tolist()[:n_rsa_speaker]\n",
        "    \n",
        "    consensus = \".\".join(consensus_samples)\n",
        "    rsa = \".\".join(rsa)\n",
        "    \n",
        "    return consensus + \"\\n\\n\" + rsa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dftest = pd.read_csv('data/candidates/extractive_sentences-_-all_reviews_2017-_-none-_-2024-12-23-21-11-00.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>gold</th>\n",
              "      <th>summary</th>\n",
              "      <th>id_candidate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                         id  \\\n",
              "0      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "\n",
              "                                                text  \\\n",
              "0  Summary: The paper presents low-rank bilinear ...   \n",
              "\n",
              "                                                gold  \\\n",
              "0  The program committee appreciates the authors'...   \n",
              "\n",
              "                                             summary  id_candidate  \n",
              "0  Summary: The paper presents low-rank bilinear ...             0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dftest[dftest.index == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['Summary: The paper presents low-rank bilinear pooling that uses Hadamard product (commonly known as element-wise multiplication). The paper implements low-rank bilinear pooling on an existing model (Kim et al., 2016b) and builds a model for Visual Question Answering (VQA) that outperforms the current state-of-art by 0.42%. The paper presents various ablation studies of the new VQA model they built.----------------Strengths:----------------1. The paper presents new insights into element-wise multiplication operation which has been previously used in VQA literature (such as Antol et al., ICCV 2015) without insights on why it should work. ----------------2. The paper presents a new model for the task of VQA that beats the current state-of-art by 0.42%. However, I have concerns about the statistical significance of the performance (see weaknesses below).----------------3. The various design choices made in model development have been experimentally verified. ----------------Weaknesses/Suggestions:----------------1. When authors explicitly (keeping rest of the model architecture same) compared low-rank bilinear pooling with compact bilinear pooling, they found that low-rank bilinear pooling performs worse. Hence, it could not be experimentally verified that low-rank bilinear pooling is better in performance than compact bilinear pooling (at least for the task of VQA).----------------2. The authors argue that low-rank bilinear pooling uses 25% less parameters than compact bilinear pooling. So, could the authors please explain how does the reduction in number of parameters help experimentally? Does the training time of the model reduce significantly? Can we train the model with less data? ----------------3. One of the contributions of the paper is that the proposed model outperforms the current state-of-art on VQA by 0.42%. However, I am skeptical that the performance of the proposed model is statistically significantly better than the current state-of-art.----------------4. I would like the authors to explicitly mention the differences between MRN, MARN and MLB. It is not very clear from reading the paper.----------------5. In the caption for Table 1, fix the following: ‚Äúhave not‚Äù -> ‚Äúhave no‚Äù ----------------Review Summary: I like the insights about low-rank bilinear pooling using Hadamard product (element-wise multiplication) presented in the paper. However, it could not be justified that low-rank bilinear pooling leads to better performance than compact biliear pooling. It does lead to reduction in number of parameters but it is not clear how much that helps experimentally. So, to be more convinced I would like the authors to provide experimental justification of why low-rank bilinear pooling is better than other forms of pooling.',\n",
              "        'Summary: The paper presents low-rank bilinear pooling that uses Hadamard product (commonly known as element-wise multiplication).'],\n",
              "       ['Summary: The paper presents low-rank bilinear pooling that uses Hadamard product (commonly known as element-wise multiplication). The paper implements low-rank bilinear pooling on an existing model (Kim et al., 2016b) and builds a model for Visual Question Answering (VQA) that outperforms the current state-of-art by 0.42%. The paper presents various ablation studies of the new VQA model they built.----------------Strengths:----------------1. The paper presents new insights into element-wise multiplication operation which has been previously used in VQA literature (such as Antol et al., ICCV 2015) without insights on why it should work. ----------------2. The paper presents a new model for the task of VQA that beats the current state-of-art by 0.42%. However, I have concerns about the statistical significance of the performance (see weaknesses below).----------------3. The various design choices made in model development have been experimentally verified. ----------------Weaknesses/Suggestions:----------------1. When authors explicitly (keeping rest of the model architecture same) compared low-rank bilinear pooling with compact bilinear pooling, they found that low-rank bilinear pooling performs worse. Hence, it could not be experimentally verified that low-rank bilinear pooling is better in performance than compact bilinear pooling (at least for the task of VQA).----------------2. The authors argue that low-rank bilinear pooling uses 25% less parameters than compact bilinear pooling. So, could the authors please explain how does the reduction in number of parameters help experimentally? Does the training time of the model reduce significantly? Can we train the model with less data? ----------------3. One of the contributions of the paper is that the proposed model outperforms the current state-of-art on VQA by 0.42%. However, I am skeptical that the performance of the proposed model is statistically significantly better than the current state-of-art.----------------4. I would like the authors to explicitly mention the differences between MRN, MARN and MLB. It is not very clear from reading the paper.----------------5. In the caption for Table 1, fix the following: ‚Äúhave not‚Äù -> ‚Äúhave no‚Äù ----------------Review Summary: I like the insights about low-rank bilinear pooling using Hadamard product (element-wise multiplication) presented in the paper. However, it could not be justified that low-rank bilinear pooling leads to better performance than compact biliear pooling. It does lead to reduction in number of parameters but it is not clear how much that helps experimentally. So, to be more convinced I would like the authors to provide experimental justification of why low-rank bilinear pooling is better than other forms of pooling.',\n",
              "        'The paper implements low-rank bilinear pooling on an existing model (Kim et al., 2016b) and builds a model for Visual Question Answering (VQA) that outperforms the current state-of-art by 0.42%.']],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dftest[dftest['id']=='https://openreview.net/forum?id=r1rhWnZkg'][:2][['text', 'summary']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "dftest = dftest.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Item 1 has the text and first sentence\n",
        "- Item 2 has the text and the second sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rsasumm.rsa_reranker import RSAReranking\n",
        "from transformers import AutoModelForSeq2SeqLM, BartTokenizer\n",
        "torch.cuda.empty_cache()\n",
        "model_id = 'facebook/bart-large-cnn'\n",
        "model = model = AutoModelForSeq2SeqLM.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
        "tokenizer = BartTokenizer.from_pretrained(model_id)\n",
        "\n",
        "reranker = RSAReranking(\n",
        "    model= model,\n",
        "    tokenizer= tokenizer,\n",
        "    candidates=dftest['summary'].tolist(),\n",
        "    source_texts=dftest['text'].tolist(),\n",
        "    batch_size=8,\n",
        "    rationality=1,\n",
        "    device=\"cuda\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/13 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:02<00:00,  5.53it/s]\n"
          ]
        }
      ],
      "source": [
        "best_rsa, best_base, speaker_df, listener_df, initial_listener_proba, initial_speaker_proba, initital_consensuality_score, consensuality_scores = reranker.rerank(t=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>gold</th>\n",
              "      <th>summary</th>\n",
              "      <th>id_candidate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [index, id, text, gold, summary, id_candidate]\n",
              "Index: []"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dftest[dftest['id']=='https://openreview.net/forum?id=r1rhWnZkg']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['---- The \"feature control\" idea is not validated empirically (the preliminary experiment in Fig.',\n",
              "       'The employed test set of 100 programs seems rather small.',\n",
              "       'I think there may be a nice paper to made from this, but as it is, it should not be accepted.',\n",
              "       \"The authors don't provide enough discussion of the relative importance of these parts.\",\n",
              "       '-Minor comments:\\n---- P and Q seem to be undefined.',\n",
              "       '-- Only the dropout rate p=0.5 was used across experiments, while the optimal rate is problem dependent, as found by earlier published work.',\n",
              "       'The human evaluation presented in the paper is not satisfactory because the human performance is reported on a very small subset (200 questions).',\n",
              "       'handcrafted filter sizes) and based on the evaluation it seems to improve the results and help to avoid over-fitting (probably due to reduced filter size and thus number of parameters).',\n",
              "       '2016',\n",
              "       'To the best of my knowledge this is the first paper that considers adversarial examples for generative models.'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_rsa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "dftest['best_rsa'] = best_rsa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "dftest['consensuality_scores'] = consensuality_scores.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>gold</th>\n",
              "      <th>summary</th>\n",
              "      <th>id_candidate</th>\n",
              "      <th>best_rsa</th>\n",
              "      <th>consnsuality_scores</th>\n",
              "      <th>consensuality_scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14829</th>\n",
              "      <td>955</td>\n",
              "      <td>https://openreview.net/forum?id=SJ6yPD5xg</td>\n",
              "      <td>This paper is about improving feature learning...</td>\n",
              "      <td>There was broad consensus by the reviewers tha...</td>\n",
              "      <td>---- The \"feature control\" idea is not validat...</td>\n",
              "      <td>12</td>\n",
              "      <td>---- The \"feature control\" idea is not validat...</td>\n",
              "      <td>1.690573</td>\n",
              "      <td>1.690573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9621</th>\n",
              "      <td>614</td>\n",
              "      <td>https://openreview.net/forum?id=ByldLrqlx</td>\n",
              "      <td>The paper presents a technique to combine deep...</td>\n",
              "      <td>This is a well written paper that attempts to ...</td>\n",
              "      <td>The employed test set of 100 programs seems ra...</td>\n",
              "      <td>7</td>\n",
              "      <td>The employed test set of 100 programs seems ra...</td>\n",
              "      <td>1.161712</td>\n",
              "      <td>1.161712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13093</th>\n",
              "      <td>838</td>\n",
              "      <td>https://openreview.net/forum?id=BkJsCIcgl</td>\n",
              "      <td>I think there may be a nice paper to made from...</td>\n",
              "      <td>There is potential here for a great paper, unf...</td>\n",
              "      <td>I think there may be a nice paper to made from...</td>\n",
              "      <td>0</td>\n",
              "      <td>I think there may be a nice paper to made from...</td>\n",
              "      <td>0.972531</td>\n",
              "      <td>0.972531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18594</th>\n",
              "      <td>1175</td>\n",
              "      <td>https://openreview.net/forum?id=Hku9NK5lx</td>\n",
              "      <td>This work introduces a number of techniques to...</td>\n",
              "      <td>The reviewers unanimously recommended acceptin...</td>\n",
              "      <td>The authors don't provide enough discussion of...</td>\n",
              "      <td>9</td>\n",
              "      <td>The authors don't provide enough discussion of...</td>\n",
              "      <td>0.915484</td>\n",
              "      <td>0.915484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8857</th>\n",
              "      <td>569</td>\n",
              "      <td>https://openreview.net/forum?id=SJvYgH9xe</td>\n",
              "      <td>This work proposes a pattern extraction method...</td>\n",
              "      <td>The equation between (8) - (9) seems to be inc...</td>\n",
              "      <td>-Minor comments:\\n---- P and Q seem to be unde...</td>\n",
              "      <td>10</td>\n",
              "      <td>-Minor comments:\\n---- P and Q seem to be unde...</td>\n",
              "      <td>1.622159</td>\n",
              "      <td>1.622159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5607</th>\n",
              "      <td>367</td>\n",
              "      <td>https://openreview.net/forum?id=HJ1JBJ5gl</td>\n",
              "      <td>This paper investigates whether the variationa...</td>\n",
              "      <td>The reviewers unanimously recommend rejecting ...</td>\n",
              "      <td>-- Only the dropout rate p=0.5 was used across...</td>\n",
              "      <td>5</td>\n",
              "      <td>-- Only the dropout rate p=0.5 was used across...</td>\n",
              "      <td>1.307342</td>\n",
              "      <td>1.307342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19015</th>\n",
              "      <td>1205</td>\n",
              "      <td>https://openreview.net/forum?id=ry3iBFqgl</td>\n",
              "      <td>Summary: The paper proposes a novel machine co...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>The human evaluation presented in the paper is...</td>\n",
              "      <td>12</td>\n",
              "      <td>The human evaluation presented in the paper is...</td>\n",
              "      <td>1.279732</td>\n",
              "      <td>1.279732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8817</th>\n",
              "      <td>565</td>\n",
              "      <td>https://openreview.net/forum?id=HkpLeH9el</td>\n",
              "      <td>This paper presents design decisions of Terpre...</td>\n",
              "      <td>Quality, Clarity: There is no consensus on thi...</td>\n",
              "      <td>2016</td>\n",
              "      <td>17</td>\n",
              "      <td>handcrafted filter sizes) and based on the eva...</td>\n",
              "      <td>1.340523</td>\n",
              "      <td>1.340523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22721</th>\n",
              "      <td>1448</td>\n",
              "      <td>https://openreview.net/forum?id=S1TER2oll</td>\n",
              "      <td>This work proposes a way how to learn filter s...</td>\n",
              "      <td>Using covariance analysis for designing convol...</td>\n",
              "      <td>handcrafted filter sizes) and based on the eva...</td>\n",
              "      <td>5</td>\n",
              "      <td>2016</td>\n",
              "      <td>0.467946</td>\n",
              "      <td>0.467946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21699</th>\n",
              "      <td>1382</td>\n",
              "      <td>https://openreview.net/forum?id=SJk01vogl</td>\n",
              "      <td>This paper considers different methods of prod...</td>\n",
              "      <td>The main idea in this paper is interesting, of...</td>\n",
              "      <td>To the best of my knowledge this is the first ...</td>\n",
              "      <td>3</td>\n",
              "      <td>To the best of my knowledge this is the first ...</td>\n",
              "      <td>1.124992</td>\n",
              "      <td>1.124992</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       index                                         id  \\\n",
              "14829    955  https://openreview.net/forum?id=SJ6yPD5xg   \n",
              "9621     614  https://openreview.net/forum?id=ByldLrqlx   \n",
              "13093    838  https://openreview.net/forum?id=BkJsCIcgl   \n",
              "18594   1175  https://openreview.net/forum?id=Hku9NK5lx   \n",
              "8857     569  https://openreview.net/forum?id=SJvYgH9xe   \n",
              "5607     367  https://openreview.net/forum?id=HJ1JBJ5gl   \n",
              "19015   1205  https://openreview.net/forum?id=ry3iBFqgl   \n",
              "8817     565  https://openreview.net/forum?id=HkpLeH9el   \n",
              "22721   1448  https://openreview.net/forum?id=S1TER2oll   \n",
              "21699   1382  https://openreview.net/forum?id=SJk01vogl   \n",
              "\n",
              "                                                    text  \\\n",
              "14829  This paper is about improving feature learning...   \n",
              "9621   The paper presents a technique to combine deep...   \n",
              "13093  I think there may be a nice paper to made from...   \n",
              "18594  This work introduces a number of techniques to...   \n",
              "8857   This work proposes a pattern extraction method...   \n",
              "5607   This paper investigates whether the variationa...   \n",
              "19015  Summary: The paper proposes a novel machine co...   \n",
              "8817   This paper presents design decisions of Terpre...   \n",
              "22721  This work proposes a way how to learn filter s...   \n",
              "21699  This paper considers different methods of prod...   \n",
              "\n",
              "                                                    gold  \\\n",
              "14829  There was broad consensus by the reviewers tha...   \n",
              "9621   This is a well written paper that attempts to ...   \n",
              "13093  There is potential here for a great paper, unf...   \n",
              "18594  The reviewers unanimously recommended acceptin...   \n",
              "8857   The equation between (8) - (9) seems to be inc...   \n",
              "5607   The reviewers unanimously recommend rejecting ...   \n",
              "19015  The program committee appreciates the authors'...   \n",
              "8817   Quality, Clarity: There is no consensus on thi...   \n",
              "22721  Using covariance analysis for designing convol...   \n",
              "21699  The main idea in this paper is interesting, of...   \n",
              "\n",
              "                                                 summary  id_candidate  \\\n",
              "14829  ---- The \"feature control\" idea is not validat...            12   \n",
              "9621   The employed test set of 100 programs seems ra...             7   \n",
              "13093  I think there may be a nice paper to made from...             0   \n",
              "18594  The authors don't provide enough discussion of...             9   \n",
              "8857   -Minor comments:\\n---- P and Q seem to be unde...            10   \n",
              "5607   -- Only the dropout rate p=0.5 was used across...             5   \n",
              "19015  The human evaluation presented in the paper is...            12   \n",
              "8817                                                2016            17   \n",
              "22721  handcrafted filter sizes) and based on the eva...             5   \n",
              "21699  To the best of my knowledge this is the first ...             3   \n",
              "\n",
              "                                                best_rsa  consnsuality_scores  \\\n",
              "14829  ---- The \"feature control\" idea is not validat...             1.690573   \n",
              "9621   The employed test set of 100 programs seems ra...             1.161712   \n",
              "13093  I think there may be a nice paper to made from...             0.972531   \n",
              "18594  The authors don't provide enough discussion of...             0.915484   \n",
              "8857   -Minor comments:\\n---- P and Q seem to be unde...             1.622159   \n",
              "5607   -- Only the dropout rate p=0.5 was used across...             1.307342   \n",
              "19015  The human evaluation presented in the paper is...             1.279732   \n",
              "8817   handcrafted filter sizes) and based on the eva...             1.340523   \n",
              "22721                                               2016             0.467946   \n",
              "21699  To the best of my knowledge this is the first ...             1.124992   \n",
              "\n",
              "       consensuality_scores  \n",
              "14829              1.690573  \n",
              "9621               1.161712  \n",
              "13093              0.972531  \n",
              "18594              0.915484  \n",
              "8857               1.622159  \n",
              "5607               1.307342  \n",
              "19015              1.279732  \n",
              "8817               1.340523  \n",
              "22721              0.467946  \n",
              "21699              1.124992  "
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dftest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14829    1.690573\n",
              "9621     1.161712\n",
              "13093    0.972531\n",
              "18594    0.915484\n",
              "8857     1.622159\n",
              "5607     1.307342\n",
              "19015    1.279732\n",
              "8817     1.340523\n",
              "22721    0.467946\n",
              "21699    1.124992\n",
              "Name: consnsuality_scores, dtype: float32"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dftest['consnsuality_scores']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'consensuality_scores'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32md:\\Github\\glimpse-mds\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'consensuality_scores'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[55], line 20\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# def consensus_scores_based_summaries(sample: DataFrame Element, n_consensus=3, n_dissensus=3):\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#     consensus_samples = sample['consensuality_scores'].sort_values(ascending=True).head(n_consensus).index.tolist()\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#     disensus_samples = sample['consensuality_scores'].sort_values(ascending=False).head(n_dissensus).index.tolist()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#     return consensus + \"\\n\\n\" + rsa\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mconsensus_scores_based_summaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdftest\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[52], line 2\u001b[0m, in \u001b[0;36mconsensus_scores_based_summaries\u001b[1;34m(sample, n_consensus, n_dissensus)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconsensus_scores_based_summaries\u001b[39m(sample, n_consensus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_dissensus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     consensus_samples \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconsensuality_scores\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(n_consensus)\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      3\u001b[0m     disensus_samples \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconsensuality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(n_dissensus)\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      5\u001b[0m     consensus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(consensus_samples)\n",
            "File \u001b[1;32md:\\Github\\glimpse-mds\\env\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[1;32md:\\Github\\glimpse-mds\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'consensuality_scores'"
          ]
        }
      ],
      "source": [
        "# def consensus_scores_based_summaries(sample: DataFrame Element, n_consensus=3, n_dissensus=3):\n",
        "#     consensus_samples = sample['consensuality_scores'].sort_values(ascending=True).head(n_consensus).index.tolist()\n",
        "#     disensus_samples = sample['consensuality_scores'].sort_values(ascending=False).head(n_dissensus).index.tolist()\n",
        "    \n",
        "#     consensus = \".\".join(consensus_samples)\n",
        "#     disensus = \".\".join(disensus_samples)\n",
        "    \n",
        "#     return consensus + \"\\n\\n\" + disensus\n",
        "    \n",
        "    \n",
        "# def rsa_scores_based_summaries(sample, n_consensus=3, n_rsa_speaker=3):\n",
        "#     consensus_samples = sample['consensuality_scores'].sort_values(ascending=True).head(n_consensus).index.tolist()\n",
        "#     rsa = sample['best_rsa'].tolist()[:n_rsa_speaker]\n",
        "    \n",
        "#     consensus = \".\".join(consensus_samples)\n",
        "#     rsa = \".\".join(rsa)\n",
        "    \n",
        "#     return consensus + \"\\n\\n\" + rsa\n",
        "\n",
        "consensus_scores_based_summaries(dftest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
