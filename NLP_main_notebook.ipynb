{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alialhousseini/glimpse-mds/blob/main/NLP_main_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "collapsed": true,
        "id": "Zw-RQzb6OZXy",
        "outputId": "6cbc74a1-8497-42dc-af21-9a79f8cc320d"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEYXb3BiQ8ym",
        "outputId": "e29bbfb4-f8d1-4f56-fc77-39bdcbcfa9d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'glimpse-mds'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (239/239), done.\u001b[K\n",
            "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
            "remote: Total 239 (delta 137), reused 197 (delta 95), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (239/239), 31.63 MiB | 13.22 MiB/s, done.\n",
            "Resolving deltas: 100% (137/137), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/alialhousseini/glimpse-mds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DNVb_lnRFJ2",
        "outputId": "13aa3655-5d0d-4fc0-bc1d-8fe8e9444126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â¬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:10\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg3boMnMRZZh"
      },
      "outputs": [],
      "source": [
        "# Define the path for the new environment\n",
        "env_path = '/content/glimpse_env'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3Qv0rFyRiia",
        "outputId": "6176b362-e9cd-497d-caae-f9763cfafe29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 23.11.0\n",
            "    latest version: 24.11.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /content/glimpse_env\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.10\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    bzip2-1.0.8                |       h4bc722e_7         247 KB  conda-forge\n",
            "    ca-certificates-2024.8.30  |       hbcca054_0         155 KB  conda-forge\n",
            "    ld_impl_linux-64-2.43      |       h712a8e2_2         654 KB  conda-forge\n",
            "    libgcc-14.2.0              |       h77fa898_1         829 KB  conda-forge\n",
            "    libgcc-ng-14.2.0           |       h69a702a_1          53 KB  conda-forge\n",
            "    libgomp-14.2.0             |       h77fa898_1         450 KB  conda-forge\n",
            "    libsqlite-3.47.0           |       hadc24fc_1         855 KB  conda-forge\n",
            "    libxcrypt-4.4.36           |       hd590300_1          98 KB  conda-forge\n",
            "    libzlib-1.3.1              |       hb9d3cd8_2          60 KB  conda-forge\n",
            "    ncurses-6.5                |       he02047a_1         868 KB  conda-forge\n",
            "    openssl-3.4.0              |       hb9d3cd8_0         2.8 MB  conda-forge\n",
            "    pip-24.3.1                 |     pyh8b19718_0         1.2 MB  conda-forge\n",
            "    python-3.10.15             |h4a871b0_2_cpython        24.1 MB  conda-forge\n",
            "    setuptools-75.6.0          |     pyhff2d567_1         756 KB  conda-forge\n",
            "    tzdata-2024b               |       hc8b5060_0         119 KB  conda-forge\n",
            "    wheel-0.45.1               |     pyhd8ed1ab_0          62 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        33.2 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h4bc722e_7 \n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2024.8.30-hbcca054_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.43-h712a8e2_2 \n",
            "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 \n",
            "  libgcc             conda-forge/linux-64::libgcc-14.2.0-h77fa898_1 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-14.2.0-h69a702a_1 \n",
            "  libgomp            conda-forge/linux-64::libgomp-14.2.0-h77fa898_1 \n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.47.0-hadc24fc_1 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 \n",
            "  libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.5-he02047a_1 \n",
            "  openssl            conda-forge/linux-64::openssl-3.4.0-hb9d3cd8_0 \n",
            "  pip                conda-forge/noarch::pip-24.3.1-pyh8b19718_0 \n",
            "  python             conda-forge/linux-64::python-3.10.15-h4a871b0_2_cpython \n",
            "  readline           conda-forge/linux-64::readline-8.2-h8228510_1 \n",
            "  setuptools         conda-forge/noarch::setuptools-75.6.0-pyhff2d567_1 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 \n",
            "  tzdata             conda-forge/noarch::tzdata-2024b-hc8b5060_0 \n",
            "  wheel              conda-forge/noarch::wheel-0.45.1-pyhd8ed1ab_0 \n",
            "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "python-3.10.15       | 24.1 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "openssl-3.4.0        | 2.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "pip-24.3.1           | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.47.0     | 855 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 829 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 450 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 155 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024b         | 119 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 62 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libzlib-1.3.1        | 60 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.15       | 24.1 MB   | :   0% 0.0025881930044147692/1 [00:00<00:39, 40.03s/it]\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.47.0     | 855 KB    | :   2% 0.018717105977158824/1 [00:00<00:05,  5.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "openssl-3.4.0        | 2.8 MB    | :   1% 0.005558673111072358/1 [00:00<00:19, 19.77s/it]\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | :   2% 0.018427913610156946/1 [00:00<00:05,  5.99s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "python-3.10.15       | 24.1 MB   | :  18% 0.17664417255130802/1 [00:00<00:00,  1.02it/s]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 829 KB    | :   2% 0.019303795604097816/1 [00:00<00:10, 10.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "openssl-3.4.0        | 2.8 MB    | :  93% 0.9338570826601562/1 [00:00<00:00,  5.24it/s]  \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | :   2% 0.021161069005956715/1 [00:00<00:10, 10.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | :   2% 0.024482562300978315/1 [00:00<00:09, 10.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.47.0     | 855 KB    | : 100% 1.0/1 [00:00<00:00,  4.16it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.47.0     | 855 KB    | : 100% 1.0/1 [00:00<00:00,  4.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.15       | 24.1 MB   | :  31% 0.30734791927425387/1 [00:00<00:00,  1.15it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | :   6% 0.06481448515129577/1 [00:00<00:04,  4.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 155 KB    | :  10% 0.10304208096702577/1 [00:00<00:02,  3.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | :  16% 0.163198629386511/1 [00:00<00:01,  2.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024b         | 119 KB    | :  13% 0.1339065335011524/1 [00:00<00:02,  2.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 62 KB     | :  26% 0.26007174830947016/1 [00:00<00:01,  1.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libzlib-1.3.1        | 60 KB     | :  27% 0.2687531781572429/1 [00:00<00:00,  1.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.15       | 24.1 MB   | :  93% 0.9291612885849022/1 [00:00<00:00,  1.84it/s]\n",
            "\n",
            "pip-24.3.1           | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.07it/s]                 \u001b[A\u001b[A\n",
            "\n",
            "pip-24.3.1           | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 829 KB    | : 100% 1.0/1 [00:01<00:00,  1.05s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 829 KB    | : 100% 1.0/1 [00:01<00:00,  1.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | : 100% 1.0/1 [00:01<00:00,  1.56s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | : 100% 1.0/1 [00:01<00:00,  1.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | : 100% 1.0/1 [00:01<00:00,  1.62s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | : 100% 1.0/1 [00:01<00:00,  1.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "openssl-3.4.0        | 2.8 MB    | : 100% 1.0/1 [00:01<00:00,  5.24it/s]               \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 450 KB    | : 100% 1.0/1 [00:02<00:00,  2.01s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 450 KB    | : 100% 1.0/1 [00:02<00:00,  2.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | : 100% 1.0/1 [00:02<00:00,  2.07s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | : 100% 1.0/1 [00:02<00:00,  2.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 155 KB    | : 100% 1.0/1 [00:02<00:00,  2.11s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 155 KB    | : 100% 1.0/1 [00:02<00:00,  2.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | : 100% 1.0/1 [00:02<00:00,  2.18s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | : 100% 1.0/1 [00:02<00:00,  2.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | : 100% 1.0/1 [00:02<00:00,  2.58s/it]                 \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | : 100% 1.0/1 [00:02<00:00,  2.58s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 62 KB     | : 100% 1.0/1 [00:02<00:00,  2.75s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 62 KB     | : 100% 1.0/1 [00:02<00:00,  2.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024b         | 119 KB    | : 100% 1.0/1 [00:02<00:00,  2.66s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024b         | 119 KB    | : 100% 1.0/1 [00:02<00:00,  2.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libzlib-1.3.1        | 60 KB     | : 100% 1.0/1 [00:02<00:00,  2.78s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libzlib-1.3.1        | 60 KB     | : 100% 1.0/1 [00:02<00:00,  2.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-14.2.0     | 53 KB     | : 100% 1.0/1 [00:02<00:00,  2.87s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate /content/glimpse_env\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the Conda environment in the specified folder\n",
        "!conda create --prefix \"$env_path\" python=3.10 -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_Cq1BZpRp0O"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!source activate /content/glimpse_env && pip install -r /content/glimpse-mds/requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Extension 1: Use an ensemble set of models for producing RSA scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| **Model**           | **Small Definition**                                                                                                         | **Model Ability and Performance**                                                                   | **Why Choose This**                                                                                       | **Purpose**                                                                                      |\n",
        "|----------------------|-----------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|\n",
        "| **BART**            | A transformer model optimized for sequence-to-sequence tasks like summarization and translation.                           | Focuses on fluency and readability with strong abstractive summarization capabilities.              | Pretrained on a diverse dataset, excels in generating coherent and fluent summaries.                      | Abstractive summarization and text generation tasks.                                            |\n",
        "| **PEGASUS**         | A transformer model designed for summarization with gap-sentence generation pretraining.                                    | Excels at abstractive summarization and capturing document essence.                                 | Strong performance on summarization benchmarks like CNN/DailyMail and XSum.                               | Creating concise and coherent abstractive summaries.                                            |\n",
        "| **T5**              | A unified text-to-text transformer model capable of handling multiple NLP tasks.                                            | Balances fluency, factual consistency, and flexibility across tasks.                                | Suitable for multitask setups with state-of-the-art results on summarization and NLI.                     | Summarization, translation, and text classification.                                            |\n",
        "| **LED**             | A long-context version of BART tailored for summarizing long documents.                                                     | Processes up to 16,384 tokens, maintaining coherence and relevance over long contexts.              | Handles lengthy academic or technical documents effectively.                                              | Summarization of research papers, reports, and other long-form texts.                          |\n",
        "| **BigBird-Pegasus** | A sparse-attention model designed for efficient processing of long documents.                                               | Balances computational efficiency with performance on long-form summarization tasks.                | Efficiently handles long contexts while preserving critical information.                                  | Summarization and classification for long texts.                                                |\n",
        "| **PEGASUS (XSUM)**  | A PEGASUS model fine-tuned specifically on the XSum dataset for abstractive summarization.                                  | Produces highly concise summaries but can sometimes lose factual consistency.                       | Ideal for tasks requiring short, highly abstractive summaries.                                            | Summarizing news articles or brief documents.                                                   |\n",
        "| **DistilBART**      | A distilled version of BART with faster inference and smaller size.                                                         | Slightly reduced fluency compared to BART but much faster and more efficient.                       | Useful for scenarios with computational constraints.                                                      | Quick summarization and inference on resource-limited systems.                                 |\n",
        "| **mBART**           | A multilingual version of BART pre-trained on multiple languages.                                                           | Handles cross-lingual summarization and translation tasks effectively.                              | Ideal for multilingual datasets and scenarios involving diverse languages.                                | Summarization and translation for non-English or multilingual texts.                           |\n",
        "| **Flan-T5**         | A fine-tuned version of T5 for enhanced task performance, including summarization and reasoning.                            | Improves generalization and performance across multiple NLP tasks.                                  | Great for zero-shot and few-shot setups, with excellent task-specific adaptation.                         | Summarization, classification, and text reasoning.                                              |\n",
        "| **BERTSUM**         | A fine-tuned BERT model for extractive summarization tasks.                                                                 | Excels at identifying and extracting key sentences from texts.                                      | Reliable for extracting main points without paraphrasing.                                                 | Extractive summarization of structured documents.                                               |\n",
        "| **FactPEGASUS**     | A fine-tuned PEGASUS model for ensuring factual consistency in summaries.                                                    | Focuses on generating factually accurate abstractive summaries.                                     | Essential for tasks where factual correctness is critical.                                                | Summarization for sensitive or factual information.                                             |\n",
        "| **CTRLsumm**        | A fine-tuned model designed for conversational summarization.                                                               | Captures conversational nuances and preserves dialogue structure in summaries.                      | Ideal for summarizing meetings, chats, or interview transcripts.                                          | Summarization of conversational or dialogue-based content.                                      |\n",
        "| **SciBERT**         | A BERT model trained on scientific literature.                                                                              | Captures domain-specific vocabulary and syntax effectively.                                         | Tailored for summarizing or analyzing scholarly articles and scientific texts.                            | Text summarization, classification, and entity recognition in scientific domains.               |\n",
        "| **ALL-MPNET**       | A sentence transformer optimized for semantic similarity tasks.                                                              | Measures semantic similarity with high accuracy.                                                    | Ideal for evaluating consistency between source text and summaries.                                       | Consistency checking and similarity analysis.                                                   |\n",
        "| **XLM-ROBERTA**     | A multilingual transformer model with strong cross-lingual understanding capabilities.                                       | Excels in multilingual understanding and summarization tasks.                                       | Suitable for multilingual datasets or cross-lingual consistency evaluation.                               | Multilingual summarization and text classification.                                             |\n",
        "| **LongFormer-LARGE**| A transformer optimized for handling long contexts efficiently using sparse attention.                                       | Processes long documents with improved computational efficiency and accuracy.                       | Handles dense academic or technical texts requiring long-form attention.                                  | Summarization and question answering for long-form texts.                                       |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U8CRIj3USAL3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from typing import List, Dict\n",
        "\n",
        "class ModelHandler:\n",
        "    def __init__(self, model, tokenizer, device=\"cpu\"):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "\n",
        "    def compute_likelihood_enc_dec(self, x: List[str], y: List[str], mean: bool = True) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Compute likelihood for Encoder-Decoder models (e.g., BART, T5).\n",
        "        \"\"\"\n",
        "        assert len(x) == len(y), \"Source and summary lists must have the same length.\"\n",
        "\n",
        "        loss_fn = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\n",
        "        # Tokenize source and summary\n",
        "        x_enc = self.tokenizer(x, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        y_enc = self.tokenizer(y, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "        # Move to the correct device\n",
        "        x_enc = {k: v.to(self.device) for k, v in x_enc.items()}\n",
        "        y_enc = {k: v.to(self.device) for k, v in y_enc.items()}\n",
        "\n",
        "        # Compute logits\n",
        "        logits = self.model(\n",
        "            input_ids=x_enc[\"input_ids\"],\n",
        "            decoder_input_ids=y_enc[\"input_ids\"],\n",
        "            attention_mask=x_enc[\"attention_mask\"],\n",
        "            decoder_attention_mask=y_enc[\"attention_mask\"],\n",
        "        ).logits\n",
        "\n",
        "        # Compute token-level likelihood\n",
        "        shifted_logits = logits[..., :-1, :].contiguous()\n",
        "        shifted_labels = y_enc[\"input_ids\"][..., 1:].contiguous()\n",
        "\n",
        "        likelihood = -loss_fn(\n",
        "            shifted_logits.view(-1, shifted_logits.size(-1)),\n",
        "            shifted_labels.view(-1),\n",
        "        )\n",
        "\n",
        "        likelihood = likelihood.view(len(x), -1).sum(dim=-1)\n",
        "        if mean:\n",
        "            likelihood /= (y_enc[\"input_ids\"] != self.tokenizer.pad_token_id).float().sum(dim=-1)\n",
        "        return likelihood\n",
        "\n",
        "    def compute_similarity_enc(self, x: List[str], y: List[str]) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Compute semantic similarity for Encoder-only models (e.g., BERTSUM, SciBERT).\n",
        "        \"\"\"\n",
        "        assert len(x) == len(y), \"Source and summary lists must have the same length.\"\n",
        "\n",
        "        # Tokenize and encode\n",
        "        x_enc = self.tokenizer(x, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        y_enc = self.tokenizer(y, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "        x_enc = {k: v.to(self.device) for k, v in x_enc.items()}\n",
        "        y_enc = {k: v.to(self.device) for k, v in y_enc.items()}\n",
        "\n",
        "        # Generate embeddings\n",
        "        x_embeddings = self.model(**x_enc).last_hidden_state.mean(dim=1)\n",
        "        y_embeddings = self.model(**y_enc).last_hidden_state.mean(dim=1)\n",
        "\n",
        "        # Compute cosine similarity\n",
        "        return torch.nn.functional.cosine_similarity(x_embeddings, y_embeddings)\n",
        "\n",
        "    def compute_custom_long_context(self, x: List[str], y: List[str]) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Handle long-context models like LongFormer or BigBird.\n",
        "        \"\"\"\n",
        "        assert len(x) == len(y), \"Source and summary lists must have the same length.\"\n",
        "\n",
        "        # Concatenate source and summary for joint tokenization\n",
        "        inputs = [f\"{src} {summ}\" for src, summ in zip(x, y)]\n",
        "        encodings = self.tokenizer(inputs, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        encodings = {k: v.to(self.device) for k, v in encodings.items()}\n",
        "\n",
        "        # Compute logits\n",
        "        logits = self.model(**encodings).logits\n",
        "\n",
        "        # Convert logits to probabilities (assume binary classification task)\n",
        "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        return probabilities[:, 1]  # Adjust based on the model's task definition\n",
        "\n",
        "    def compute_custom_others(self, x: List[str], y: List[str]) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Handle special cases like ALL-MPNET or XLM-RoBERTa.\n",
        "        \"\"\"\n",
        "        assert len(x) == len(y), \"Source and summary lists must have the same length.\"\n",
        "\n",
        "        # Generate embeddings\n",
        "        x_embeddings = self.model.encode(x, convert_to_tensor=True)\n",
        "        y_embeddings = self.model.encode(y, convert_to_tensor=True)\n",
        "\n",
        "        # Compute cosine similarity\n",
        "        return torch.nn.functional.cosine_similarity(x_embeddings, y_embeddings)\n",
        "\n",
        "# Generalized dictionary for model-to-function mapping\n",
        "model_handlers: Dict[str, Dict] = {\n",
        "    \"ENC-DEC\": {\n",
        "        # BART: Different version\n",
        "        # PEGASUS: Different version (XSUM)\n",
        "        # T5: Different version (C4)\n",
        "        \n",
        "        \"models\": [\"BART\", \"PEGASUS\", \"T5\", \"mBART\", \"Flan-T5\"],\n",
        "        \"function\": \"compute_likelihood_enc_dec\",\n",
        "    },\n",
        "    \"ENC\": {\n",
        "        \"models\": [\"BERTSUM\", \"SciBERT\"],\n",
        "        \"function\": \"compute_similarity_enc\",\n",
        "    },\n",
        "    \"Others\": {\n",
        "        \"models\": [\"ALL-MPNET\", \"XLM-RoBERTa\"],\n",
        "        \"function\": \"compute_custom_others\",\n",
        "    },\n",
        "    \"LongContext\": {\n",
        "        \"models\": [\"LED\", \"BigBird-Pegasus\"],\n",
        "        \"function\": \"compute_custom_long_context\",\n",
        "    },\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
