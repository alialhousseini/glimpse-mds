{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alialhousseini/glimpse-mds/blob/main/NLP_main_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "collapsed": true,
        "id": "Zw-RQzb6OZXy",
        "outputId": "6cbc74a1-8497-42dc-af21-9a79f8cc320d"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEYXb3BiQ8ym",
        "outputId": "e29bbfb4-f8d1-4f56-fc77-39bdcbcfa9d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'glimpse-mds'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (239/239), done.\u001b[K\n",
            "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
            "remote: Total 239 (delta 137), reused 197 (delta 95), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (239/239), 31.63 MiB | 13.22 MiB/s, done.\n",
            "Resolving deltas: 100% (137/137), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/alialhousseini/glimpse-mds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DNVb_lnRFJ2",
        "outputId": "13aa3655-5d0d-4fc0-bc1d-8fe8e9444126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â¬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:10\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg3boMnMRZZh"
      },
      "outputs": [],
      "source": [
        "# Define the path for the new environment\n",
        "env_path = '/content/glimpse_env'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3Qv0rFyRiia",
        "outputId": "6176b362-e9cd-497d-caae-f9763cfafe29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 23.11.0\n",
            "    latest version: 24.11.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /content/glimpse_env\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.10\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    bzip2-1.0.8                |       h4bc722e_7         247 KB  conda-forge\n",
            "    ca-certificates-2024.8.30  |       hbcca054_0         155 KB  conda-forge\n",
            "    ld_impl_linux-64-2.43      |       h712a8e2_2         654 KB  conda-forge\n",
            "    libgcc-14.2.0              |       h77fa898_1         829 KB  conda-forge\n",
            "    libgcc-ng-14.2.0           |       h69a702a_1          53 KB  conda-forge\n",
            "    libgomp-14.2.0             |       h77fa898_1         450 KB  conda-forge\n",
            "    libsqlite-3.47.0           |       hadc24fc_1         855 KB  conda-forge\n",
            "    libxcrypt-4.4.36           |       hd590300_1          98 KB  conda-forge\n",
            "    libzlib-1.3.1              |       hb9d3cd8_2          60 KB  conda-forge\n",
            "    ncurses-6.5                |       he02047a_1         868 KB  conda-forge\n",
            "    openssl-3.4.0              |       hb9d3cd8_0         2.8 MB  conda-forge\n",
            "    pip-24.3.1                 |     pyh8b19718_0         1.2 MB  conda-forge\n",
            "    python-3.10.15             |h4a871b0_2_cpython        24.1 MB  conda-forge\n",
            "    setuptools-75.6.0          |     pyhff2d567_1         756 KB  conda-forge\n",
            "    tzdata-2024b               |       hc8b5060_0         119 KB  conda-forge\n",
            "    wheel-0.45.1               |     pyhd8ed1ab_0          62 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        33.2 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h4bc722e_7 \n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2024.8.30-hbcca054_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.43-h712a8e2_2 \n",
            "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 \n",
            "  libgcc             conda-forge/linux-64::libgcc-14.2.0-h77fa898_1 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-14.2.0-h69a702a_1 \n",
            "  libgomp            conda-forge/linux-64::libgomp-14.2.0-h77fa898_1 \n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.47.0-hadc24fc_1 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 \n",
            "  libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.5-he02047a_1 \n",
            "  openssl            conda-forge/linux-64::openssl-3.4.0-hb9d3cd8_0 \n",
            "  pip                conda-forge/noarch::pip-24.3.1-pyh8b19718_0 \n",
            "  python             conda-forge/linux-64::python-3.10.15-h4a871b0_2_cpython \n",
            "  readline           conda-forge/linux-64::readline-8.2-h8228510_1 \n",
            "  setuptools         conda-forge/noarch::setuptools-75.6.0-pyhff2d567_1 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 \n",
            "  tzdata             conda-forge/noarch::tzdata-2024b-hc8b5060_0 \n",
            "  wheel              conda-forge/noarch::wheel-0.45.1-pyhd8ed1ab_0 \n",
            "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "python-3.10.15       | 24.1 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "openssl-3.4.0        | 2.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "pip-24.3.1           | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.47.0     | 855 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 829 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 450 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 155 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024b         | 119 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 62 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libzlib-1.3.1        | 60 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.15       | 24.1 MB   | :   0% 0.0025881930044147692/1 [00:00<00:39, 40.03s/it]\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.47.0     | 855 KB    | :   2% 0.018717105977158824/1 [00:00<00:05,  5.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "openssl-3.4.0        | 2.8 MB    | :   1% 0.005558673111072358/1 [00:00<00:19, 19.77s/it]\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | :   2% 0.018427913610156946/1 [00:00<00:05,  5.99s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "python-3.10.15       | 24.1 MB   | :  18% 0.17664417255130802/1 [00:00<00:00,  1.02it/s]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 829 KB    | :   2% 0.019303795604097816/1 [00:00<00:10, 10.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "openssl-3.4.0        | 2.8 MB    | :  93% 0.9338570826601562/1 [00:00<00:00,  5.24it/s]  \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | :   2% 0.021161069005956715/1 [00:00<00:10, 10.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | :   2% 0.024482562300978315/1 [00:00<00:09, 10.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.47.0     | 855 KB    | : 100% 1.0/1 [00:00<00:00,  4.16it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.47.0     | 855 KB    | : 100% 1.0/1 [00:00<00:00,  4.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.15       | 24.1 MB   | :  31% 0.30734791927425387/1 [00:00<00:00,  1.15it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | :   6% 0.06481448515129577/1 [00:00<00:04,  4.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 155 KB    | :  10% 0.10304208096702577/1 [00:00<00:02,  3.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | :  16% 0.163198629386511/1 [00:00<00:01,  2.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024b         | 119 KB    | :  13% 0.1339065335011524/1 [00:00<00:02,  2.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 62 KB     | :  26% 0.26007174830947016/1 [00:00<00:01,  1.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libzlib-1.3.1        | 60 KB     | :  27% 0.2687531781572429/1 [00:00<00:00,  1.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.15       | 24.1 MB   | :  93% 0.9291612885849022/1 [00:00<00:00,  1.84it/s]\n",
            "\n",
            "pip-24.3.1           | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.07it/s]                 \u001b[A\u001b[A\n",
            "\n",
            "pip-24.3.1           | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 829 KB    | : 100% 1.0/1 [00:01<00:00,  1.05s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 829 KB    | : 100% 1.0/1 [00:01<00:00,  1.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | : 100% 1.0/1 [00:01<00:00,  1.56s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-75.6.0    | 756 KB    | : 100% 1.0/1 [00:01<00:00,  1.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | : 100% 1.0/1 [00:01<00:00,  1.62s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 654 KB    | : 100% 1.0/1 [00:01<00:00,  1.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "openssl-3.4.0        | 2.8 MB    | : 100% 1.0/1 [00:01<00:00,  5.24it/s]               \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 450 KB    | : 100% 1.0/1 [00:02<00:00,  2.01s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 450 KB    | : 100% 1.0/1 [00:02<00:00,  2.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | : 100% 1.0/1 [00:02<00:00,  2.07s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 247 KB    | : 100% 1.0/1 [00:02<00:00,  2.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 155 KB    | : 100% 1.0/1 [00:02<00:00,  2.11s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 155 KB    | : 100% 1.0/1 [00:02<00:00,  2.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | : 100% 1.0/1 [00:02<00:00,  2.18s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | : 100% 1.0/1 [00:02<00:00,  2.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | : 100% 1.0/1 [00:02<00:00,  2.58s/it]                 \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 868 KB    | : 100% 1.0/1 [00:02<00:00,  2.58s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 62 KB     | : 100% 1.0/1 [00:02<00:00,  2.75s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 62 KB     | : 100% 1.0/1 [00:02<00:00,  2.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024b         | 119 KB    | : 100% 1.0/1 [00:02<00:00,  2.66s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024b         | 119 KB    | : 100% 1.0/1 [00:02<00:00,  2.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libzlib-1.3.1        | 60 KB     | : 100% 1.0/1 [00:02<00:00,  2.78s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libzlib-1.3.1        | 60 KB     | : 100% 1.0/1 [00:02<00:00,  2.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-14.2.0     | 53 KB     | : 100% 1.0/1 [00:02<00:00,  2.87s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate /content/glimpse_env\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the Conda environment in the specified folder\n",
        "!conda create --prefix \"$env_path\" python=3.10 -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_Cq1BZpRp0O"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!source activate /content/glimpse_env && pip install -r /content/glimpse-mds/requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Extension 1: Use an ensemble set of models for producing RSA scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| **Model**           | **Small Definition**                                                                                                         | **Model Ability and Performance**                                                                   | **Why Choose This**                                                                                       | **Purpose**                                                                                      |\n",
        "|----------------------|-----------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|\n",
        "| **BART**            | A transformer model optimized for sequence-to-sequence tasks like summarization and translation.                           | Focuses on fluency and readability with strong abstractive summarization capabilities.              | Pretrained on a diverse dataset, excels in generating coherent and fluent summaries.                      | Abstractive summarization and text generation tasks.                                            |\n",
        "| **PEGASUS**         | A transformer model designed for summarization with gap-sentence generation pretraining.                                    | Excels at abstractive summarization and capturing document essence.                                 | Strong performance on summarization benchmarks like CNN/DailyMail and XSum.                               | Creating concise and coherent abstractive summaries.                                            |\n",
        "| **T5**              | A unified text-to-text transformer model capable of handling multiple NLP tasks.                                            | Balances fluency, factual consistency, and flexibility across tasks.                                | Suitable for multitask setups with state-of-the-art results on summarization and NLI.                     | Summarization, translation, and text classification.                                            |\n",
        "| **LED**             | A long-context version of BART tailored for summarizing long documents.                                                     | Processes up to 16,384 tokens, maintaining coherence and relevance over long contexts.              | Handles lengthy academic or technical documents effectively.                                              | Summarization of research papers, reports, and other long-form texts.                          |\n",
        "| **BigBird-Pegasus** | A sparse-attention model designed for efficient processing of long documents.                                               | Balances computational efficiency with performance on long-form summarization tasks.                | Efficiently handles long contexts while preserving critical information.                                  | Summarization and classification for long texts.                                                |\n",
        "| **PEGASUS (XSUM)**  | A PEGASUS model fine-tuned specifically on the XSum dataset for abstractive summarization.                                  | Produces highly concise summaries but can sometimes lose factual consistency.                       | Ideal for tasks requiring short, highly abstractive summaries.                                            | Summarizing news articles or brief documents.                                                   |\n",
        "| **DistilBART**      | A distilled version of BART with faster inference and smaller size.                                                         | Slightly reduced fluency compared to BART but much faster and more efficient.                       | Useful for scenarios with computational constraints.                                                      | Quick summarization and inference on resource-limited systems.                                 |\n",
        "| **mBART**           | A multilingual version of BART pre-trained on multiple languages.                                                           | Handles cross-lingual summarization and translation tasks effectively.                              | Ideal for multilingual datasets and scenarios involving diverse languages.                                | Summarization and translation for non-English or multilingual texts.                           |\n",
        "| **Flan-T5**         | A fine-tuned version of T5 for enhanced task performance, including summarization and reasoning.                            | Improves generalization and performance across multiple NLP tasks.                                  | Great for zero-shot and few-shot setups, with excellent task-specific adaptation.                         | Summarization, classification, and text reasoning.                                              |\n",
        "| **BERTSUM**         | A fine-tuned BERT model for extractive summarization tasks.                                                                 | Excels at identifying and extracting key sentences from texts.                                      | Reliable for extracting main points without paraphrasing.                                                 | Extractive summarization of structured documents.                                               |\n",
        "| **FactPEGASUS**     | A fine-tuned PEGASUS model for ensuring factual consistency in summaries.                                                    | Focuses on generating factually accurate abstractive summaries.                                     | Essential for tasks where factual correctness is critical.                                                | Summarization for sensitive or factual information.                                             |\n",
        "| **CTRLsumm**        | A fine-tuned model designed for conversational summarization.                                                               | Captures conversational nuances and preserves dialogue structure in summaries.                      | Ideal for summarizing meetings, chats, or interview transcripts.                                          | Summarization of conversational or dialogue-based content.                                      |\n",
        "| **SciBERT**         | A BERT model trained on scientific literature.                                                                              | Captures domain-specific vocabulary and syntax effectively.                                         | Tailored for summarizing or analyzing scholarly articles and scientific texts.                            | Text summarization, classification, and entity recognition in scientific domains.               |\n",
        "| **ALL-MPNET**       | A sentence transformer optimized for semantic similarity tasks.                                                              | Measures semantic similarity with high accuracy.                                                    | Ideal for evaluating consistency between source text and summaries.                                       | Consistency checking and similarity analysis.                                                   |\n",
        "| **XLM-ROBERTA**     | A multilingual transformer model with strong cross-lingual understanding capabilities.                                       | Excels in multilingual understanding and summarization tasks.                                       | Suitable for multilingual datasets or cross-lingual consistency evaluation.                               | Multilingual summarization and text classification.                                             |\n",
        "| **LongFormer-LARGE**| A transformer optimized for handling long contexts efficiently using sparse attention.                                       | Processes long documents with improved computational efficiency and accuracy.                       | Handles dense academic or technical texts requiring long-form attention.                                  | Summarization and question answering for long-form texts.                                       |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U8CRIj3USAL3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def consensus_scores_based_summaries(sample, n_consensus=3, n_dissensus=3):\n",
        "    consensus_samples = sample['consensuality_scores'].sort_values(ascending=True).head(n_consensus).index.tolist()\n",
        "    disensus_samples = sample['consensuality_scores'].sort_values(ascending=False).head(n_dissensus).index.tolist()\n",
        "    \n",
        "    consensus = \".\".join(consensus_samples)\n",
        "    disensus = \".\".join(disensus_samples)\n",
        "    \n",
        "    return consensus + \"\\n\\n\" + disensus\n",
        "    \n",
        "    \n",
        "def rsa_scores_based_summaries(sample, n_consensus=3, n_rsa_speaker=3):\n",
        "    consensus_samples = sample['consensuality_scores'].sort_values(ascending=True).head(n_consensus).index.tolist()\n",
        "    rsa = sample['best_rsa'].tolist()[:n_rsa_speaker]\n",
        "    \n",
        "    consensus = \".\".join(consensus_samples)\n",
        "    rsa = \".\".join(rsa)\n",
        "    \n",
        "    return consensus + \"\\n\\n\" + rsa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dftest = pd.read_csv('data/candidates/extractive_sentences-_-all_reviews_2017-_-none-_-2024-12-23-21-11-00.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>gold</th>\n",
              "      <th>summary</th>\n",
              "      <th>id_candidate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                         id  \\\n",
              "0      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "\n",
              "                                                text  \\\n",
              "0  Summary: The paper presents low-rank bilinear ...   \n",
              "\n",
              "                                                gold  \\\n",
              "0  The program committee appreciates the authors'...   \n",
              "\n",
              "                                             summary  id_candidate  \n",
              "0  Summary: The paper presents low-rank bilinear ...             0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dftest[dftest.index == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['Summary: The paper presents low-rank bilinear pooling that uses Hadamard product (commonly known as element-wise multiplication). The paper implements low-rank bilinear pooling on an existing model (Kim et al., 2016b) and builds a model for Visual Question Answering (VQA) that outperforms the current state-of-art by 0.42%. The paper presents various ablation studies of the new VQA model they built.----------------Strengths:----------------1. The paper presents new insights into element-wise multiplication operation which has been previously used in VQA literature (such as Antol et al., ICCV 2015) without insights on why it should work. ----------------2. The paper presents a new model for the task of VQA that beats the current state-of-art by 0.42%. However, I have concerns about the statistical significance of the performance (see weaknesses below).----------------3. The various design choices made in model development have been experimentally verified. ----------------Weaknesses/Suggestions:----------------1. When authors explicitly (keeping rest of the model architecture same) compared low-rank bilinear pooling with compact bilinear pooling, they found that low-rank bilinear pooling performs worse. Hence, it could not be experimentally verified that low-rank bilinear pooling is better in performance than compact bilinear pooling (at least for the task of VQA).----------------2. The authors argue that low-rank bilinear pooling uses 25% less parameters than compact bilinear pooling. So, could the authors please explain how does the reduction in number of parameters help experimentally? Does the training time of the model reduce significantly? Can we train the model with less data? ----------------3. One of the contributions of the paper is that the proposed model outperforms the current state-of-art on VQA by 0.42%. However, I am skeptical that the performance of the proposed model is statistically significantly better than the current state-of-art.----------------4. I would like the authors to explicitly mention the differences between MRN, MARN and MLB. It is not very clear from reading the paper.----------------5. In the caption for Table 1, fix the following: â€œhave notâ€ -> â€œhave noâ€ ----------------Review Summary: I like the insights about low-rank bilinear pooling using Hadamard product (element-wise multiplication) presented in the paper. However, it could not be justified that low-rank bilinear pooling leads to better performance than compact biliear pooling. It does lead to reduction in number of parameters but it is not clear how much that helps experimentally. So, to be more convinced I would like the authors to provide experimental justification of why low-rank bilinear pooling is better than other forms of pooling.',\n",
              "        'Summary: The paper presents low-rank bilinear pooling that uses Hadamard product (commonly known as element-wise multiplication).'],\n",
              "       ['Summary: The paper presents low-rank bilinear pooling that uses Hadamard product (commonly known as element-wise multiplication). The paper implements low-rank bilinear pooling on an existing model (Kim et al., 2016b) and builds a model for Visual Question Answering (VQA) that outperforms the current state-of-art by 0.42%. The paper presents various ablation studies of the new VQA model they built.----------------Strengths:----------------1. The paper presents new insights into element-wise multiplication operation which has been previously used in VQA literature (such as Antol et al., ICCV 2015) without insights on why it should work. ----------------2. The paper presents a new model for the task of VQA that beats the current state-of-art by 0.42%. However, I have concerns about the statistical significance of the performance (see weaknesses below).----------------3. The various design choices made in model development have been experimentally verified. ----------------Weaknesses/Suggestions:----------------1. When authors explicitly (keeping rest of the model architecture same) compared low-rank bilinear pooling with compact bilinear pooling, they found that low-rank bilinear pooling performs worse. Hence, it could not be experimentally verified that low-rank bilinear pooling is better in performance than compact bilinear pooling (at least for the task of VQA).----------------2. The authors argue that low-rank bilinear pooling uses 25% less parameters than compact bilinear pooling. So, could the authors please explain how does the reduction in number of parameters help experimentally? Does the training time of the model reduce significantly? Can we train the model with less data? ----------------3. One of the contributions of the paper is that the proposed model outperforms the current state-of-art on VQA by 0.42%. However, I am skeptical that the performance of the proposed model is statistically significantly better than the current state-of-art.----------------4. I would like the authors to explicitly mention the differences between MRN, MARN and MLB. It is not very clear from reading the paper.----------------5. In the caption for Table 1, fix the following: â€œhave notâ€ -> â€œhave noâ€ ----------------Review Summary: I like the insights about low-rank bilinear pooling using Hadamard product (element-wise multiplication) presented in the paper. However, it could not be justified that low-rank bilinear pooling leads to better performance than compact biliear pooling. It does lead to reduction in number of parameters but it is not clear how much that helps experimentally. So, to be more convinced I would like the authors to provide experimental justification of why low-rank bilinear pooling is better than other forms of pooling.',\n",
              "        'The paper implements low-rank bilinear pooling on an existing model (Kim et al., 2016b) and builds a model for Visual Question Answering (VQA) that outperforms the current state-of-art by 0.42%.']],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dftest[dftest['id']=='https://openreview.net/forum?id=r1rhWnZkg'][:2][['text', 'summary']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "dftest = dftest.head(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Item 1 has the text and first sentence\n",
        "- Item 2 has the text and the second sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from rsasumm.rsa_reranker import RSAReranking\n",
        "from transformers import AutoModelForSeq2SeqLM, BartTokenizer\n",
        "torch.cuda.empty_cache()\n",
        "model_id = 'facebook/bart-large-cnn'\n",
        "model = model = AutoModelForSeq2SeqLM.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
        "tokenizer = BartTokenizer.from_pretrained(model_id)\n",
        "\n",
        "reranker = RSAReranking(\n",
        "    model= model,\n",
        "    tokenizer= tokenizer,\n",
        "    candidates=dftest['summary'].tolist(),\n",
        "    source_texts=dftest['text'].tolist(),\n",
        "    batch_size=8,\n",
        "    rationality=1,\n",
        "    device=\"cuda\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/13 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:13<00:00,  1.03s/it]\n"
          ]
        }
      ],
      "source": [
        "best_rsa, best_base, speaker_df, listener_df, initial_listener_proba, initial_speaker_proba, initital_consensuality_score, consensuality_scores = reranker.rerank(t=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 10)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_speaker_proba.values.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>gold</th>\n",
              "      <th>summary</th>\n",
              "      <th>id_candidate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [index, id, text, gold, summary, id_candidate]\n",
              "Index: []"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dftest[dftest['id']=='https://openreview.net/forum?id=r1rhWnZkg']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['---- The \"feature control\" idea is not validated empirically (the preliminary experiment in Fig.',\n",
              "       'The employed test set of 100 programs seems rather small.',\n",
              "       'I think there may be a nice paper to made from this, but as it is, it should not be accepted.',\n",
              "       \"The authors don't provide enough discussion of the relative importance of these parts.\",\n",
              "       '-Minor comments:\\n---- P and Q seem to be undefined.',\n",
              "       '-- Only the dropout rate p=0.5 was used across experiments, while the optimal rate is problem dependent, as found by earlier published work.',\n",
              "       'The human evaluation presented in the paper is not satisfactory because the human performance is reported on a very small subset (200 questions).',\n",
              "       'handcrafted filter sizes) and based on the evaluation it seems to improve the results and help to avoid over-fitting (probably due to reduced filter size and thus number of parameters).',\n",
              "       '2016',\n",
              "       'To the best of my knowledge this is the first paper that considers adversarial examples for generative models.'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_rsa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "dftest['best_rsa'] = best_rsa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "dftest['consensuality_scores'] = consensuality_scores.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>gold</th>\n",
              "      <th>summary</th>\n",
              "      <th>id_candidate</th>\n",
              "      <th>best_rsa</th>\n",
              "      <th>consnsuality_scores</th>\n",
              "      <th>consensuality_scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14829</th>\n",
              "      <td>955</td>\n",
              "      <td>https://openreview.net/forum?id=SJ6yPD5xg</td>\n",
              "      <td>This paper is about improving feature learning...</td>\n",
              "      <td>There was broad consensus by the reviewers tha...</td>\n",
              "      <td>---- The \"feature control\" idea is not validat...</td>\n",
              "      <td>12</td>\n",
              "      <td>---- The \"feature control\" idea is not validat...</td>\n",
              "      <td>1.690573</td>\n",
              "      <td>1.690573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9621</th>\n",
              "      <td>614</td>\n",
              "      <td>https://openreview.net/forum?id=ByldLrqlx</td>\n",
              "      <td>The paper presents a technique to combine deep...</td>\n",
              "      <td>This is a well written paper that attempts to ...</td>\n",
              "      <td>The employed test set of 100 programs seems ra...</td>\n",
              "      <td>7</td>\n",
              "      <td>The employed test set of 100 programs seems ra...</td>\n",
              "      <td>1.161712</td>\n",
              "      <td>1.161712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13093</th>\n",
              "      <td>838</td>\n",
              "      <td>https://openreview.net/forum?id=BkJsCIcgl</td>\n",
              "      <td>I think there may be a nice paper to made from...</td>\n",
              "      <td>There is potential here for a great paper, unf...</td>\n",
              "      <td>I think there may be a nice paper to made from...</td>\n",
              "      <td>0</td>\n",
              "      <td>I think there may be a nice paper to made from...</td>\n",
              "      <td>0.972531</td>\n",
              "      <td>0.972531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18594</th>\n",
              "      <td>1175</td>\n",
              "      <td>https://openreview.net/forum?id=Hku9NK5lx</td>\n",
              "      <td>This work introduces a number of techniques to...</td>\n",
              "      <td>The reviewers unanimously recommended acceptin...</td>\n",
              "      <td>The authors don't provide enough discussion of...</td>\n",
              "      <td>9</td>\n",
              "      <td>The authors don't provide enough discussion of...</td>\n",
              "      <td>0.915484</td>\n",
              "      <td>0.915484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8857</th>\n",
              "      <td>569</td>\n",
              "      <td>https://openreview.net/forum?id=SJvYgH9xe</td>\n",
              "      <td>This work proposes a pattern extraction method...</td>\n",
              "      <td>The equation between (8) - (9) seems to be inc...</td>\n",
              "      <td>-Minor comments:\\n---- P and Q seem to be unde...</td>\n",
              "      <td>10</td>\n",
              "      <td>-Minor comments:\\n---- P and Q seem to be unde...</td>\n",
              "      <td>1.622159</td>\n",
              "      <td>1.622159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5607</th>\n",
              "      <td>367</td>\n",
              "      <td>https://openreview.net/forum?id=HJ1JBJ5gl</td>\n",
              "      <td>This paper investigates whether the variationa...</td>\n",
              "      <td>The reviewers unanimously recommend rejecting ...</td>\n",
              "      <td>-- Only the dropout rate p=0.5 was used across...</td>\n",
              "      <td>5</td>\n",
              "      <td>-- Only the dropout rate p=0.5 was used across...</td>\n",
              "      <td>1.307342</td>\n",
              "      <td>1.307342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19015</th>\n",
              "      <td>1205</td>\n",
              "      <td>https://openreview.net/forum?id=ry3iBFqgl</td>\n",
              "      <td>Summary: The paper proposes a novel machine co...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>The human evaluation presented in the paper is...</td>\n",
              "      <td>12</td>\n",
              "      <td>The human evaluation presented in the paper is...</td>\n",
              "      <td>1.279732</td>\n",
              "      <td>1.279732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8817</th>\n",
              "      <td>565</td>\n",
              "      <td>https://openreview.net/forum?id=HkpLeH9el</td>\n",
              "      <td>This paper presents design decisions of Terpre...</td>\n",
              "      <td>Quality, Clarity: There is no consensus on thi...</td>\n",
              "      <td>2016</td>\n",
              "      <td>17</td>\n",
              "      <td>handcrafted filter sizes) and based on the eva...</td>\n",
              "      <td>1.340523</td>\n",
              "      <td>1.340523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22721</th>\n",
              "      <td>1448</td>\n",
              "      <td>https://openreview.net/forum?id=S1TER2oll</td>\n",
              "      <td>This work proposes a way how to learn filter s...</td>\n",
              "      <td>Using covariance analysis for designing convol...</td>\n",
              "      <td>handcrafted filter sizes) and based on the eva...</td>\n",
              "      <td>5</td>\n",
              "      <td>2016</td>\n",
              "      <td>0.467946</td>\n",
              "      <td>0.467946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21699</th>\n",
              "      <td>1382</td>\n",
              "      <td>https://openreview.net/forum?id=SJk01vogl</td>\n",
              "      <td>This paper considers different methods of prod...</td>\n",
              "      <td>The main idea in this paper is interesting, of...</td>\n",
              "      <td>To the best of my knowledge this is the first ...</td>\n",
              "      <td>3</td>\n",
              "      <td>To the best of my knowledge this is the first ...</td>\n",
              "      <td>1.124992</td>\n",
              "      <td>1.124992</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       index                                         id  \\\n",
              "14829    955  https://openreview.net/forum?id=SJ6yPD5xg   \n",
              "9621     614  https://openreview.net/forum?id=ByldLrqlx   \n",
              "13093    838  https://openreview.net/forum?id=BkJsCIcgl   \n",
              "18594   1175  https://openreview.net/forum?id=Hku9NK5lx   \n",
              "8857     569  https://openreview.net/forum?id=SJvYgH9xe   \n",
              "5607     367  https://openreview.net/forum?id=HJ1JBJ5gl   \n",
              "19015   1205  https://openreview.net/forum?id=ry3iBFqgl   \n",
              "8817     565  https://openreview.net/forum?id=HkpLeH9el   \n",
              "22721   1448  https://openreview.net/forum?id=S1TER2oll   \n",
              "21699   1382  https://openreview.net/forum?id=SJk01vogl   \n",
              "\n",
              "                                                    text  \\\n",
              "14829  This paper is about improving feature learning...   \n",
              "9621   The paper presents a technique to combine deep...   \n",
              "13093  I think there may be a nice paper to made from...   \n",
              "18594  This work introduces a number of techniques to...   \n",
              "8857   This work proposes a pattern extraction method...   \n",
              "5607   This paper investigates whether the variationa...   \n",
              "19015  Summary: The paper proposes a novel machine co...   \n",
              "8817   This paper presents design decisions of Terpre...   \n",
              "22721  This work proposes a way how to learn filter s...   \n",
              "21699  This paper considers different methods of prod...   \n",
              "\n",
              "                                                    gold  \\\n",
              "14829  There was broad consensus by the reviewers tha...   \n",
              "9621   This is a well written paper that attempts to ...   \n",
              "13093  There is potential here for a great paper, unf...   \n",
              "18594  The reviewers unanimously recommended acceptin...   \n",
              "8857   The equation between (8) - (9) seems to be inc...   \n",
              "5607   The reviewers unanimously recommend rejecting ...   \n",
              "19015  The program committee appreciates the authors'...   \n",
              "8817   Quality, Clarity: There is no consensus on thi...   \n",
              "22721  Using covariance analysis for designing convol...   \n",
              "21699  The main idea in this paper is interesting, of...   \n",
              "\n",
              "                                                 summary  id_candidate  \\\n",
              "14829  ---- The \"feature control\" idea is not validat...            12   \n",
              "9621   The employed test set of 100 programs seems ra...             7   \n",
              "13093  I think there may be a nice paper to made from...             0   \n",
              "18594  The authors don't provide enough discussion of...             9   \n",
              "8857   -Minor comments:\\n---- P and Q seem to be unde...            10   \n",
              "5607   -- Only the dropout rate p=0.5 was used across...             5   \n",
              "19015  The human evaluation presented in the paper is...            12   \n",
              "8817                                                2016            17   \n",
              "22721  handcrafted filter sizes) and based on the eva...             5   \n",
              "21699  To the best of my knowledge this is the first ...             3   \n",
              "\n",
              "                                                best_rsa  consnsuality_scores  \\\n",
              "14829  ---- The \"feature control\" idea is not validat...             1.690573   \n",
              "9621   The employed test set of 100 programs seems ra...             1.161712   \n",
              "13093  I think there may be a nice paper to made from...             0.972531   \n",
              "18594  The authors don't provide enough discussion of...             0.915484   \n",
              "8857   -Minor comments:\\n---- P and Q seem to be unde...             1.622159   \n",
              "5607   -- Only the dropout rate p=0.5 was used across...             1.307342   \n",
              "19015  The human evaluation presented in the paper is...             1.279732   \n",
              "8817   handcrafted filter sizes) and based on the eva...             1.340523   \n",
              "22721                                               2016             0.467946   \n",
              "21699  To the best of my knowledge this is the first ...             1.124992   \n",
              "\n",
              "       consensuality_scores  \n",
              "14829              1.690573  \n",
              "9621               1.161712  \n",
              "13093              0.972531  \n",
              "18594              0.915484  \n",
              "8857               1.622159  \n",
              "5607               1.307342  \n",
              "19015              1.279732  \n",
              "8817               1.340523  \n",
              "22721              0.467946  \n",
              "21699              1.124992  "
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dftest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14829    1.690573\n",
              "9621     1.161712\n",
              "13093    0.972531\n",
              "18594    0.915484\n",
              "8857     1.622159\n",
              "5607     1.307342\n",
              "19015    1.279732\n",
              "8817     1.340523\n",
              "22721    0.467946\n",
              "21699    1.124992\n",
              "Name: consnsuality_scores, dtype: float32"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dftest['consnsuality_scores']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'consensuality_scores'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32md:\\Github\\glimpse-mds\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'consensuality_scores'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[55], line 20\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# def consensus_scores_based_summaries(sample: DataFrame Element, n_consensus=3, n_dissensus=3):\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#     consensus_samples = sample['consensuality_scores'].sort_values(ascending=True).head(n_consensus).index.tolist()\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#     disensus_samples = sample['consensuality_scores'].sort_values(ascending=False).head(n_dissensus).index.tolist()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#     return consensus + \"\\n\\n\" + rsa\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mconsensus_scores_based_summaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdftest\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[52], line 2\u001b[0m, in \u001b[0;36mconsensus_scores_based_summaries\u001b[1;34m(sample, n_consensus, n_dissensus)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconsensus_scores_based_summaries\u001b[39m(sample, n_consensus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_dissensus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     consensus_samples \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconsensuality_scores\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(n_consensus)\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      3\u001b[0m     disensus_samples \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconsensuality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(n_dissensus)\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      5\u001b[0m     consensus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(consensus_samples)\n",
            "File \u001b[1;32md:\\Github\\glimpse-mds\\env\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[1;32md:\\Github\\glimpse-mds\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'consensuality_scores'"
          ]
        }
      ],
      "source": [
        "# def consensus_scores_based_summaries(sample: DataFrame Element, n_consensus=3, n_dissensus=3):\n",
        "#     consensus_samples = sample['consensuality_scores'].sort_values(ascending=True).head(n_consensus).index.tolist()\n",
        "#     disensus_samples = sample['consensuality_scores'].sort_values(ascending=False).head(n_dissensus).index.tolist()\n",
        "    \n",
        "#     consensus = \".\".join(consensus_samples)\n",
        "#     disensus = \".\".join(disensus_samples)\n",
        "    \n",
        "#     return consensus + \"\\n\\n\" + disensus\n",
        "    \n",
        "    \n",
        "# def rsa_scores_based_summaries(sample, n_consensus=3, n_rsa_speaker=3):\n",
        "#     consensus_samples = sample['consensuality_scores'].sort_values(ascending=True).head(n_consensus).index.tolist()\n",
        "#     rsa = sample['best_rsa'].tolist()[:n_rsa_speaker]\n",
        "    \n",
        "#     consensus = \".\".join(consensus_samples)\n",
        "#     rsa = \".\".join(rsa)\n",
        "    \n",
        "#     return consensus + \"\\n\\n\" + rsa\n",
        "\n",
        "consensus_scores_based_summaries(dftest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def compute_rsa(summaries: pd.DataFrame, model, tokenizer, device):\n",
        "    results = []\n",
        "\n",
        "    for name, group in tqdm(summaries.groupby([\"id\"])):\n",
        "        print(name)\n",
        "        print(group)\n",
        "        rsa_reranker = RSAReranking(\n",
        "            model,\n",
        "            tokenizer,\n",
        "            device=device,\n",
        "            candidates=group.summary.unique().tolist(),\n",
        "            source_texts=group.text.unique().tolist(),\n",
        "            batch_size=32,\n",
        "            rationality=3,\n",
        "        )\n",
        "        (\n",
        "            best_rsa,\n",
        "            best_base,\n",
        "            speaker_df,\n",
        "            listener_df,\n",
        "            initial_listener,\n",
        "            language_model_proba_df,\n",
        "            initial_consensuality_scores,\n",
        "            consensuality_scores,\n",
        "        ) = rsa_reranker.rerank(t=2)\n",
        "\n",
        "        gold = group['gold'].tolist()[0]\n",
        "\n",
        "        results.append(\n",
        "            {\n",
        "                \"id\": name,\n",
        "                \"best_rsa\": best_rsa,  # best speaker score\n",
        "                \"best_base\": best_base,  # naive baseline\n",
        "                \"speaker_df\": speaker_df,  # all speaker results\n",
        "                # all listener results (chances of guessing correctly)\n",
        "                \"listener_df\": listener_df,\n",
        "                \"initial_listener\": initial_listener,\n",
        "                \"language_model_proba_df\": language_model_proba_df,\n",
        "                \"initial_consensuality_scores\": initial_consensuality_scores,\n",
        "                \"consensuality_scores\": consensuality_scores,  # uniqueness scores\n",
        "                \"gold\": gold,\n",
        "                \"rationality\": 3,  # hyperparameter\n",
        "                \"text_candidates\": group\n",
        "            }\n",
        "        )\n",
        "        \n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, BartTokenizer\n",
        "import torch\n",
        "model_id = 'facebook/bart-large-cnn'\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
        "tokenizer = BartTokenizer.from_pretrained(model_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('https://openreview.net/forum?id=r1rhWnZkg',)\n",
            "    index                                         id  \\\n",
            "0       0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "1       0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "2       0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "3       0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "4       0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "5       0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "6       0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "7       0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "8       0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "9       0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "10      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "11      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "12      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "13      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "14      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "15      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "16      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "17      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "18      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "19      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "20      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "21      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "22      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "23      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "24      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "25      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "26      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "27      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "28      0  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "29      1  https://openreview.net/forum?id=r1rhWnZkg   \n",
            "\n",
            "                                                 text  \\\n",
            "0   Summary: The paper presents low-rank bilinear ...   \n",
            "1   Summary: The paper presents low-rank bilinear ...   \n",
            "2   Summary: The paper presents low-rank bilinear ...   \n",
            "3   Summary: The paper presents low-rank bilinear ...   \n",
            "4   Summary: The paper presents low-rank bilinear ...   \n",
            "5   Summary: The paper presents low-rank bilinear ...   \n",
            "6   Summary: The paper presents low-rank bilinear ...   \n",
            "7   Summary: The paper presents low-rank bilinear ...   \n",
            "8   Summary: The paper presents low-rank bilinear ...   \n",
            "9   Summary: The paper presents low-rank bilinear ...   \n",
            "10  Summary: The paper presents low-rank bilinear ...   \n",
            "11  Summary: The paper presents low-rank bilinear ...   \n",
            "12  Summary: The paper presents low-rank bilinear ...   \n",
            "13  Summary: The paper presents low-rank bilinear ...   \n",
            "14  Summary: The paper presents low-rank bilinear ...   \n",
            "15  Summary: The paper presents low-rank bilinear ...   \n",
            "16  Summary: The paper presents low-rank bilinear ...   \n",
            "17  Summary: The paper presents low-rank bilinear ...   \n",
            "18  Summary: The paper presents low-rank bilinear ...   \n",
            "19  Summary: The paper presents low-rank bilinear ...   \n",
            "20  Summary: The paper presents low-rank bilinear ...   \n",
            "21  Summary: The paper presents low-rank bilinear ...   \n",
            "22  Summary: The paper presents low-rank bilinear ...   \n",
            "23  Summary: The paper presents low-rank bilinear ...   \n",
            "24  Summary: The paper presents low-rank bilinear ...   \n",
            "25  Summary: The paper presents low-rank bilinear ...   \n",
            "26  Summary: The paper presents low-rank bilinear ...   \n",
            "27  Summary: The paper presents low-rank bilinear ...   \n",
            "28  Summary: The paper presents low-rank bilinear ...   \n",
            "29  Results on the VQA task are good for this simp...   \n",
            "\n",
            "                                                 gold  \\\n",
            "0   The program committee appreciates the authors'...   \n",
            "1   The program committee appreciates the authors'...   \n",
            "2   The program committee appreciates the authors'...   \n",
            "3   The program committee appreciates the authors'...   \n",
            "4   The program committee appreciates the authors'...   \n",
            "5   The program committee appreciates the authors'...   \n",
            "6   The program committee appreciates the authors'...   \n",
            "7   The program committee appreciates the authors'...   \n",
            "8   The program committee appreciates the authors'...   \n",
            "9   The program committee appreciates the authors'...   \n",
            "10  The program committee appreciates the authors'...   \n",
            "11  The program committee appreciates the authors'...   \n",
            "12  The program committee appreciates the authors'...   \n",
            "13  The program committee appreciates the authors'...   \n",
            "14  The program committee appreciates the authors'...   \n",
            "15  The program committee appreciates the authors'...   \n",
            "16  The program committee appreciates the authors'...   \n",
            "17  The program committee appreciates the authors'...   \n",
            "18  The program committee appreciates the authors'...   \n",
            "19  The program committee appreciates the authors'...   \n",
            "20  The program committee appreciates the authors'...   \n",
            "21  The program committee appreciates the authors'...   \n",
            "22  The program committee appreciates the authors'...   \n",
            "23  The program committee appreciates the authors'...   \n",
            "24  The program committee appreciates the authors'...   \n",
            "25  The program committee appreciates the authors'...   \n",
            "26  The program committee appreciates the authors'...   \n",
            "27  The program committee appreciates the authors'...   \n",
            "28  The program committee appreciates the authors'...   \n",
            "29  The program committee appreciates the authors'...   \n",
            "\n",
            "                                              summary  id_candidate  \n",
            "0   Summary: The paper presents low-rank bilinear ...             0  \n",
            "1   The paper implements low-rank bilinear pooling...             1  \n",
            "2   The paper presents various ablation studies of...             2  \n",
            "3                                -Strengths:\\n\\n\\n-1.             3  \n",
            "4   The paper presents new insights into element-w...             4  \n",
            "5                                                 -2.             5  \n",
            "6   The paper presents a new model for the task of...             6  \n",
            "7   However, I have concerns about the statistical...             7  \n",
            "8                                                 -3.             8  \n",
            "9   The various design choices made in model devel...             9  \n",
            "10                  -Weaknesses/Suggestions:\\n\\n\\n-1.            10  \n",
            "11  When authors explicitly (keeping rest of the m...            11  \n",
            "12  Hence, it could not be experimentally verified...            12  \n",
            "13                                                -2.            13  \n",
            "14  The authors argue that low-rank bilinear pooli...            14  \n",
            "15  So, could the authors please explain how does ...            15  \n",
            "16  Does the training time of the model reduce sig...            16  \n",
            "17             Can we train the model with less data?            17  \n",
            "18                                                -3.            18  \n",
            "19  One of the contributions of the paper is that ...            19  \n",
            "20  However, I am skeptical that the performance o...            20  \n",
            "21                                                -4.            21  \n",
            "22  I would like the authors to explicitly mention...            22  \n",
            "23       It is not very clear from reading the paper.            23  \n",
            "24                                                -5.            24  \n",
            "25  In the caption for Table 1, fix the following:...            25  \n",
            "26  However, it could not be justified that low-ra...            26  \n",
            "27  It does lead to reduction in number of paramet...            27  \n",
            "28  So, to be more convinced I would like the auth...            28  \n",
            "29  Results on the VQA task are good for this simp...             0  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'RSAReranking' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_rsa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdftest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[10], line 9\u001b[0m, in \u001b[0;36mcompute_rsa\u001b[1;34m(summaries, model, tokenizer, device)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(name)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(group)\n\u001b[1;32m----> 9\u001b[0m rsa_reranker \u001b[38;5;241m=\u001b[39m \u001b[43mRSAReranking\u001b[49m(\n\u001b[0;32m     10\u001b[0m     model,\n\u001b[0;32m     11\u001b[0m     tokenizer,\n\u001b[0;32m     12\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m     13\u001b[0m     candidates\u001b[38;5;241m=\u001b[39mgroup\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[0;32m     14\u001b[0m     source_texts\u001b[38;5;241m=\u001b[39mgroup\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[0;32m     15\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     16\u001b[0m     rationality\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m (\n\u001b[0;32m     19\u001b[0m     best_rsa,\n\u001b[0;32m     20\u001b[0m     best_base,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     consensuality_scores,\n\u001b[0;32m     27\u001b[0m ) \u001b[38;5;241m=\u001b[39m rsa_reranker\u001b[38;5;241m.\u001b[39mrerank(t\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     29\u001b[0m gold \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgold\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m]\n",
            "\u001b[1;31mNameError\u001b[0m: name 'RSAReranking' is not defined"
          ]
        }
      ],
      "source": [
        "model = model.to(\"cuda\")\n",
        "res = compute_rsa(dftest, model, tokenizer, \"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dftest = pd.read_csv('data/candidates/extractive_sentences-_-all_reviews_2017-_-none-_-2024-12-23-21-11-00.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>gold</th>\n",
              "      <th>summary</th>\n",
              "      <th>id_candidate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>The paper implements low-rank bilinear pooling...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>The paper presents various ablation studies of...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>-Strengths:\\n\\n\\n-1.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>The paper presents new insights into element-w...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>2</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>This work proposes to approximate the bilinear...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>Related work: The comparison to the related wo...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>2</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>This work proposes to approximate the bilinear...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>----Minor\\n---- It is not clear why the Lu et ...</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>2</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>This work proposes to approximate the bilinear...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>---- Sect 2, first sentence: â€œevery pairsâ€ -&gt; ...</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>2</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>This work proposes to approximate the bilinear...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>It is a bit unfortunate that most of the exper...</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>2</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>This work proposes to approximate the bilinear...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>-To be more convincing I would like to see the...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    index                                         id  \\\n",
              "0       0  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "1       0  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "2       0  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "3       0  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "4       0  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "..    ...                                        ...   \n",
              "67      2  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "68      2  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "69      2  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "70      2  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "71      2  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "\n",
              "                                                 text  \\\n",
              "0   Summary: The paper presents low-rank bilinear ...   \n",
              "1   Summary: The paper presents low-rank bilinear ...   \n",
              "2   Summary: The paper presents low-rank bilinear ...   \n",
              "3   Summary: The paper presents low-rank bilinear ...   \n",
              "4   Summary: The paper presents low-rank bilinear ...   \n",
              "..                                                ...   \n",
              "67  This work proposes to approximate the bilinear...   \n",
              "68  This work proposes to approximate the bilinear...   \n",
              "69  This work proposes to approximate the bilinear...   \n",
              "70  This work proposes to approximate the bilinear...   \n",
              "71  This work proposes to approximate the bilinear...   \n",
              "\n",
              "                                                 gold  \\\n",
              "0   The program committee appreciates the authors'...   \n",
              "1   The program committee appreciates the authors'...   \n",
              "2   The program committee appreciates the authors'...   \n",
              "3   The program committee appreciates the authors'...   \n",
              "4   The program committee appreciates the authors'...   \n",
              "..                                                ...   \n",
              "67  The program committee appreciates the authors'...   \n",
              "68  The program committee appreciates the authors'...   \n",
              "69  The program committee appreciates the authors'...   \n",
              "70  The program committee appreciates the authors'...   \n",
              "71  The program committee appreciates the authors'...   \n",
              "\n",
              "                                              summary  id_candidate  \n",
              "0   Summary: The paper presents low-rank bilinear ...             0  \n",
              "1   The paper implements low-rank bilinear pooling...             1  \n",
              "2   The paper presents various ablation studies of...             2  \n",
              "3                                -Strengths:\\n\\n\\n-1.             3  \n",
              "4   The paper presents new insights into element-w...             4  \n",
              "..                                                ...           ...  \n",
              "67  Related work: The comparison to the related wo...            31  \n",
              "68  ----Minor\\n---- It is not clear why the Lu et ...            32  \n",
              "69  ---- Sect 2, first sentence: â€œevery pairsâ€ -> ...            33  \n",
              "70  It is a bit unfortunate that most of the exper...            34  \n",
              "71  -To be more convincing I would like to see the...            35  \n",
              "\n",
              "[72 rows x 6 columns]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dftest[dftest['id']=='https://openreview.net/forum?id=r1rhWnZkg']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Summary: The paper presents low-rank bilinear pooling that uses Hadamard product (commonly known as element-wise multiplication). The paper implements low-rank bilinear pooling on an existing model (Kim et al., 2016b) and builds a model for Visual Question Answering (VQA) that outperforms the current state-of-art by 0.42%. The paper presents various ablation studies of the new VQA model they built.----------------Strengths:----------------1. The paper presents new insights into element-wise multiplication operation which has been previously used in VQA literature (such as Antol et al., ICCV 2015) without insights on why it should work. ----------------2. The paper presents a new model for the task of VQA that beats the current state-of-art by 0.42%. However, I have concerns about the statistical significance of the performance (see weaknesses below).----------------3. The various design choices made in model development have been experimentally verified. ----------------Weaknesses/Suggestions:----------------1. When authors explicitly (keeping rest of the model architecture same) compared low-rank bilinear pooling with compact bilinear pooling, they found that low-rank bilinear pooling performs worse. Hence, it could not be experimentally verified that low-rank bilinear pooling is better in performance than compact bilinear pooling (at least for the task of VQA).----------------2. The authors argue that low-rank bilinear pooling uses 25% less parameters than compact bilinear pooling. So, could the authors please explain how does the reduction in number of parameters help experimentally? Does the training time of the model reduce significantly? Can we train the model with less data? ----------------3. One of the contributions of the paper is that the proposed model outperforms the current state-of-art on VQA by 0.42%. However, I am skeptical that the performance of the proposed model is statistically significantly better than the current state-of-art.----------------4. I would like the authors to explicitly mention the differences between MRN, MARN and MLB. It is not very clear from reading the paper.----------------5. In the caption for Table 1, fix the following: â€œhave notâ€ -> â€œhave noâ€ ----------------Review Summary: I like the insights about low-rank bilinear pooling using Hadamard product (element-wise multiplication) presented in the paper. However, it could not be justified that low-rank bilinear pooling leads to better performance than compact biliear pooling. It does lead to reduction in number of parameters but it is not clear how much that helps experimentally. So, to be more convinced I would like the authors to provide experimental justification of why low-rank bilinear pooling is better than other forms of pooling.'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "29\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "text = dftest[dftest['id']=='https://openreview.net/forum?id=r1rhWnZkg']['text'][0].replace('-----', '\\n')\n",
        "#print(text)\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "sentences = [sentence for sentence in sentences if sentence != \"\"]\n",
        "print(len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>gold</th>\n",
              "      <th>summary</th>\n",
              "      <th>id_candidate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>The paper implements low-rank bilinear pooling...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>The paper presents various ablation studies of...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>-Strengths:\\n\\n\\n-1.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>https://openreview.net/forum?id=r1rhWnZkg</td>\n",
              "      <td>Summary: The paper presents low-rank bilinear ...</td>\n",
              "      <td>The program committee appreciates the authors'...</td>\n",
              "      <td>The paper presents new insights into element-w...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23638</th>\n",
              "      <td>1510</td>\n",
              "      <td>https://openreview.net/forum?id=Sks9_ajex</td>\n",
              "      <td>This paper proposes to investigate attention t...</td>\n",
              "      <td>Important task (attention models), interesting...</td>\n",
              "      <td>-In summary:\\n---Pros:\\n---- Clearly written a...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23639</th>\n",
              "      <td>1510</td>\n",
              "      <td>https://openreview.net/forum?id=Sks9_ajex</td>\n",
              "      <td>This paper proposes to investigate attention t...</td>\n",
              "      <td>Important task (attention models), interesting...</td>\n",
              "      <td>---- Consistent improvement of the student wit...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23640</th>\n",
              "      <td>1510</td>\n",
              "      <td>https://openreview.net/forum?id=Sks9_ajex</td>\n",
              "      <td>This paper proposes to investigate attention t...</td>\n",
              "      <td>Important task (attention models), interesting...</td>\n",
              "      <td>---Cons:\\n---- Students have worst performance...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23641</th>\n",
              "      <td>1510</td>\n",
              "      <td>https://openreview.net/forum?id=Sks9_ajex</td>\n",
              "      <td>This paper proposes to investigate attention t...</td>\n",
              "      <td>Important task (attention models), interesting...</td>\n",
              "      <td>---- It is not clear which attention to use in...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23642</th>\n",
              "      <td>1510</td>\n",
              "      <td>https://openreview.net/forum?id=Sks9_ajex</td>\n",
              "      <td>This paper proposes to investigate attention t...</td>\n",
              "      <td>Important task (attention models), interesting...</td>\n",
              "      <td>---- Somewhat incremental novelty relatively t...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23643 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index                                         id  \\\n",
              "0          0  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "1          0  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "2          0  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "3          0  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "4          0  https://openreview.net/forum?id=r1rhWnZkg   \n",
              "...      ...                                        ...   \n",
              "23638   1510  https://openreview.net/forum?id=Sks9_ajex   \n",
              "23639   1510  https://openreview.net/forum?id=Sks9_ajex   \n",
              "23640   1510  https://openreview.net/forum?id=Sks9_ajex   \n",
              "23641   1510  https://openreview.net/forum?id=Sks9_ajex   \n",
              "23642   1510  https://openreview.net/forum?id=Sks9_ajex   \n",
              "\n",
              "                                                    text  \\\n",
              "0      Summary: The paper presents low-rank bilinear ...   \n",
              "1      Summary: The paper presents low-rank bilinear ...   \n",
              "2      Summary: The paper presents low-rank bilinear ...   \n",
              "3      Summary: The paper presents low-rank bilinear ...   \n",
              "4      Summary: The paper presents low-rank bilinear ...   \n",
              "...                                                  ...   \n",
              "23638  This paper proposes to investigate attention t...   \n",
              "23639  This paper proposes to investigate attention t...   \n",
              "23640  This paper proposes to investigate attention t...   \n",
              "23641  This paper proposes to investigate attention t...   \n",
              "23642  This paper proposes to investigate attention t...   \n",
              "\n",
              "                                                    gold  \\\n",
              "0      The program committee appreciates the authors'...   \n",
              "1      The program committee appreciates the authors'...   \n",
              "2      The program committee appreciates the authors'...   \n",
              "3      The program committee appreciates the authors'...   \n",
              "4      The program committee appreciates the authors'...   \n",
              "...                                                  ...   \n",
              "23638  Important task (attention models), interesting...   \n",
              "23639  Important task (attention models), interesting...   \n",
              "23640  Important task (attention models), interesting...   \n",
              "23641  Important task (attention models), interesting...   \n",
              "23642  Important task (attention models), interesting...   \n",
              "\n",
              "                                                 summary  id_candidate  \n",
              "0      Summary: The paper presents low-rank bilinear ...             0  \n",
              "1      The paper implements low-rank bilinear pooling...             1  \n",
              "2      The paper presents various ablation studies of...             2  \n",
              "3                                   -Strengths:\\n\\n\\n-1.             3  \n",
              "4      The paper presents new insights into element-w...             4  \n",
              "...                                                  ...           ...  \n",
              "23638  -In summary:\\n---Pros:\\n---- Clearly written a...            14  \n",
              "23639  ---- Consistent improvement of the student wit...            15  \n",
              "23640  ---Cons:\\n---- Students have worst performance...            16  \n",
              "23641  ---- It is not clear which attention to use in...            17  \n",
              "23642  ---- Somewhat incremental novelty relatively t...            18  \n",
              "\n",
              "[23643 rows x 6 columns]"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dftest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('https://openreview.net/forum?id=B1-Hhnslg',)\n",
            "       index                                         id  \\\n",
            "22526   1438  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22527   1438  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22528   1438  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22529   1438  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22530   1438  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22531   1438  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22532   1438  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22533   1438  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22534   1438  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22535   1439  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22536   1439  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22537   1439  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22538   1439  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22539   1439  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22540   1439  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22541   1439  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22542   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22543   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22544   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22545   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22546   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22547   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22548   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22549   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22550   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22551   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22552   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22553   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22554   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22555   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22556   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22557   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22558   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22559   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22560   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "22561   1440  https://openreview.net/forum?id=B1-Hhnslg   \n",
            "\n",
            "                                                    text  \\\n",
            "22526  The paper is an extension of the matching netw...   \n",
            "22527  The paper is an extension of the matching netw...   \n",
            "22528  The paper is an extension of the matching netw...   \n",
            "22529  The paper is an extension of the matching netw...   \n",
            "22530  The paper is an extension of the matching netw...   \n",
            "22531  The paper is an extension of the matching netw...   \n",
            "22532  The paper is an extension of the matching netw...   \n",
            "22533  The paper is an extension of the matching netw...   \n",
            "22534  The paper is an extension of the matching netw...   \n",
            "22535  This paper proposes an improved version of mat...   \n",
            "22536  This paper proposes an improved version of mat...   \n",
            "22537  This paper proposes an improved version of mat...   \n",
            "22538  This paper proposes an improved version of mat...   \n",
            "22539  This paper proposes an improved version of mat...   \n",
            "22540  This paper proposes an improved version of mat...   \n",
            "22541  This paper proposes an improved version of mat...   \n",
            "22542  *** Paper Summary ***----------------This pape...   \n",
            "22543  *** Paper Summary ***----------------This pape...   \n",
            "22544  *** Paper Summary ***----------------This pape...   \n",
            "22545  *** Paper Summary ***----------------This pape...   \n",
            "22546  *** Paper Summary ***----------------This pape...   \n",
            "22547  *** Paper Summary ***----------------This pape...   \n",
            "22548  *** Paper Summary ***----------------This pape...   \n",
            "22549  *** Paper Summary ***----------------This pape...   \n",
            "22550  *** Paper Summary ***----------------This pape...   \n",
            "22551  *** Paper Summary ***----------------This pape...   \n",
            "22552  *** Paper Summary ***----------------This pape...   \n",
            "22553  *** Paper Summary ***----------------This pape...   \n",
            "22554  *** Paper Summary ***----------------This pape...   \n",
            "22555  *** Paper Summary ***----------------This pape...   \n",
            "22556  *** Paper Summary ***----------------This pape...   \n",
            "22557  *** Paper Summary ***----------------This pape...   \n",
            "22558  *** Paper Summary ***----------------This pape...   \n",
            "22559  *** Paper Summary ***----------------This pape...   \n",
            "22560  *** Paper Summary ***----------------This pape...   \n",
            "22561  *** Paper Summary ***----------------This pape...   \n",
            "\n",
            "                                                    gold  \\\n",
            "22526  The program committee appreciates the authors'...   \n",
            "22527  The program committee appreciates the authors'...   \n",
            "22528  The program committee appreciates the authors'...   \n",
            "22529  The program committee appreciates the authors'...   \n",
            "22530  The program committee appreciates the authors'...   \n",
            "22531  The program committee appreciates the authors'...   \n",
            "22532  The program committee appreciates the authors'...   \n",
            "22533  The program committee appreciates the authors'...   \n",
            "22534  The program committee appreciates the authors'...   \n",
            "22535  The program committee appreciates the authors'...   \n",
            "22536  The program committee appreciates the authors'...   \n",
            "22537  The program committee appreciates the authors'...   \n",
            "22538  The program committee appreciates the authors'...   \n",
            "22539  The program committee appreciates the authors'...   \n",
            "22540  The program committee appreciates the authors'...   \n",
            "22541  The program committee appreciates the authors'...   \n",
            "22542  The program committee appreciates the authors'...   \n",
            "22543  The program committee appreciates the authors'...   \n",
            "22544  The program committee appreciates the authors'...   \n",
            "22545  The program committee appreciates the authors'...   \n",
            "22546  The program committee appreciates the authors'...   \n",
            "22547  The program committee appreciates the authors'...   \n",
            "22548  The program committee appreciates the authors'...   \n",
            "22549  The program committee appreciates the authors'...   \n",
            "22550  The program committee appreciates the authors'...   \n",
            "22551  The program committee appreciates the authors'...   \n",
            "22552  The program committee appreciates the authors'...   \n",
            "22553  The program committee appreciates the authors'...   \n",
            "22554  The program committee appreciates the authors'...   \n",
            "22555  The program committee appreciates the authors'...   \n",
            "22556  The program committee appreciates the authors'...   \n",
            "22557  The program committee appreciates the authors'...   \n",
            "22558  The program committee appreciates the authors'...   \n",
            "22559  The program committee appreciates the authors'...   \n",
            "22560  The program committee appreciates the authors'...   \n",
            "22561  The program committee appreciates the authors'...   \n",
            "\n",
            "                                                 summary  id_candidate  \n",
            "22526  The paper is an extension of the matching netw...             0  \n",
            "22527                                       in NIPS2016.             1  \n",
            "22528  Instead of using all the examples in the suppo...             2  \n",
            "22529  The training procedure and experimental settin...             3  \n",
            "22530  I am not completely sure about its advantages ...             4  \n",
            "22531  It seems to me when dealing with 1-shot case, ...             5  \n",
            "22532  When dealing with 5-shot case, original matchi...             6  \n",
            "22533  The experimental results reported for prototyp...             7  \n",
            "22534  I  think it is a simple, straightforward,  nov...             8  \n",
            "22535  This paper proposes an improved version of mat...             0  \n",
            "22536  Instead of considering each support point indi...             1  \n",
            "22537                                                1).             2  \n",
            "22538  This is combined with episodic few-shot traini...             3  \n",
            "22539  -Although the idea is quite straightforward, a...             4  \n",
            "22540  One addition that I think would improve the pa...             5  \n",
            "22541  In its current form the paper a bit vague abou...             6  \n",
            "22542  *** Paper Summary ***\\n\\n\\n-This paper simplif...             0  \n",
            "22543  Empirical comparisons with matching networks a...             1  \n",
            "22544  -*** Review ***\\n\\n\\n-The paper reads well and...             2  \n",
            "22545  This work of learning metric learning propose ...             3  \n",
            "22546  However, I am not sure it achieve better resul...             4  \n",
            "22547  The space of learning embeddings to optimize n...             5  \n",
            "22548  I would suggest to improve the discussion of r...             6  \n",
            "22549  -The related work section can be extended to i...             7  \n",
            "22550  Extensions to perform the same task with neura...             8  \n",
            "22551  Regarding approaches pursuing similar goals wi...             9  \n",
            "22552  The learning to rank (for websearch) litteratu...            10  \n",
            "22553  one example \"the query\" defines the class and ...            11  \n",
            "22554  I would suggest to start with Chris Burges 201...            12  \n",
            "22555  One learning class \\n\\n\\n-I am not sure the re...            13  \n",
            "22556  The results are positive on Omniglot but I fee...            14  \n",
            "22557  It can be considered misleading not to report it.            15  \n",
            "22558  On Cub 200, I thought that the state-of-the-ar...            16  \n",
            "22559  -Overall, paper could greatly be improved, bot...            17  \n",
            "22560  -*** References ***\\n\\n\\n-Large Margin Nearest...            18  \n",
            "22561  Weinberger et al, 2005\\n---From RankNet to Lam...            19  \n"
          ]
        }
      ],
      "source": [
        "grouped = dftest.groupby([\"id\"])\n",
        "for name, dft in grouped:\n",
        "\tprint(name)\n",
        "\tprint(dft)\n",
        "\tbreak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "490"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "curr_ds = pd.read_csv('data/candidatess/all_reviews_2017_-_abstr.csv')\n",
        "curr_ds['id'].nunique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "data = Path('data/lm_probas/all_reviews_2017_-_abstr-_-BART.pkl')\n",
        "df = pd.read_pickle(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['id', 'language_model_proba_df', 'gold', 'rationality', 'text_candidates'])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['results'][0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data\\lm_probas\n"
          ]
        }
      ],
      "source": [
        "lm_probas_path = Path(\"data/lm_probas\")\n",
        "print(lm_probas_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_names = ['BART', 'PEGASUS']\n",
        "lm_probas_files = list([Path('data\\lm_probas\\all_reviews_2017_-_abstr-_-BART.pkl'), Path('data\\lm_probas\\all_reviews_2017_-_abstr-_-PEGASUS.pkl'), Path('data\\lm_probas\\BART_all_reviews_2018_-_extr-_-PGS.pkl')])\n",
        "lm_probas_files = [file for file in lm_probas_files if any(\n",
        "    model_name in file.stem.split('-_-')[-1] for model_name in model_names)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[WindowsPath('data/lm_probas\\x07ll_reviews_2017_-_abstr-_-BART.pkl'),\n",
              " WindowsPath('data/lm_probas\\x07ll_reviews_2017_-_abstr-_-PEGASUS.pkl')]"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_probas_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
