{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Summaries from VECTORIZED-RSA\n",
    "\n",
    "This script is used to accept set of pkl files where likelihood are aggregated, and then use these values to compute a single RSA values that is later used to retrieve GLIMPSE-SPEAKER and GLIMPSE-UNIQUE\n",
    "\n",
    "Please not that this notebook will save all obtained results in a new folder (similar to all other scripts) where results can be easily evaluated to be compared later against other techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModel\n",
    "\n",
    "class VectorRSAReranking:\n",
    "    def __init__(\n",
    "            self,\n",
    "            lm_probas: np.ndarray,\n",
    "            num_models: int,\n",
    "            candidates: List[str],\n",
    "            source_texts: List[str],\n",
    "            batch_size: int = 32,\n",
    "            rationality: int = 1,\n",
    "            device=\"cuda\",\n",
    "    ):\n",
    "        \n",
    "        self.num_models = num_models \n",
    "        self.device = device\n",
    "        self.likelihood_matrix = torch.Tensor(lm_probas)\n",
    "\n",
    "        self.candidates = candidates\n",
    "        self.source_texts = source_texts\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.rationality = rationality\n",
    "\n",
    "\n",
    "    @cache\n",
    "    def S(self, t):\n",
    "        if t == 0:\n",
    "            return self.initial_speaker_probas\n",
    "        else:\n",
    "            listener = self.L(t - 1)\n",
    "            # Process each element in the lists separately\n",
    "            result = []\n",
    "            for i in range(self.num_models):\n",
    "                # Extract i-th elements from each list in the matrix\n",
    "                current_layer = listener[..., i]\n",
    "                # Perform operation on the current layer\n",
    "                prod = current_layer * self.rationality\n",
    "                processed_layer = torch.log_softmax(prod, dim=-1)\n",
    "                result.append(processed_layer)\n",
    "            \n",
    "            # Stack the processed layers into a single tensor\n",
    "            # Shape will be [batch_size, num_classes, list_length]\n",
    "            return torch.stack(result, dim=-1)\n",
    "\n",
    "    @cache\n",
    "    def L(self, t):\n",
    "        speaker = self.S(t)\n",
    "        result = []\n",
    "        for i in range(self.num_models):\n",
    "            # Extract i-th elements from each list in the matrix\n",
    "            current_layer = speaker[..., i]\n",
    "            processed_layer = torch.log_softmax(current_layer, dim=-2)\n",
    "            result.append(processed_layer)\n",
    "        \n",
    "        return torch.stack(result, dim=-1)\n",
    "\n",
    "    def mk_listener_dataframe(self, t, agg_method):\n",
    "        self.initial_speaker_probas = self.likelihood_matrix #self.likelihood_matrix()        \n",
    "        initial_listener_probas = self.L(0)\n",
    "        initial_speaker_probas = self.S(0)\n",
    "\n",
    "        # compute consensus\n",
    "        uniform_distribution_over_source_texts = torch.ones_like(\n",
    "            initial_listener_probas\n",
    "        ) / len(self.source_texts)\n",
    "\n",
    "        consensuality_scores = (\n",
    "            (\n",
    "                torch.exp(self.L(t))\n",
    "                * (self.L(t) - torch.log(uniform_distribution_over_source_texts))\n",
    "            )\n",
    "            .sum(0).cpu().numpy()\n",
    "        )\n",
    "\n",
    "        # Aggregating the scores over the models\n",
    "        if agg_method==\"mean\":\n",
    "            initial_listener_probas = initial_listener_probas.mean(dim=-1).cpu().numpy()\n",
    "            initial_speaker_probas = initial_speaker_probas.mean(dim=-1).cpu().numpy()\n",
    "            consensuality_scores = consensuality_scores.mean(axis=1)\n",
    "            speaker_df = pd.DataFrame(self.S(t).mean(dim=-1).cpu().numpy().tolist())\n",
    "            listener_df = pd.DataFrame(self.L(t).mean(dim=-1).cpu().numpy().tolist())\n",
    "        elif agg_method==\"max\":\n",
    "            initial_listener_probas = initial_listener_probas.max(dim=-1).values.cpu().numpy()\n",
    "            initial_speaker_probas = initial_speaker_probas.max(dim=-1).values.cpu().numpy()\n",
    "            consensuality_scores = consensuality_scores.max(axis=1)\n",
    "            speaker_df = pd.DataFrame(self.S(t).max(dim=-1).values.cpu().numpy().tolist())\n",
    "            listener_df = pd.DataFrame(self.L(t).max(dim=-1).values.cpu().numpy().tolist())\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"agg_method must be either 'mean' or 'max', got: {agg_method}\")\n",
    "\n",
    "        # Compute and return `initial_listener_probas` and other necessary components\n",
    "        initial_listener_probas = pd.DataFrame(initial_listener_probas)\n",
    "        initial_listener_probas.index = self.source_texts\n",
    "        initial_listener_probas.columns = self.candidates\n",
    "   \n",
    "        initial_speaker_probas = pd.DataFrame(initial_speaker_probas)\n",
    "        initial_speaker_probas.index = self.source_texts\n",
    "        initial_speaker_probas.columns = self.candidates\n",
    "        \n",
    "        consensuality_scores = pd.Series(consensuality_scores, index=self.candidates)\n",
    "\n",
    "        listener_df.index = self.source_texts\n",
    "        speaker_df.index = self.source_texts\n",
    "\n",
    "        listener_df.columns = self.candidates\n",
    "        speaker_df.columns = self.candidates\n",
    "\n",
    "        return listener_df, speaker_df, initial_listener_probas, initial_speaker_probas, None, consensuality_scores\n",
    "\n",
    "    def rerank(self, t=1, agg_method=\"mean\"):\n",
    "        \"\"\"\n",
    "        return the best summary (according to rsa) for each text\n",
    "        \"\"\"\n",
    "        (\n",
    "            listener_df,\n",
    "            speaker_df,\n",
    "            initial_listener_proba,\n",
    "            initial_speaker_proba,\n",
    "            initital_consensuality_score,\n",
    "            consensuality_scores,\n",
    "        ) = self.mk_listener_dataframe(t=t, agg_method=agg_method)\n",
    "        best_rsa = speaker_df.idxmax(axis=1).values\n",
    "        best_base = initial_listener_proba.idxmax(axis=1).values\n",
    "\n",
    "        return (\n",
    "            best_rsa,\n",
    "            best_base,\n",
    "            speaker_df,\n",
    "            listener_df,\n",
    "            initial_listener_proba,\n",
    "            initial_speaker_proba,\n",
    "            initital_consensuality_score,\n",
    "            consensuality_scores,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\vector_probas\\all_merged_226_extr_LED_Large_PEGASUS_Large_PEGASUS_BigBird_Arxiv.pkl\n",
      "data\\vector_probas\\BART_all_merged_226_abstr_LED_Large_PEGASUS_Large_PEGASUS_BigBird.pkl\n",
      "data\\vector_probas\\PEGASUS_Arxiv_all_merged_226_abstr_LED_Large_PEGASUS_Large_PEGASUS.pkl\n",
      "data\\vector_probas\\PEGASUS_Large_all_merged_226_abstr_LED_Large_PEGASUS_Large_PEGASUS.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle as pk\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "path_probas = Path(\"data/vector_probas\")\n",
    "for file in path_probas.glob('*.pkl'):\n",
    "    dataset_name = str(file).split('\\\\')[-1].split('all')[0]\n",
    "    if dataset_name == '':\n",
    "        dataset_name = 'extr_'\n",
    "\n",
    "    with open(file, 'rb') as file:\n",
    "        agg_lm_probas = pk.load(file)\n",
    "\n",
    "    assert len(agg_lm_probas['results']) == 226\n",
    "\n",
    "    for aggregation_method in [\"mean\", \"max\"]:\n",
    "        resultsGS = pd.DataFrame(columns=['id','summary','text','gold'])\n",
    "        resultsGS_file = \"data\\\\vector_results\\\\\"+dataset_name+\"vector_\"+aggregation_method+\"_GS.csv\"\n",
    "        resultsGU = pd.DataFrame(columns=['id','summary','text','gold'])\n",
    "        resultsGU_file = \"data\\\\vector_results\\\\\"+dataset_name+\"vector_\"+aggregation_method+\"_GU.csv\"\n",
    "\n",
    "        for i in range(len(agg_lm_probas['results'])):\n",
    "            lm_probas_concat = agg_lm_probas['results'][i]['lm_probas_concat']\n",
    "            candidates = lm_probas_concat.columns.tolist()\n",
    "            source_texts = lm_probas_concat.index.tolist()\n",
    "            lm_probas = lm_probas_concat.values\n",
    "            lm_probas = np.array([[np.array(cell) for cell in row] for row in lm_probas])\n",
    "            best_rsa, best_base, speaker_df, listener_df, initial_listener_proba, initial_speaker_proba, _, \\\n",
    "            consensuality_score = VectorRSAReranking(num_models=5, lm_probas=lm_probas, device='cpu', candidates=candidates, \\\n",
    "                                                    source_texts=source_texts).rerank(t=3, agg_method=aggregation_method)\n",
    "            \n",
    "            id = agg_lm_probas['results'][i]['id']\n",
    "            gold = agg_lm_probas['results'][i]['gold']\n",
    "\n",
    "            consensus_samples = consensuality_score.sort_values(ascending=True).head(3).index.tolist()\n",
    "            disensus_samples = consensuality_score.sort_values(ascending=False).head(3).index.tolist()\n",
    "\n",
    "            consensus = \".\".join(consensus_samples)\n",
    "            disensus = \".\".join(disensus_samples)\n",
    "\n",
    "            summaryGU = consensus + \"\\n\\n\" + disensus\n",
    "\n",
    "            rsa = best_rsa.tolist()[:3]\n",
    "            rsa = \".\".join(rsa)\n",
    "\n",
    "            summaryGS = consensus + \"\\n\\n\" + rsa\n",
    "\n",
    "            newGS = {'id': id, 'summary': summaryGS, 'text': \" \".join(source_texts), 'gold': gold}\n",
    "            newGSdf = pd.DataFrame(newGS, index = None)\n",
    "            resultsGS = pd.concat([resultsGS, newGSdf], ignore_index=True)\n",
    "\n",
    "            newGU = {'id': id, 'summary': summaryGU, 'text': \" \".join(source_texts), 'gold': gold}\n",
    "            newGUdf = pd.DataFrame(newGU, index = None)\n",
    "            resultsGU = pd.concat([resultsGU, newGUdf], ignore_index=True)\n",
    "\n",
    "\n",
    "        resultsGS.to_csv(resultsGS_file, index=False)\n",
    "        resultsGU.to_csv(resultsGU_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
